task: tagger
backend: pytorch
dataset: wnut-iobes
conll_output: wnut-bert.conll
basedir: ./
unif: 0.1
preproc:
  mxlen: -1
  mxwlen: -1

features:
 - name: word
   vectorizer:
     label: bert-base-cased-dict1d
   embeddings:
     type: tlm-words-embed
     word_embed_type: learned-positional-w-bias
     label: bert-base-cased-npz
     reduction: sum-layer-norm
     layer_norms_after: true
     finetune: true
     mlm: true
loader:
  reader_type: default
  named_fields: {"0": "text", "-1": "y"}
  label_vectorizer:
    label: y
    type: wordpiece-label-dict1d

model:
  model_type: pass
  constrain_decode: 0
  crf: 0

train:
  epochs: 40
  optim: adam
  eta: 1.0e-5
  early_stopping_metric: f1
  clip: 5.0
  span_type: iobes
  batchsz: 32
