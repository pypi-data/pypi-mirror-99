[active]

selected: development

[development]

# default broker url. this must be a url in the form of:
# transport://userid:password@hostname:port/virtual_host
# for example with amqp transport:
# amqp://amqp:5672/
# only the scheme part (transport://) is required, the rest is
# optional, and defaults to the specific transports default values.
# the transport part is the broker implementation to use, and the default
# is amqp, (uses librabbitmq if installed or falls back to pyamqp). there are also
# other choices available, including: 'redis://', 'sqs://' and 'qpid://'.
# the scheme can also be a fully qualified path to your own transport implementation:
# 'proj.transports.MyTransport://localhost'
# more than one broker url, of the same transport, can also be specified.
# the broker urls can be passed in as a single string that's semicolon delimited:
# 'transport://userid:password@hostname:port//;transport://userid:password@hostname:port//'
# or as a list:
# ['transport://userid:password@localhost:port//',
#  'transport://userid:password@hostname:port//']
# the brokers will then be used in the 'broker_failover_strategy'.
broker_url: null

# a dict of additional options passed to the underlying transport.
# see your transport user manual for supported options (if any).
# example setting the visibility timeout (supported by redis and sqs transports):
# {"visibility_timeout": 18000} (5 hours)
# example setting the producer connection maximum number of retries (so producers
# won't retry forever if the broker isn't available at the first task execution):
# {"max_retries": 2}
broker_transport_options: {"max_retries": 2}

# the default timeout in seconds before we give up establishing a
# connection to the amqp server. this setting is disabled when using gevent.
# defaults to 4 seconds.
broker_connection_timeout: 4

# automatically try to re-establish the connection to the amqp broker if lost.
# the time between retries is increased for each retry, and is not exhausted before
# 'broker_connection_max_retries' is exceeded.
# defaults to true.
broker_connection_retry: true

# maximum number of retries before we give up re-establishing a connection
# to the amqp broker. if this is set to 0 or null, we'll retry forever.
# defaults to 20.
broker_connection_max_retries: 20

# default failover strategy for the broker connection object. if supplied, may map
# to a key in 'kombu.connection.failover_strategies', or be a reference to any method
# that yields a single item from a supplied list.
# defaults to 'round-robin'.
broker_failover_strategy: round-robin

# set custom amqp login method.
# defaults to 'AMQPLAIN'.
broker_login_method: AMQPLAIN

# the maximum number of connections that can be open in the connection pool.
# the pool is enabled by default since version 2.5, with a default limit of ten
# connections. this number can be tweaked depending on the number of threads/green-threads
# (eventlet/gevent) using a connection. for example running eventlet with 1000 greenlets
# that use a connection to the broker, contention can arise and you should consider
# increasing the limit. if set to null or 0 the connection pool will be disabled and
# connections will be established and closed for every use.
# defaults to 10.
broker_pool_limit: 10

# toggles ssl usage on broker connection and ssl settings.
# the valid values for this option vary by transport.
# supported transports are 'pyamqp' and 'redis'.
# defaults to false.
# if set to true and transport is 'pyamqp' the connection will use ssl with default ssl settings.
# if set to a dict, will configure ssl connection according to the specified policy. the format
# used is python's ssl.wrap_socket() options. note that ssl socket is generally served on a
# separate port by the broker.
# sample for 'pyamqp':
# {
#  "keyfile": "/var/ssl/private/worker-key.pem",
#  "certfile": "/var/ssl/amqp-server-cert.pem",
#  "ca_certs": "/var/ssl/myca.pem",
#  "cert_reqs": ssl.CERT_REQUIRED
# }
# if set to true and transport is 'redis' the setting must be a dict with the following keys:
# ssl_cert_reqs (required): one of the 'SSLContext.verify_mode' values:
# 'ssl.CERT_NONE', 'ssl.CERT_OPTIONAL' or 'ssl.CERT_REQUIRED'.
# ssl_ca_certs (optional): path to the CA certificate.
# ssl_certfile (optional): path to the client certificate.
# ssl_keyfile (optional): path to the client key.
broker_use_ssl: false

# these settings can be configured, instead of 'broker_url' to specify
# different connection parameters for broker connections used for consuming and producing.
# both options can also be specified as a list for failover alternates.
# see 'broker_url' for more information.
### broker_read_url: null
### broker_write_url: null

# this value is only used by the worker, clients do not use a heartbeat at the moment.
# it's not always possible to detect connection loss in a timely manner using tcp/ip
# alone, so amqp defines something called heartbeats that's is used both by the client and
# the broker to detect if a connection was closed. if the heartbeat value is 10 seconds,
# then the heartbeat will be monitored at the interval specified by the
# 'broker_heartbeat_checkrate' setting (by default this is set to double the rate of
# the heartbeat value, so for the 10 seconds, the heartbeat is checked every 5 seconds).
# this could only be enabled on 'pyamqp' transport.
# defaults to 120. only uncomment if you know what it is.
### broker_heartbeat: 120

# at intervals the worker will monitor that the broker hasn't missed too many heartbeats.
# the rate at which this is checked is calculated by dividing the 'broker_heartbeat' value
# with this value, so if the heartbeat is 10.0 and the rate is the default 2.0, the check
# will be performed every 5 seconds (twice the heartbeat sending rate).
# this could only be enabled on 'pyamqp' transport.
# defaults to 2. only uncomment if you know what it is.
### broker_heartbeat_checkrate: 2

# the backend used to store task results (tombstones).
# could be one of the following:
# rpc, database, redis, cache, mongodb, cassandra, elasticsearch, ironcache,
# couchbase, arangodb, couchdb, cosmosdbsql, filesystem, consul, azureblockblob, s3.
# defaults to null and no backend is enabled.
# to use the database backend you have to configure the 'result_backend' setting with a
# connection url and the 'db+' prefix: 'db+scheme://user:password@host:port/dbname'.
# example connections for different databases:
# sqlite: 'db+sqlite:///results.sqlite'
# mysql: 'db+mysql://scott:tiger@localhost/foo'
# postgresql: 'db+postgresql://scott:tiger@localhost/mydatabase'
# oracle: 'db+oracle://scott:tiger@127.0.0.1:1521/sidname'
result_backend: null

# if set to true, result messages will be persistent.
# this means the messages won't be lost after a broker restart.
# this needs the 'result_backed' to be enabled too.
# defaults to false.
result_persistent: false

# optional compression method used for task results.
# can be gzip, bzip2 (if available), or any custom compression schemes
# registered in the kombu compression registry.
# default is null and no compression will be applied.
result_compression: null

# time (in seconds, or a timedelta object) for when after stored task
# tombstones will be deleted. a built-in periodic task will delete the results
# after this time (celery.backend_cleanup), assuming that celery beat is enabled.
# the task runs daily at 4am. a value of null or 0 means results will never
# expire (depending on backend specifications).
# defaults to 1 day (86400 seconds).
result_expires: 86400

# result serialization format.
# defaults to 'json'.
result_serializer: json

# enables extended task result attributes (name, args, kwargs, worker,
# retries, queue, delivery_info) to be written to backend.
# defaults to false.
result_extended: false

# to specify additional sqlalchemy database engine options you can use this setting.
# for example: {"echo": true}.
# defaults to an empty dict.
database_engine_options: {}

# when sqlalchemy is configured as the result backend, celery automatically creates
# two tables to store result meta-data for tasks. this setting allows you to customize
# the schema of the tables.
# for example:
# {
#    "task": "custom_schema_name",
#    "group": "custom_schema_name"
# }
# defaults to an empty dict.
database_table_schemas: {}

# when sqlalchemy is configured as the result backend, celery automatically creates two
# tables to store result meta-data for tasks. this setting allows you to customize the
# table names. for example:
# {
#    "task": "custom_table_name",
#    "group": "custom_table_name",
# }
# defaults to an empty dict.
database_table_names: {}

# short lived sessions are disabled by default. if enabled they can drastically
# reduce performance, especially on systems processing lots of tasks. this option
# is useful on low-traffic workers that experience errors as a result of cached
# database connections going stale through inactivity. for example, intermittent
# errors like (OperationalError) (2006, 'mysql server has gone away') can be fixed
# by enabling short lived sessions. this option only affects the database backend.
# defaults to false.
database_short_lived_sessions: false

# whether to store the task return values or not (tombstones).
# if you still want to store errors, just not successful return values, you
# can set 'task_store_errors_even_if_ignored' to true.
# defaults to false.
task_ignore_result: false

# if set, the worker stores all task errors in the result store
# even if 'task_ignore_result' is true.
# defaults to false.
task_store_errors_even_if_ignored: false

# if true the task will report its status as 'started' when the task is executed
# by a worker. the default value is false as the normal behavior is to not report
# that level of granularity. tasks are either pending, finished, or waiting to be
# retried. having a 'started' state can be useful for when there are long running
# tasks and there's a need to report what task is currently running.
# defaults to false.
task_track_started: false

# default compression used for task messages. can be gzip, bzip2 (if available), or any
# custom compression schemes registered in the kombu compression registry.
# default is null and no compression will be applied.
task_compression: null

# set the default task message protocol version used to send tasks.
# supported protocols are 1 and 2.
# protocol 2 is supported by 3.1.24 and 4.x+.
# defaults to 2.
task_protocol: 2

# a string identifying the default serialization method to use. can be
# json (default), pickle, yaml, msgpack, or any custom serialization methods
# that have been registered with 'kombu.serialization.registry'.
# defaults to 'json'.
task_serializer: json

# if this is true, all tasks will be executed locally by blocking until the
# task returns. apply_async() and task.delay() will return an EagerResult
# instance, that emulates the api and behavior of AsyncResult, except the
# result is already evaluated. that is, tasks will be executed locally
# instead of being sent to the queue.
# defaults to false.
task_always_eager: false

# if this is true, eagerly executed tasks (applied by task.apply(), or when the
# 'task_always_eager' setting is enabled), will propagate exceptions.
# it's the same as always running apply() with throw=True.
# defaults to false.
task_eager_propagates: false

# if enabled task results will include the workers stack when re-raising task errors.
# this requires the 'tblib' library, that can be installed using pip:
# pip install celery[tblib]
# defaults to false.
task_remote_tracebacks: false

# task hard time limit in seconds. the worker processing the task
# will be killed and replaced with a new one when this is exceeded.
# defaults to null and has no limit.
task_time_limit: null

# task soft time limit in seconds.
# the 'SoftTimeLimitExceeded' exception will be raised when this is exceeded.
# for example, the task can catch this to clean up before the hard time limit comes.
# defaults to null and has no soft limit.
task_soft_time_limit: null

# late ack means the task messages will be acknowledged after the
# task has been executed, not just before.
# defaults to false.
task_acks_late: false

# when enabled messages for all tasks will be acknowledged even if they fail or time out.
# configuring this setting only applies to tasks that are acknowledged after they have
# been executed and only if 'task_acks_late' is enabled.
# defaults to true.
task_acks_on_failure_or_timeout: true

# even if 'task_acks_late' is enabled, the worker will acknowledge tasks when the
# worker process executing them abruptly exits or is signaled (e.g., kill/int, etc).
# setting this to true allows the message to be re-queued instead, so that the task
# will execute again by the same worker, or another worker.
# defaults to false.
task_reject_on_worker_lost: false

# the global default rate limit for tasks.
# this value is used for tasks that doesn't have a custom rate limit.
# defaults to null and has no rate limit.
task_default_rate_limit: null

# if enabled (default), any queues specified that aren't defined in
# 'task_queues' will be automatically created.
# defaults to true.
task_create_missing_queues: true

# can be transient (messages not written to disk) or persistent (written to disk).
# defaults to 'persistent'.
task_default_delivery_mode: persistent

# the name of the default queue used by 'apply_async' if the message has no route
# or no custom queue has been specified. this queue must be listed in 'task_queues'.
# if 'task_queues' isn't specified then it's automatically created containing one queue
# entry, where this name is used as the name of that queue.
# defaults to 'celery'.
task_default_queue: celery

# name of the default exchange to use when no custom exchange is
# specified for a key in the 'task_queues' setting.
# defaults to the value set for 'task_default_queue'.
### task_default_exchange: null

# default exchange type used when no custom exchange type is specified
# for a key in the 'task_queues' setting.
# defaults to 'direct'.
task_default_exchange_type: direct

# the default routing key used when no custom routing key is specified
# for a key in the task_queues setting.
# defaults to the value set for 'task_default_queue'.
### task_default_routing_key: null

# decides if publishing task messages will be retried in the case of connection
# loss or other connection errors. see also 'task_publish_retry_policy'.
# defaults to true.
task_publish_retry: true

# defines the default policy when retrying publishing a task message in
# the case of connection loss or other connection errors.
# it must be a dict and could contain these keys:
# max_retries, interval_start, interval_step and interval_max.
# for example:
# {
#    "max_retries": 3,
#    "interval_start": 0,
#    "interval_step": 0.2,
#    "interval_max": 0.2,
# }
### task_publish_retry_policy: {}

# a default max priority for all queues.
# it is only for rabbitmq.
# defaults to null.
task_queue_max_priority: null

# a default priority for all tasks.
# it is only for rabbitmq.
# defaults to null.
task_default_priority: null

# if enabled, child tasks will inherit priority of the parent task.
# it is only for rabbitmq.
# defaults to false.
task_inherit_parent_priority: false

# most users will not want to specify this setting and should rather use
# the automatic routing facilities. if you really want to configure advanced
# routing, this setting should be a list of 'kombu.Queue' objects the worker will
# consume from.
# if you want to set this, you must extend celery package of pyrin in your application
# and provide required configurations to it.
### task_queues: null

# if enabled, a task-sent event will be sent for every task so tasks can be
# tracked before they're consumed by a worker.
# defaults to false.
task_send_sent_event: false

# a white-list of content-types/serializers to allow.
# if a message is received that's not in this list then
# the message will be discarded with an error.
# it could be any content type such as pickle and yaml.
# defaults to ['json'].
accept_content: [json]

# if enabled dates and times in messages will be converted to use the utc timezone.
# defaults to true.
enable_utc: true

# a sequence of modules to import when the worker starts.
# this is used to specify the task modules to import, but also
# to import signal handlers and additional remote control commands, etc.
imports: []

# exact same semantics as imports, but can be used as a
# means to have different import categories.
# the modules in this setting are imported after the modules in imports.
include: []

# configure celery to use a custom time zone. the timezone value can
# be any time zone supported by the pytz library.
# if not set the utc timezone is used. for backwards compatibility there's
# also a enable_utc setting, and when this is set to false the system local
# timezone is used instead.
timezone: UTC

# the default scheduler class.
# defaults to 'celery.beat:PersistentScheduler'.
beat_scheduler: celery.beat:PersistentScheduler

# the periodic task schedule used by beat.
# defaults to an empty dict.
beat_schedule: {}

# name of the file used by PersistentScheduler to store the last run times of
# periodic tasks. can be a relative or absolute path, but be aware that the
# suffix .db may be appended to the file name (depending on python version).
# defaults to 'celerybeat-schedule'.
beat_schedule_filename: celerybeat-schedule

# the number of periodic tasks that can be called before another database sync
# is issued. a value of 0 (default) means sync based on timing - default of 3 minutes
# as determined by scheduler.sync_every. if set to 1, beat will call sync after every
# task message sent. defaults to 0.
beat_sync_every: 0

# the maximum number of seconds beat can sleep between checking the schedule.
# the default for this value is scheduler specific. for the default celery beat
# scheduler the value is 300 (5 minutes), but for the django-celery-beat database
# scheduler it's 5 seconds because the schedule may be changed externally, and so
# it must take changes to the schedule into account.
# only uncomment if you know what it is.
### beat_max_loop_interval: 0

# path to a file to store process id of beat process.
# note that if this file is existed and the process is active, beat process will not start.
beat_pid_file: null

# path to a file to put beat logs into it.
beat_log_file: null

# beat log level. it could be one of:
# 'DEBUG', 'INFO', 'WARNING', 'ERROR', or 'CRITICAL'.
# defaults to 'WARNING'.
beat_log_level: WARNING

# to enable message signing you should configure the 'task_serializer' setting to use
# the 'auth' serializer. enforcing the workers to only accept signed messages, you
# should set 'accept_content' to ['auth']. for additional signing of the event protocol,
# set 'event_serializer' to 'auth'. also required is configuring the paths used to
# locate private keys and certificates on the file-system: the 'security_key',
# 'security_certificate' and 'security_cert_store' settings respectively.
# you can tweak the signing algorithm with 'security_digest'.

# the relative or absolute path to a file containing the private key
# used to sign messages when message signing is used.
# defaults to null.
security_key: null

# the relative or absolute path to an x.509 certificate file
# used to sign messages when message signing is used.
# defaults to null.
security_certificate: null

# the directory containing x.509 certificates used for message signing.
# can be a glob with wild-cards, (for example /etc/certs/*.pem).
# defaults to null.
security_cert_store: null

# a cryptography digest used to sign messages when message signing is used.
# defaults to 'sha256'.
security_digest: sha256

# message serialization format used when sending event messages.
# defaults to 'json'.
event_serializer: json

# name of the autoscaler class to use.
# defaults to 'celery.worker.autoscale:Autoscaler'.
worker_autoscaler: celery.worker.autoscale:Autoscaler

# the number of concurrent worker processes/threads/green threads executing tasks.
# if you're doing mostly I/O you can have more processes, but if mostly cpu-bound, try to
# keep it close to the number of cpus on your machine. if not set, the number of cpus/cores
# on the host will be used.
# defaults to null and will use the number of cpus/cores of host machine.
worker_concurrency: null

# name of the consumer class used by the worker.
# defaults to 'celery.worker.consumer:Consumer'.
worker_consumer: celery.worker.consumer:Consumer

# specify if remote control of the workers is enabled.
# defaults to true.
worker_enable_remote_control: true

# name of the pool class used by the worker.
# defaults to 'celery.concurrency.prefork:TaskPool'.
worker_pool: celery.concurrency.prefork:TaskPool

# if enabled the worker pool can be restarted using the 'pool_restart' remote control command.
# defaults to false.
worker_pool_restarts: false

# how many messages to prefetch at a time multiplied by the number of concurrent processes.
# the default is 4 (four messages for each process). the default setting is usually a good
# choice. however if you have very long running tasks waiting in the queue and you have to
# start the workers, note that the first worker to start will receive four times the number
# of messages initially. thus the tasks may not be fairly distributed to the workers.
# to disable prefetching, set worker_prefetch_multiplier to 1. changing that setting
# to 0 will allow the worker to keep consuming as many messages as it wants.
# defaults to 4.
worker_prefetch_multiplier: 4

# if enabled stdout and stderr will be redirected to the current logger.
# used by celery worker and celery beat.
# defaults to true.
worker_redirect_stdouts: true

# the log level output to stdout and stderr is logged as.
# can be one of 'DEBUG', 'INFO', 'WARNING', 'ERROR', or 'CRITICAL'.
# defaults to 'WARNING'.
worker_redirect_stdouts_level: WARNING

# send task-related events so that tasks can be monitored using tools like flower.
# sets the default value for the workers -E argument.
# defaults to false.
worker_send_task_events: false

# enables/disables colors in logging output by the celery apps.
# defaults to true if the app is logging to a terminal.
worker_log_color: true

# name of the file used to stores persistent worker state (like revoked tasks).
# can be a relative or absolute path, but be aware that the suffix '.db' may be
# appended to the file name (depending on python version).
# defaults to null.
worker_state_db: null

# name of the eta scheduler class used by the worker.
# default is or set by the pool implementation.
# defaults to 'kombu.asynchronous.hub.timer:Timer'.
worker_timer: kombu.asynchronous.hub.timer:Timer

# set the maximum time in seconds that the eta scheduler can sleep between
# rechecking the schedule. setting this value to 1 second means the schedulers
# precision will be 1 second. if you need near millisecond precision you can set this to 0.1.
# defaults to 1 second.
worker_timer_precision: 1

# disable all rate limits, even if tasks has explicit rate limits set.
# defaults to false.
worker_disable_rate_limits: false

# maximum amount of resident memory, in kilobytes, that may be consumed by a
# worker before it will be replaced by a new worker. if a single task causes a
# worker to exceed this limit, the task will be completed, and the worker will
# be replaced afterwards.
# defaults to null and has no limit.
worker_max_memory_per_child: null

# maximum number of tasks a pool worker process can execute before
# it's replaced with a new one. defaults to null and has no limit.
worker_max_tasks_per_child: null

# in some cases a worker may be killed without proper cleanup, and the worker may have
# published a result before terminating. this value specifies how long we wait for any
# missing results before raising a 'WorkerLostError' exception.
# defaults to 10 seconds.
worker_lost_wait: 10

# this option enables so that every worker has a dedicated queue, so that tasks
# can be routed to specific workers. the queue name for each worker is automatically
# generated based on the worker hostname and a '.dq' suffix, using the 'C.dq' exchange.
worker_direct: false

# path to a file to store process id of worker.
# note that if this file is existed and the process is active, worker will not start.
worker_pid_file: null

# path to a file to put worker logs into it.
worker_log_file: null

# worker log level. it could be one of:
# 'DEBUG', 'INFO', 'WARNING', 'ERROR', or 'CRITICAL'.
# defaults to 'WARNING'.
worker_log_level: WARNING

# max and min processes to use for autoscaling. in the form of:
# max_process_count, min_process_count, for example 10,3.
worker_autoscale: null

# a hostname to be used for worker node.
# note that if you want to start multiple worker nodes on the same
# machine, you must set different hostnames for each one.
worker_hostname: null

# list of queues to enable for worker.
# it must contain queue names separated by comma.
# for example: images,videos
worker_queues: null

# optimization profile to be applied.
# could be from: 'default' and 'fair'.
# defaults to null.
worker_optimization: null

[production]

# default broker url. this must be a url in the form of:
# transport://userid:password@hostname:port/virtual_host
# for example with amqp transport:
# amqp://amqp:5672/
# only the scheme part (transport://) is required, the rest is
# optional, and defaults to the specific transports default values.
# the transport part is the broker implementation to use, and the default
# is amqp, (uses librabbitmq if installed or falls back to pyamqp). there are also
# other choices available, including: 'redis://', 'sqs://' and 'qpid://'.
# the scheme can also be a fully qualified path to your own transport implementation:
# 'proj.transports.MyTransport://localhost'
# more than one broker url, of the same transport, can also be specified.
# the broker urls can be passed in as a single string that's semicolon delimited:
# 'transport://userid:password@hostname:port//;transport://userid:password@hostname:port//'
# or as a list:
# ['transport://userid:password@localhost:port//',
#  'transport://userid:password@hostname:port//']
# the brokers will then be used in the 'broker_failover_strategy'.
broker_url: null

# a dict of additional options passed to the underlying transport.
# see your transport user manual for supported options (if any).
# example setting the visibility timeout (supported by redis and sqs transports):
# {"visibility_timeout": 18000} (5 hours)
# example setting the producer connection maximum number of retries (so producers
# won't retry forever if the broker isn't available at the first task execution):
# {"max_retries": 2}
broker_transport_options: {"max_retries": 2}

# the default timeout in seconds before we give up establishing a
# connection to the amqp server. this setting is disabled when using gevent.
# defaults to 4 seconds.
broker_connection_timeout: 4

# automatically try to re-establish the connection to the amqp broker if lost.
# the time between retries is increased for each retry, and is not exhausted before
# 'broker_connection_max_retries' is exceeded.
# defaults to true.
broker_connection_retry: true

# maximum number of retries before we give up re-establishing a connection
# to the amqp broker. if this is set to 0 or null, we'll retry forever.
# defaults to 20.
broker_connection_max_retries: 20

# default failover strategy for the broker connection object. if supplied, may map
# to a key in 'kombu.connection.failover_strategies', or be a reference to any method
# that yields a single item from a supplied list.
# defaults to 'round-robin'.
broker_failover_strategy: round-robin

# set custom amqp login method.
# defaults to 'AMQPLAIN'.
broker_login_method: AMQPLAIN

# the maximum number of connections that can be open in the connection pool.
# the pool is enabled by default since version 2.5, with a default limit of ten
# connections. this number can be tweaked depending on the number of threads/green-threads
# (eventlet/gevent) using a connection. for example running eventlet with 1000 greenlets
# that use a connection to the broker, contention can arise and you should consider
# increasing the limit. if set to null or 0 the connection pool will be disabled and
# connections will be established and closed for every use.
# defaults to 10.
broker_pool_limit: 10

# toggles ssl usage on broker connection and ssl settings.
# the valid values for this option vary by transport.
# supported transports are 'pyamqp' and 'redis'.
# defaults to false.
# if set to true and transport is 'pyamqp' the connection will use ssl with default ssl settings.
# if set to a dict, will configure ssl connection according to the specified policy. the format
# used is python's ssl.wrap_socket() options. note that ssl socket is generally served on a
# separate port by the broker.
# sample for 'pyamqp':
# {
#  "keyfile": "/var/ssl/private/worker-key.pem",
#  "certfile": "/var/ssl/amqp-server-cert.pem",
#  "ca_certs": "/var/ssl/myca.pem",
#  "cert_reqs": ssl.CERT_REQUIRED
# }
# if set to true and transport is 'redis' the setting must be a dict with the following keys:
# ssl_cert_reqs (required): one of the 'SSLContext.verify_mode' values:
# 'ssl.CERT_NONE', 'ssl.CERT_OPTIONAL' or 'ssl.CERT_REQUIRED'.
# ssl_ca_certs (optional): path to the CA certificate.
# ssl_certfile (optional): path to the client certificate.
# ssl_keyfile (optional): path to the client key.
broker_use_ssl: false

# these settings can be configured, instead of 'broker_url' to specify
# different connection parameters for broker connections used for consuming and producing.
# both options can also be specified as a list for failover alternates.
# see 'broker_url' for more information.
### broker_read_url: null
### broker_write_url: null

# this value is only used by the worker, clients do not use a heartbeat at the moment.
# it's not always possible to detect connection loss in a timely manner using tcp/ip
# alone, so amqp defines something called heartbeats that's is used both by the client and
# the broker to detect if a connection was closed. if the heartbeat value is 10 seconds,
# then the heartbeat will be monitored at the interval specified by the
# 'broker_heartbeat_checkrate' setting (by default this is set to double the rate of
# the heartbeat value, so for the 10 seconds, the heartbeat is checked every 5 seconds).
# this could only be enabled on 'pyamqp' transport.
# defaults to 120. only uncomment if you know what it is.
### broker_heartbeat: 120

# at intervals the worker will monitor that the broker hasn't missed too many heartbeats.
# the rate at which this is checked is calculated by dividing the 'broker_heartbeat' value
# with this value, so if the heartbeat is 10.0 and the rate is the default 2.0, the check
# will be performed every 5 seconds (twice the heartbeat sending rate).
# this could only be enabled on 'pyamqp' transport.
# defaults to 2. only uncomment if you know what it is.
### broker_heartbeat_checkrate: 2

# the backend used to store task results (tombstones).
# could be one of the following:
# rpc, database, redis, cache, mongodb, cassandra, elasticsearch, ironcache,
# couchbase, arangodb, couchdb, cosmosdbsql, filesystem, consul, azureblockblob, s3.
# defaults to null and no backend is enabled.
# to use the database backend you have to configure the 'result_backend' setting with a
# connection url and the 'db+' prefix: 'db+scheme://user:password@host:port/dbname'.
# example connections for different databases:
# sqlite: 'db+sqlite:///results.sqlite'
# mysql: 'db+mysql://scott:tiger@localhost/foo'
# postgresql: 'db+postgresql://scott:tiger@localhost/mydatabase'
# oracle: 'db+oracle://scott:tiger@127.0.0.1:1521/sidname'
result_backend: null

# if set to true, result messages will be persistent.
# this means the messages won't be lost after a broker restart.
# this needs the 'result_backed' to be enabled too.
# defaults to false.
result_persistent: false

# optional compression method used for task results.
# can be gzip, bzip2 (if available), or any custom compression schemes
# registered in the kombu compression registry.
# default is null and no compression will be applied.
result_compression: null

# time (in seconds, or a timedelta object) for when after stored task
# tombstones will be deleted. a built-in periodic task will delete the results
# after this time (celery.backend_cleanup), assuming that celery beat is enabled.
# the task runs daily at 4am. a value of null or 0 means results will never
# expire (depending on backend specifications).
# defaults to 1 day (86400 seconds).
result_expires: 86400

# result serialization format.
# defaults to 'json'.
result_serializer: json

# enables extended task result attributes (name, args, kwargs, worker,
# retries, queue, delivery_info) to be written to backend.
# defaults to false.
result_extended: false

# to specify additional sqlalchemy database engine options you can use this setting.
# for example: {"echo": true}.
# defaults to an empty dict.
database_engine_options: {}

# when sqlalchemy is configured as the result backend, celery automatically creates
# two tables to store result meta-data for tasks. this setting allows you to customize
# the schema of the tables.
# for example:
# {
#    "task": "custom_schema_name",
#    "group": "custom_schema_name"
# }
# defaults to an empty dict.
database_table_schemas: {}

# when sqlalchemy is configured as the result backend, celery automatically creates two
# tables to store result meta-data for tasks. this setting allows you to customize the
# table names. for example:
# {
#    "task": "custom_table_name",
#    "group": "custom_table_name",
# }
# defaults to an empty dict.
database_table_names: {}

# short lived sessions are disabled by default. if enabled they can drastically
# reduce performance, especially on systems processing lots of tasks. this option
# is useful on low-traffic workers that experience errors as a result of cached
# database connections going stale through inactivity. for example, intermittent
# errors like (OperationalError) (2006, 'mysql server has gone away') can be fixed
# by enabling short lived sessions. this option only affects the database backend.
# defaults to false.
database_short_lived_sessions: false

# whether to store the task return values or not (tombstones).
# if you still want to store errors, just not successful return values, you
# can set 'task_store_errors_even_if_ignored' to true.
# defaults to false.
task_ignore_result: false

# if set, the worker stores all task errors in the result store
# even if 'task_ignore_result' is true.
# defaults to false.
task_store_errors_even_if_ignored: false

# if true the task will report its status as 'started' when the task is executed
# by a worker. the default value is false as the normal behavior is to not report
# that level of granularity. tasks are either pending, finished, or waiting to be
# retried. having a 'started' state can be useful for when there are long running
# tasks and there's a need to report what task is currently running.
# defaults to false.
task_track_started: false

# default compression used for task messages. can be gzip, bzip2 (if available), or any
# custom compression schemes registered in the kombu compression registry.
# default is null and no compression will be applied.
task_compression: null

# set the default task message protocol version used to send tasks.
# supported protocols are 1 and 2.
# protocol 2 is supported by 3.1.24 and 4.x+.
# defaults to 2.
task_protocol: 2

# a string identifying the default serialization method to use. can be
# json (default), pickle, yaml, msgpack, or any custom serialization methods
# that have been registered with 'kombu.serialization.registry'.
# defaults to 'json'.
task_serializer: json

# if this is true, all tasks will be executed locally by blocking until the
# task returns. apply_async() and task.delay() will return an EagerResult
# instance, that emulates the api and behavior of AsyncResult, except the
# result is already evaluated. that is, tasks will be executed locally
# instead of being sent to the queue.
# defaults to false.
task_always_eager: false

# if this is true, eagerly executed tasks (applied by task.apply(), or when the
# 'task_always_eager' setting is enabled), will propagate exceptions.
# it's the same as always running apply() with throw=True.
# defaults to false.
task_eager_propagates: false

# if enabled task results will include the workers stack when re-raising task errors.
# this requires the 'tblib' library, that can be installed using pip:
# pip install celery[tblib]
# defaults to false.
task_remote_tracebacks: false

# task hard time limit in seconds. the worker processing the task
# will be killed and replaced with a new one when this is exceeded.
# defaults to null and has no limit.
task_time_limit: null

# task soft time limit in seconds.
# the 'SoftTimeLimitExceeded' exception will be raised when this is exceeded.
# for example, the task can catch this to clean up before the hard time limit comes.
# defaults to null and has no soft limit.
task_soft_time_limit: null

# late ack means the task messages will be acknowledged after the
# task has been executed, not just before.
# defaults to false.
task_acks_late: false

# when enabled messages for all tasks will be acknowledged even if they fail or time out.
# configuring this setting only applies to tasks that are acknowledged after they have
# been executed and only if 'task_acks_late' is enabled.
# defaults to true.
task_acks_on_failure_or_timeout: true

# even if 'task_acks_late' is enabled, the worker will acknowledge tasks when the
# worker process executing them abruptly exits or is signaled (e.g., kill/int, etc).
# setting this to true allows the message to be re-queued instead, so that the task
# will execute again by the same worker, or another worker.
# defaults to false.
task_reject_on_worker_lost: false

# the global default rate limit for tasks.
# this value is used for tasks that doesn't have a custom rate limit.
# defaults to null and has no rate limit.
task_default_rate_limit: null

# if enabled (default), any queues specified that aren't defined in
# 'task_queues' will be automatically created.
# defaults to true.
task_create_missing_queues: true

# can be transient (messages not written to disk) or persistent (written to disk).
# defaults to 'persistent'.
task_default_delivery_mode: persistent

# the name of the default queue used by 'apply_async' if the message has no route
# or no custom queue has been specified. this queue must be listed in 'task_queues'.
# if 'task_queues' isn't specified then it's automatically created containing one queue
# entry, where this name is used as the name of that queue.
# defaults to 'celery'.
task_default_queue: celery

# name of the default exchange to use when no custom exchange is
# specified for a key in the 'task_queues' setting.
# defaults to the value set for 'task_default_queue'.
### task_default_exchange: null

# default exchange type used when no custom exchange type is specified
# for a key in the 'task_queues' setting.
# defaults to 'direct'.
task_default_exchange_type: direct

# the default routing key used when no custom routing key is specified
# for a key in the task_queues setting.
# defaults to the value set for 'task_default_queue'.
### task_default_routing_key: null

# decides if publishing task messages will be retried in the case of connection
# loss or other connection errors. see also 'task_publish_retry_policy'.
# defaults to true.
task_publish_retry: true

# defines the default policy when retrying publishing a task message in
# the case of connection loss or other connection errors.
# it must be a dict and could contain these keys:
# max_retries, interval_start, interval_step and interval_max.
# for example:
# {
#    "max_retries": 3,
#    "interval_start": 0,
#    "interval_step": 0.2,
#    "interval_max": 0.2,
# }
### task_publish_retry_policy: {}

# a default max priority for all queues.
# it is only for rabbitmq.
# defaults to null.
task_queue_max_priority: null

# a default priority for all tasks.
# it is only for rabbitmq.
# defaults to null.
task_default_priority: null

# if enabled, child tasks will inherit priority of the parent task.
# it is only for rabbitmq.
# defaults to false.
task_inherit_parent_priority: false

# most users will not want to specify this setting and should rather use
# the automatic routing facilities. if you really want to configure advanced
# routing, this setting should be a list of 'kombu.Queue' objects the worker will
# consume from.
# if you want to set this, you must extend celery package of pyrin in your application
# and provide required configurations to it.
### task_queues: null

# if enabled, a task-sent event will be sent for every task so tasks can be
# tracked before they're consumed by a worker.
# defaults to false.
task_send_sent_event: false

# a white-list of content-types/serializers to allow.
# if a message is received that's not in this list then
# the message will be discarded with an error.
# it could be any content type such as pickle and yaml.
# defaults to ['json'].
accept_content: [json]

# if enabled dates and times in messages will be converted to use the utc timezone.
# defaults to true.
enable_utc: true

# a sequence of modules to import when the worker starts.
# this is used to specify the task modules to import, but also
# to import signal handlers and additional remote control commands, etc.
imports: []

# exact same semantics as imports, but can be used as a
# means to have different import categories.
# the modules in this setting are imported after the modules in imports.
include: []

# configure celery to use a custom time zone. the timezone value can
# be any time zone supported by the pytz library.
# if not set the utc timezone is used. for backwards compatibility there's
# also a enable_utc setting, and when this is set to false the system local
# timezone is used instead.
timezone: UTC

# the default scheduler class.
# defaults to 'celery.beat:PersistentScheduler'.
beat_scheduler: celery.beat:PersistentScheduler

# the periodic task schedule used by beat.
# defaults to an empty dict.
beat_schedule: {}

# name of the file used by PersistentScheduler to store the last run times of
# periodic tasks. can be a relative or absolute path, but be aware that the
# suffix .db may be appended to the file name (depending on python version).
# defaults to 'celerybeat-schedule'.
beat_schedule_filename: celerybeat-schedule

# the number of periodic tasks that can be called before another database sync
# is issued. a value of 0 (default) means sync based on timing - default of 3 minutes
# as determined by scheduler.sync_every. if set to 1, beat will call sync after every
# task message sent. defaults to 0.
beat_sync_every: 0

# the maximum number of seconds beat can sleep between checking the schedule.
# the default for this value is scheduler specific. for the default celery beat
# scheduler the value is 300 (5 minutes), but for the django-celery-beat database
# scheduler it's 5 seconds because the schedule may be changed externally, and so
# it must take changes to the schedule into account.
# only uncomment if you know what it is.
### beat_max_loop_interval: 0

# path to a file to store process id of beat process.
# note that if this file is existed and the process is active, beat process will not start.
beat_pid_file: null

# path to a file to put beat logs into it.
beat_log_file: null

# beat log level. it could be one of:
# 'DEBUG', 'INFO', 'WARNING', 'ERROR', or 'CRITICAL'.
# defaults to 'WARNING'.
beat_log_level: WARNING

# to enable message signing you should configure the 'task_serializer' setting to use
# the 'auth' serializer. enforcing the workers to only accept signed messages, you
# should set 'accept_content' to ['auth']. for additional signing of the event protocol,
# set 'event_serializer' to 'auth'. also required is configuring the paths used to
# locate private keys and certificates on the file-system: the 'security_key',
# 'security_certificate' and 'security_cert_store' settings respectively.
# you can tweak the signing algorithm with 'security_digest'.

# the relative or absolute path to a file containing the private key
# used to sign messages when message signing is used.
# defaults to null.
security_key: null

# the relative or absolute path to an x.509 certificate file
# used to sign messages when message signing is used.
# defaults to null.
security_certificate: null

# the directory containing x.509 certificates used for message signing.
# can be a glob with wild-cards, (for example /etc/certs/*.pem).
# defaults to null.
security_cert_store: null

# a cryptography digest used to sign messages when message signing is used.
# defaults to 'sha256'.
security_digest: sha256

# message serialization format used when sending event messages.
# defaults to 'json'.
event_serializer: json

# name of the autoscaler class to use.
# defaults to 'celery.worker.autoscale:Autoscaler'.
worker_autoscaler: celery.worker.autoscale:Autoscaler

# the number of concurrent worker processes/threads/green threads executing tasks.
# if you're doing mostly I/O you can have more processes, but if mostly cpu-bound, try to
# keep it close to the number of cpus on your machine. if not set, the number of cpus/cores
# on the host will be used.
# defaults to null and will use the number of cpus/cores of host machine.
worker_concurrency: null

# name of the consumer class used by the worker.
# defaults to 'celery.worker.consumer:Consumer'.
worker_consumer: celery.worker.consumer:Consumer

# specify if remote control of the workers is enabled.
# defaults to true.
worker_enable_remote_control: true

# name of the pool class used by the worker.
# defaults to 'celery.concurrency.prefork:TaskPool'.
worker_pool: celery.concurrency.prefork:TaskPool

# if enabled the worker pool can be restarted using the 'pool_restart' remote control command.
# defaults to false.
worker_pool_restarts: false

# how many messages to prefetch at a time multiplied by the number of concurrent processes.
# the default is 4 (four messages for each process). the default setting is usually a good
# choice. however if you have very long running tasks waiting in the queue and you have to
# start the workers, note that the first worker to start will receive four times the number
# of messages initially. thus the tasks may not be fairly distributed to the workers.
# to disable prefetching, set worker_prefetch_multiplier to 1. changing that setting
# to 0 will allow the worker to keep consuming as many messages as it wants.
# defaults to 4.
worker_prefetch_multiplier: 4

# if enabled stdout and stderr will be redirected to the current logger.
# used by celery worker and celery beat.
# defaults to true.
worker_redirect_stdouts: true

# the log level output to stdout and stderr is logged as.
# can be one of 'DEBUG', 'INFO', 'WARNING', 'ERROR', or 'CRITICAL'.
# defaults to 'WARNING'.
worker_redirect_stdouts_level: WARNING

# send task-related events so that tasks can be monitored using tools like flower.
# sets the default value for the workers -E argument.
# defaults to false.
worker_send_task_events: false

# enables/disables colors in logging output by the celery apps.
# defaults to true if the app is logging to a terminal.
worker_log_color: true

# name of the file used to stores persistent worker state (like revoked tasks).
# can be a relative or absolute path, but be aware that the suffix '.db' may be
# appended to the file name (depending on python version).
# defaults to null.
worker_state_db: null

# name of the eta scheduler class used by the worker.
# default is or set by the pool implementation.
# defaults to 'kombu.asynchronous.hub.timer:Timer'.
worker_timer: kombu.asynchronous.hub.timer:Timer

# set the maximum time in seconds that the eta scheduler can sleep between
# rechecking the schedule. setting this value to 1 second means the schedulers
# precision will be 1 second. if you need near millisecond precision you can set this to 0.1.
# defaults to 1 second.
worker_timer_precision: 1

# disable all rate limits, even if tasks has explicit rate limits set.
# defaults to false.
worker_disable_rate_limits: false

# maximum amount of resident memory, in kilobytes, that may be consumed by a
# worker before it will be replaced by a new worker. if a single task causes a
# worker to exceed this limit, the task will be completed, and the worker will
# be replaced afterwards.
# defaults to null and has no limit.
worker_max_memory_per_child: null

# maximum number of tasks a pool worker process can execute before
# it's replaced with a new one. defaults to null and has no limit.
worker_max_tasks_per_child: null

# in some cases a worker may be killed without proper cleanup, and the worker may have
# published a result before terminating. this value specifies how long we wait for any
# missing results before raising a 'WorkerLostError' exception.
# defaults to 10 seconds.
worker_lost_wait: 10

# this option enables so that every worker has a dedicated queue, so that tasks
# can be routed to specific workers. the queue name for each worker is automatically
# generated based on the worker hostname and a '.dq' suffix, using the 'C.dq' exchange.
worker_direct: false

# path to a file to store process id of worker.
# note that if this file is existed and the process is active, worker will not start.
worker_pid_file: null

# path to a file to put worker logs into it.
worker_log_file: null

# worker log level. it could be one of:
# 'DEBUG', 'INFO', 'WARNING', 'ERROR', or 'CRITICAL'.
# defaults to 'WARNING'.
worker_log_level: WARNING

# max and min processes to use for autoscaling. in the form of:
# max_process_count, min_process_count, for example 10,3.
worker_autoscale: null

# a hostname to be used for worker node.
# note that if you want to start multiple worker nodes on the same
# machine, you must set different hostnames for each one.
worker_hostname: null

# list of queues to enable for worker.
# it must contain queue names separated by comma.
# for example: images,videos
worker_queues: null

# optimization profile to be applied.
# could be from: 'default' and 'fair'.
# defaults to null.
worker_optimization: null

[test]

# default broker url. this must be a url in the form of:
# transport://userid:password@hostname:port/virtual_host
# for example with amqp transport:
# amqp://amqp:5672/
# only the scheme part (transport://) is required, the rest is
# optional, and defaults to the specific transports default values.
# the transport part is the broker implementation to use, and the default
# is amqp, (uses librabbitmq if installed or falls back to pyamqp). there are also
# other choices available, including: 'redis://', 'sqs://' and 'qpid://'.
# the scheme can also be a fully qualified path to your own transport implementation:
# 'proj.transports.MyTransport://localhost'
# more than one broker url, of the same transport, can also be specified.
# the broker urls can be passed in as a single string that's semicolon delimited:
# 'transport://userid:password@hostname:port//;transport://userid:password@hostname:port//'
# or as a list:
# ['transport://userid:password@localhost:port//',
#  'transport://userid:password@hostname:port//']
# the brokers will then be used in the 'broker_failover_strategy'.
broker_url: null

# a dict of additional options passed to the underlying transport.
# see your transport user manual for supported options (if any).
# example setting the visibility timeout (supported by redis and sqs transports):
# {"visibility_timeout": 18000} (5 hours)
# example setting the producer connection maximum number of retries (so producers
# won't retry forever if the broker isn't available at the first task execution):
# {"max_retries": 2}
broker_transport_options: {"max_retries": 2}

# the default timeout in seconds before we give up establishing a
# connection to the amqp server. this setting is disabled when using gevent.
# defaults to 4 seconds.
broker_connection_timeout: 4

# automatically try to re-establish the connection to the amqp broker if lost.
# the time between retries is increased for each retry, and is not exhausted before
# 'broker_connection_max_retries' is exceeded.
# defaults to true.
broker_connection_retry: true

# maximum number of retries before we give up re-establishing a connection
# to the amqp broker. if this is set to 0 or null, we'll retry forever.
# defaults to 20.
broker_connection_max_retries: 20

# default failover strategy for the broker connection object. if supplied, may map
# to a key in 'kombu.connection.failover_strategies', or be a reference to any method
# that yields a single item from a supplied list.
# defaults to 'round-robin'.
broker_failover_strategy: round-robin

# set custom amqp login method.
# defaults to 'AMQPLAIN'.
broker_login_method: AMQPLAIN

# the maximum number of connections that can be open in the connection pool.
# the pool is enabled by default since version 2.5, with a default limit of ten
# connections. this number can be tweaked depending on the number of threads/green-threads
# (eventlet/gevent) using a connection. for example running eventlet with 1000 greenlets
# that use a connection to the broker, contention can arise and you should consider
# increasing the limit. if set to null or 0 the connection pool will be disabled and
# connections will be established and closed for every use.
# defaults to 10.
broker_pool_limit: 10

# toggles ssl usage on broker connection and ssl settings.
# the valid values for this option vary by transport.
# supported transports are 'pyamqp' and 'redis'.
# defaults to false.
# if set to true and transport is 'pyamqp' the connection will use ssl with default ssl settings.
# if set to a dict, will configure ssl connection according to the specified policy. the format
# used is python's ssl.wrap_socket() options. note that ssl socket is generally served on a
# separate port by the broker.
# sample for 'pyamqp':
# {
#  "keyfile": "/var/ssl/private/worker-key.pem",
#  "certfile": "/var/ssl/amqp-server-cert.pem",
#  "ca_certs": "/var/ssl/myca.pem",
#  "cert_reqs": ssl.CERT_REQUIRED
# }
# if set to true and transport is 'redis' the setting must be a dict with the following keys:
# ssl_cert_reqs (required): one of the 'SSLContext.verify_mode' values:
# 'ssl.CERT_NONE', 'ssl.CERT_OPTIONAL' or 'ssl.CERT_REQUIRED'.
# ssl_ca_certs (optional): path to the CA certificate.
# ssl_certfile (optional): path to the client certificate.
# ssl_keyfile (optional): path to the client key.
broker_use_ssl: false

# these settings can be configured, instead of 'broker_url' to specify
# different connection parameters for broker connections used for consuming and producing.
# both options can also be specified as a list for failover alternates.
# see 'broker_url' for more information.
### broker_read_url: null
### broker_write_url: null

# this value is only used by the worker, clients do not use a heartbeat at the moment.
# it's not always possible to detect connection loss in a timely manner using tcp/ip
# alone, so amqp defines something called heartbeats that's is used both by the client and
# the broker to detect if a connection was closed. if the heartbeat value is 10 seconds,
# then the heartbeat will be monitored at the interval specified by the
# 'broker_heartbeat_checkrate' setting (by default this is set to double the rate of
# the heartbeat value, so for the 10 seconds, the heartbeat is checked every 5 seconds).
# this could only be enabled on 'pyamqp' transport.
# defaults to 120. only uncomment if you know what it is.
### broker_heartbeat: 120

# at intervals the worker will monitor that the broker hasn't missed too many heartbeats.
# the rate at which this is checked is calculated by dividing the 'broker_heartbeat' value
# with this value, so if the heartbeat is 10.0 and the rate is the default 2.0, the check
# will be performed every 5 seconds (twice the heartbeat sending rate).
# this could only be enabled on 'pyamqp' transport.
# defaults to 2. only uncomment if you know what it is.
### broker_heartbeat_checkrate: 2

# the backend used to store task results (tombstones).
# could be one of the following:
# rpc, database, redis, cache, mongodb, cassandra, elasticsearch, ironcache,
# couchbase, arangodb, couchdb, cosmosdbsql, filesystem, consul, azureblockblob, s3.
# defaults to null and no backend is enabled.
# to use the database backend you have to configure the 'result_backend' setting with a
# connection url and the 'db+' prefix: 'db+scheme://user:password@host:port/dbname'.
# example connections for different databases:
# sqlite: 'db+sqlite:///results.sqlite'
# mysql: 'db+mysql://scott:tiger@localhost/foo'
# postgresql: 'db+postgresql://scott:tiger@localhost/mydatabase'
# oracle: 'db+oracle://scott:tiger@127.0.0.1:1521/sidname'
result_backend: null

# if set to true, result messages will be persistent.
# this means the messages won't be lost after a broker restart.
# this needs the 'result_backed' to be enabled too.
# defaults to false.
result_persistent: false

# optional compression method used for task results.
# can be gzip, bzip2 (if available), or any custom compression schemes
# registered in the kombu compression registry.
# default is null and no compression will be applied.
result_compression: null

# time (in seconds, or a timedelta object) for when after stored task
# tombstones will be deleted. a built-in periodic task will delete the results
# after this time (celery.backend_cleanup), assuming that celery beat is enabled.
# the task runs daily at 4am. a value of null or 0 means results will never
# expire (depending on backend specifications).
# defaults to 1 day (86400 seconds).
result_expires: 86400

# result serialization format.
# defaults to 'json'.
result_serializer: json

# enables extended task result attributes (name, args, kwargs, worker,
# retries, queue, delivery_info) to be written to backend.
# defaults to false.
result_extended: false

# to specify additional sqlalchemy database engine options you can use this setting.
# for example: {"echo": true}.
# defaults to an empty dict.
database_engine_options: {}

# when sqlalchemy is configured as the result backend, celery automatically creates
# two tables to store result meta-data for tasks. this setting allows you to customize
# the schema of the tables.
# for example:
# {
#    "task": "custom_schema_name",
#    "group": "custom_schema_name"
# }
# defaults to an empty dict.
database_table_schemas: {}

# when sqlalchemy is configured as the result backend, celery automatically creates two
# tables to store result meta-data for tasks. this setting allows you to customize the
# table names. for example:
# {
#    "task": "custom_table_name",
#    "group": "custom_table_name",
# }
# defaults to an empty dict.
database_table_names: {}

# short lived sessions are disabled by default. if enabled they can drastically
# reduce performance, especially on systems processing lots of tasks. this option
# is useful on low-traffic workers that experience errors as a result of cached
# database connections going stale through inactivity. for example, intermittent
# errors like (OperationalError) (2006, 'mysql server has gone away') can be fixed
# by enabling short lived sessions. this option only affects the database backend.
# defaults to false.
database_short_lived_sessions: false

# whether to store the task return values or not (tombstones).
# if you still want to store errors, just not successful return values, you
# can set 'task_store_errors_even_if_ignored' to true.
# defaults to false.
task_ignore_result: false

# if set, the worker stores all task errors in the result store
# even if 'task_ignore_result' is true.
# defaults to false.
task_store_errors_even_if_ignored: false

# if true the task will report its status as 'started' when the task is executed
# by a worker. the default value is false as the normal behavior is to not report
# that level of granularity. tasks are either pending, finished, or waiting to be
# retried. having a 'started' state can be useful for when there are long running
# tasks and there's a need to report what task is currently running.
# defaults to false.
task_track_started: false

# default compression used for task messages. can be gzip, bzip2 (if available), or any
# custom compression schemes registered in the kombu compression registry.
# default is null and no compression will be applied.
task_compression: null

# set the default task message protocol version used to send tasks.
# supported protocols are 1 and 2.
# protocol 2 is supported by 3.1.24 and 4.x+.
# defaults to 2.
task_protocol: 2

# a string identifying the default serialization method to use. can be
# json (default), pickle, yaml, msgpack, or any custom serialization methods
# that have been registered with 'kombu.serialization.registry'.
# defaults to 'json'.
task_serializer: json

# if this is true, all tasks will be executed locally by blocking until the
# task returns. apply_async() and task.delay() will return an EagerResult
# instance, that emulates the api and behavior of AsyncResult, except the
# result is already evaluated. that is, tasks will be executed locally
# instead of being sent to the queue.
# defaults to false.
task_always_eager: false

# if this is true, eagerly executed tasks (applied by task.apply(), or when the
# 'task_always_eager' setting is enabled), will propagate exceptions.
# it's the same as always running apply() with throw=True.
# defaults to false.
task_eager_propagates: false

# if enabled task results will include the workers stack when re-raising task errors.
# this requires the 'tblib' library, that can be installed using pip:
# pip install celery[tblib]
# defaults to false.
task_remote_tracebacks: false

# task hard time limit in seconds. the worker processing the task
# will be killed and replaced with a new one when this is exceeded.
# defaults to null and has no limit.
task_time_limit: null

# task soft time limit in seconds.
# the 'SoftTimeLimitExceeded' exception will be raised when this is exceeded.
# for example, the task can catch this to clean up before the hard time limit comes.
# defaults to null and has no soft limit.
task_soft_time_limit: null

# late ack means the task messages will be acknowledged after the
# task has been executed, not just before.
# defaults to false.
task_acks_late: false

# when enabled messages for all tasks will be acknowledged even if they fail or time out.
# configuring this setting only applies to tasks that are acknowledged after they have
# been executed and only if 'task_acks_late' is enabled.
# defaults to true.
task_acks_on_failure_or_timeout: true

# even if 'task_acks_late' is enabled, the worker will acknowledge tasks when the
# worker process executing them abruptly exits or is signaled (e.g., kill/int, etc).
# setting this to true allows the message to be re-queued instead, so that the task
# will execute again by the same worker, or another worker.
# defaults to false.
task_reject_on_worker_lost: false

# the global default rate limit for tasks.
# this value is used for tasks that doesn't have a custom rate limit.
# defaults to null and has no rate limit.
task_default_rate_limit: null

# if enabled (default), any queues specified that aren't defined in
# 'task_queues' will be automatically created.
# defaults to true.
task_create_missing_queues: true

# can be transient (messages not written to disk) or persistent (written to disk).
# defaults to 'persistent'.
task_default_delivery_mode: persistent

# the name of the default queue used by 'apply_async' if the message has no route
# or no custom queue has been specified. this queue must be listed in 'task_queues'.
# if 'task_queues' isn't specified then it's automatically created containing one queue
# entry, where this name is used as the name of that queue.
# defaults to 'celery'.
task_default_queue: celery

# name of the default exchange to use when no custom exchange is
# specified for a key in the 'task_queues' setting.
# defaults to the value set for 'task_default_queue'.
### task_default_exchange: null

# default exchange type used when no custom exchange type is specified
# for a key in the 'task_queues' setting.
# defaults to 'direct'.
task_default_exchange_type: direct

# the default routing key used when no custom routing key is specified
# for a key in the task_queues setting.
# defaults to the value set for 'task_default_queue'.
### task_default_routing_key: null

# decides if publishing task messages will be retried in the case of connection
# loss or other connection errors. see also 'task_publish_retry_policy'.
# defaults to true.
task_publish_retry: true

# defines the default policy when retrying publishing a task message in
# the case of connection loss or other connection errors.
# it must be a dict and could contain these keys:
# max_retries, interval_start, interval_step and interval_max.
# for example:
# {
#    "max_retries": 3,
#    "interval_start": 0,
#    "interval_step": 0.2,
#    "interval_max": 0.2,
# }
### task_publish_retry_policy: {}

# a default max priority for all queues.
# it is only for rabbitmq.
# defaults to null.
task_queue_max_priority: null

# a default priority for all tasks.
# it is only for rabbitmq.
# defaults to null.
task_default_priority: null

# if enabled, child tasks will inherit priority of the parent task.
# it is only for rabbitmq.
# defaults to false.
task_inherit_parent_priority: false

# most users will not want to specify this setting and should rather use
# the automatic routing facilities. if you really want to configure advanced
# routing, this setting should be a list of 'kombu.Queue' objects the worker will
# consume from.
# if you want to set this, you must extend celery package of pyrin in your application
# and provide required configurations to it.
### task_queues: null

# if enabled, a task-sent event will be sent for every task so tasks can be
# tracked before they're consumed by a worker.
# defaults to false.
task_send_sent_event: false

# a white-list of content-types/serializers to allow.
# if a message is received that's not in this list then
# the message will be discarded with an error.
# it could be any content type such as pickle and yaml.
# defaults to ['json'].
accept_content: [json]

# if enabled dates and times in messages will be converted to use the utc timezone.
# defaults to true.
enable_utc: true

# a sequence of modules to import when the worker starts.
# this is used to specify the task modules to import, but also
# to import signal handlers and additional remote control commands, etc.
imports: []

# exact same semantics as imports, but can be used as a
# means to have different import categories.
# the modules in this setting are imported after the modules in imports.
include: []

# configure celery to use a custom time zone. the timezone value can
# be any time zone supported by the pytz library.
# if not set the utc timezone is used. for backwards compatibility there's
# also a enable_utc setting, and when this is set to false the system local
# timezone is used instead.
timezone: UTC

# the default scheduler class.
# defaults to 'celery.beat:PersistentScheduler'.
beat_scheduler: celery.beat:PersistentScheduler

# the periodic task schedule used by beat.
# defaults to an empty dict.
beat_schedule: {}

# name of the file used by PersistentScheduler to store the last run times of
# periodic tasks. can be a relative or absolute path, but be aware that the
# suffix .db may be appended to the file name (depending on python version).
# defaults to 'celerybeat-schedule'.
beat_schedule_filename: celerybeat-schedule

# the number of periodic tasks that can be called before another database sync
# is issued. a value of 0 (default) means sync based on timing - default of 3 minutes
# as determined by scheduler.sync_every. if set to 1, beat will call sync after every
# task message sent. defaults to 0.
beat_sync_every: 0

# the maximum number of seconds beat can sleep between checking the schedule.
# the default for this value is scheduler specific. for the default celery beat
# scheduler the value is 300 (5 minutes), but for the django-celery-beat database
# scheduler it's 5 seconds because the schedule may be changed externally, and so
# it must take changes to the schedule into account.
# only uncomment if you know what it is.
### beat_max_loop_interval: 0

# path to a file to store process id of beat process.
# note that if this file is existed and the process is active, beat process will not start.
beat_pid_file: null

# path to a file to put beat logs into it.
beat_log_file: null

# beat log level. it could be one of:
# 'DEBUG', 'INFO', 'WARNING', 'ERROR', or 'CRITICAL'.
# defaults to 'WARNING'.
beat_log_level: WARNING

# to enable message signing you should configure the 'task_serializer' setting to use
# the 'auth' serializer. enforcing the workers to only accept signed messages, you
# should set 'accept_content' to ['auth']. for additional signing of the event protocol,
# set 'event_serializer' to 'auth'. also required is configuring the paths used to
# locate private keys and certificates on the file-system: the 'security_key',
# 'security_certificate' and 'security_cert_store' settings respectively.
# you can tweak the signing algorithm with 'security_digest'.

# the relative or absolute path to a file containing the private key
# used to sign messages when message signing is used.
# defaults to null.
security_key: null

# the relative or absolute path to an x.509 certificate file
# used to sign messages when message signing is used.
# defaults to null.
security_certificate: null

# the directory containing x.509 certificates used for message signing.
# can be a glob with wild-cards, (for example /etc/certs/*.pem).
# defaults to null.
security_cert_store: null

# a cryptography digest used to sign messages when message signing is used.
# defaults to 'sha256'.
security_digest: sha256

# message serialization format used when sending event messages.
# defaults to 'json'.
event_serializer: json

# name of the autoscaler class to use.
# defaults to 'celery.worker.autoscale:Autoscaler'.
worker_autoscaler: celery.worker.autoscale:Autoscaler

# the number of concurrent worker processes/threads/green threads executing tasks.
# if you're doing mostly I/O you can have more processes, but if mostly cpu-bound, try to
# keep it close to the number of cpus on your machine. if not set, the number of cpus/cores
# on the host will be used.
# defaults to null and will use the number of cpus/cores of host machine.
worker_concurrency: null

# name of the consumer class used by the worker.
# defaults to 'celery.worker.consumer:Consumer'.
worker_consumer: celery.worker.consumer:Consumer

# specify if remote control of the workers is enabled.
# defaults to true.
worker_enable_remote_control: true

# name of the pool class used by the worker.
# defaults to 'celery.concurrency.prefork:TaskPool'.
worker_pool: celery.concurrency.prefork:TaskPool

# if enabled the worker pool can be restarted using the 'pool_restart' remote control command.
# defaults to false.
worker_pool_restarts: false

# how many messages to prefetch at a time multiplied by the number of concurrent processes.
# the default is 4 (four messages for each process). the default setting is usually a good
# choice. however if you have very long running tasks waiting in the queue and you have to
# start the workers, note that the first worker to start will receive four times the number
# of messages initially. thus the tasks may not be fairly distributed to the workers.
# to disable prefetching, set worker_prefetch_multiplier to 1. changing that setting
# to 0 will allow the worker to keep consuming as many messages as it wants.
# defaults to 4.
worker_prefetch_multiplier: 4

# if enabled stdout and stderr will be redirected to the current logger.
# used by celery worker and celery beat.
# defaults to true.
worker_redirect_stdouts: true

# the log level output to stdout and stderr is logged as.
# can be one of 'DEBUG', 'INFO', 'WARNING', 'ERROR', or 'CRITICAL'.
# defaults to 'WARNING'.
worker_redirect_stdouts_level: WARNING

# send task-related events so that tasks can be monitored using tools like flower.
# sets the default value for the workers -E argument.
# defaults to false.
worker_send_task_events: false

# enables/disables colors in logging output by the celery apps.
# defaults to true if the app is logging to a terminal.
worker_log_color: true

# name of the file used to stores persistent worker state (like revoked tasks).
# can be a relative or absolute path, but be aware that the suffix '.db' may be
# appended to the file name (depending on python version).
# defaults to null.
worker_state_db: null

# name of the eta scheduler class used by the worker.
# default is or set by the pool implementation.
# defaults to 'kombu.asynchronous.hub.timer:Timer'.
worker_timer: kombu.asynchronous.hub.timer:Timer

# set the maximum time in seconds that the eta scheduler can sleep between
# rechecking the schedule. setting this value to 1 second means the schedulers
# precision will be 1 second. if you need near millisecond precision you can set this to 0.1.
# defaults to 1 second.
worker_timer_precision: 1

# disable all rate limits, even if tasks has explicit rate limits set.
# defaults to false.
worker_disable_rate_limits: false

# maximum amount of resident memory, in kilobytes, that may be consumed by a
# worker before it will be replaced by a new worker. if a single task causes a
# worker to exceed this limit, the task will be completed, and the worker will
# be replaced afterwards.
# defaults to null and has no limit.
worker_max_memory_per_child: null

# maximum number of tasks a pool worker process can execute before
# it's replaced with a new one. defaults to null and has no limit.
worker_max_tasks_per_child: null

# in some cases a worker may be killed without proper cleanup, and the worker may have
# published a result before terminating. this value specifies how long we wait for any
# missing results before raising a 'WorkerLostError' exception.
# defaults to 10 seconds.
worker_lost_wait: 10

# this option enables so that every worker has a dedicated queue, so that tasks
# can be routed to specific workers. the queue name for each worker is automatically
# generated based on the worker hostname and a '.dq' suffix, using the 'C.dq' exchange.
worker_direct: false

# path to a file to store process id of worker.
# note that if this file is existed and the process is active, worker will not start.
worker_pid_file: null

# path to a file to put worker logs into it.
worker_log_file: null

# worker log level. it could be one of:
# 'DEBUG', 'INFO', 'WARNING', 'ERROR', or 'CRITICAL'.
# defaults to 'WARNING'.
worker_log_level: WARNING

# max and min processes to use for autoscaling. in the form of:
# max_process_count, min_process_count, for example 10,3.
worker_autoscale: null

# a hostname to be used for worker node.
# note that if you want to start multiple worker nodes on the same
# machine, you must set different hostnames for each one.
worker_hostname: null

# list of queues to enable for worker.
# it must contain queue names separated by comma.
# for example: images,videos
worker_queues: null

# optimization profile to be applied.
# could be from: 'default' and 'fair'.
# defaults to null.
worker_optimization: null
