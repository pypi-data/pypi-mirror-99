{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmagpy.pmag as pmag\n",
    "import pmagpy.pmagplotlib as pmagplotlib\n",
    "import pmagpy.ipmag as ipmag\n",
    "import pmagpy.contribution_builder as cb\n",
    "from pmagpy import convert_2_magic as convert\n",
    "import matplotlib.pyplot as plt # our plotting buddy\n",
    "import numpy as np # the fabulous NumPy package\n",
    "import pandas as pd # and of course Pandas\n",
    "# test if Basemap and/or cartopy is installed\n",
    "has_basemap, Basemap = pmag.import_basemap()\n",
    "has_cartopy, Cartopy = pmag.import_cartopy()\n",
    "# This allows you to make matplotlib plots inside the notebook.  \n",
    "%matplotlib inline \n",
    "from IPython.display import Image\n",
    "import os\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "from pmagpy.mapping import map_magic    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sites_extract(site_file='sites.txt',directions_file='directions.xls',\n",
    "                  intensity_file='intensity.xls',info_file='site_info.xls',\n",
    "                  output_dir_path='./',input_dir_path='./',latex=False):\n",
    "    \"\"\"\n",
    "    Extracts directional and/or intensity data from a MagIC 3.0 format sites.txt file.\n",
    "    Default output format is an Excel file. \n",
    "    Optional latex format longtable file which can be uploaded to Overleaf or \n",
    "    typeset with latex on your own computer.  \n",
    "    \n",
    "    Parameters\n",
    "    ___________\n",
    "    site_file : str\n",
    "         input file name\n",
    "    directions_file : str\n",
    "          output file name for directional data\n",
    "    intensity_file : str\n",
    "          output file name for intensity data\n",
    "    site_info : str\n",
    "          output file name for site information (lat, lon, location, age....)\n",
    "    output_dir_path : str\n",
    "          path for output files\n",
    "    input_dir_path : str\n",
    "          path for intput file if different from output_dir_path (default is same)\n",
    "    latex : boolean\n",
    "           if True, output file should be latex formatted table with a .tex ending\n",
    "           \n",
    "    Return :\n",
    "        [True,False], error type : True if successful\n",
    "        \n",
    "    Effects : \n",
    "        writes cvs or latex formatted tables for use in publications\n",
    "    \"\"\"\n",
    "    if not input_dir_path:\n",
    "        input_dir_path = output_dir_path\n",
    "    try:\n",
    "        fname = pmag.resolve_file_name(site_file, input_dir_path)\n",
    "    except IOError:\n",
    "        print(\"bad site file name\")\n",
    "        return False, \"bad site file name\"\n",
    "    sites_df=pd.read_csv(fname,sep='\\t',header=1)\n",
    "# do directional stuff first\n",
    "    # a few things need cleaning up\n",
    "    dir_df=sites_df.dropna(subset=['dir_dec','dir_inc']) # delete blank directions\n",
    "    # sort by absolute value of vgp_lat in order to eliminate duplicate rows for\n",
    "    # directions put in by accident on intensity rows\n",
    "    if len(dir_df)>0:\n",
    "\n",
    "        DirCols = [\"Site\", \"TC (%)\", \"Dec.\", \"Inc.\", \"N\", \"k    \", \"R\", \"a95\"]\n",
    "\n",
    "        dir_file=pmag.resolve_file_name(directions_file,output_dir_path)\n",
    "        dir_df['dir_n_samples']=dir_df['dir_n_samples'].values.astype('int')\n",
    "        dir_df['dir_tilt_correction']=dir_df['dir_tilt_correction'].values.astype('int')\n",
    "        has_vgps=False\n",
    "        if 'vgp_lat' in dir_df.columns:\n",
    "            test_vgp=dir_df.dropna(subset=['vgp_lat','vgp_lon'])\n",
    "            if len(test_vgp)>0: has_vgps=True\n",
    "        if has_vgps:\n",
    "            dir_df['vgp_lat_abs']=dir_df.vgp_lat.abs() \n",
    "            dir_df.sort_values(by=['site','vgp_lat_abs'],ascending=False,inplace=True)\n",
    "            dir_df=dir_df[['site','dir_tilt_correction','dir_dec','dir_inc',\\\n",
    "                'dir_n_samples','dir_k','dir_r','dir_alpha95','vgp_lat','vgp_lon']]\n",
    "    # this will take the first record for each site's directions (including VGP lat if present)\n",
    "            DirCols.append(\"VGP Lat\")\n",
    "            DirCols.append(\"VGP Long\")\n",
    "            dir_df.drop_duplicates(subset=['dir_dec','dir_inc','site'],inplace=True)\n",
    "        else:\n",
    "            dir_df.drop_duplicates(subset=['dir_dec','dir_inc','site'],inplace=True)\n",
    "            dir_df=dir_df[['site','dir_tilt_correction','dir_dec','dir_inc',\\\n",
    "                   'dir_n_samples','dir_k','dir_r','dir_alpha95']]   \n",
    "        dir_df.columns=DirCols \n",
    "        dir_df.sort_values(by=['Site'],inplace=True,ascending=True)\n",
    "        if latex:\n",
    "            directions_out = open(dir_file, 'w+', errors=\"backslashreplace\")\n",
    "            directions_out.write('\\documentclass{article}\\n')\n",
    "            directions_out.write('\\\\usepackage{booktabs}\\n')\n",
    "            directions_out.write('\\\\usepackage{longtable}\\n')\n",
    "            directions_out.write('\\\\begin{document}')\n",
    "            directions_out.write(dir_df.to_latex(index=False,longtable=True,multicolumn=False))\n",
    "            directions_out.write('\\end{document}\\n')\n",
    "            directions_out.close()\n",
    "        else:\n",
    "            dir_df.to_excel(dir_file,index=False)\n",
    "    else: \n",
    "        print (\"No directional data for ouput.\")\n",
    "# now for the intensities\n",
    "    has_vadms,has_vdms=False,False\n",
    "    int_df=sites_df.dropna(subset=['int_abs'])\n",
    "    int_df['int_n_samples']=int_df['int_n_samples'].values.astype('int')\n",
    "    if len(int_df)>0:\n",
    "        int_df['int_abs_uT']=1e6*int_df.int_abs.values # convert to uT\n",
    "        int_df['int_abs_sigma_uT']=1e6*int_df.int_abs_sigma.values # convert to uT\n",
    "        int_df['int_abs_uT']=int_df['int_abs_uT'].values.astype('int')\n",
    "        int_df['int_abs_sigma_uT']=int_df['int_abs_sigma_uT'].values.astype('int')\n",
    "        int_df['int_abs_sigma_perc']=int_df['int_abs_sigma_perc'].values.astype('int')\n",
    "        int_file=pmag.resolve_file_name(intensity_file,output_dir_path)\n",
    "\n",
    "        IntCols = [\"Site\", \"N\", \"B\", \"B sigma\",\"sigma (%)\"]\n",
    "        if 'vadm' in int_df.columns:\n",
    "            test_vadm=int_df.dropna(subset=['vadm'])\n",
    "            if len(test_vadm)>0: \n",
    "                has_vadms=True\n",
    "\n",
    "        if 'vdm' in int_df.columns:\n",
    "            test_vdm=int_df.dropna(subset=['vdm'])\n",
    "            if len(test_vdm)>0: has_vdms=True\n",
    "       \n",
    "        if has_vadms:\n",
    "            IntCols.append(\"VADM\")\n",
    "            IntCols.append(\"VADM sigma\")\n",
    "        if has_vdms:\n",
    "            IntCols.append(\"VDM\")\n",
    "            IntCols.append(\"VDM sigma\")\n",
    "        if not has_vadms and not has_vdms:\n",
    "            int_df=int_df[['site','int_n_samples','int_abs_uT','int_abs_sigma_uT',\\\n",
    "                'int_abs_sigma_perc']]\n",
    "        if has_vadms and not has_vdms:\n",
    "            int_df.sort_values(by=['site','vadm'],ascending=False,inplace=True)\n",
    "            int_df.drop_duplicates(subset=['int_abs_uT','site'],inplace=True)\n",
    "\n",
    "            int_df['vadm_ZAm2']=1e-21*int_df.vadm.values\n",
    "            int_df['vadm_sigma_ZAm2']=1e-21*int_df.vadm_sigma.values\n",
    "            int_df=int_df[['site','int_n_samples','int_abs_uT','int_abs_sigma_uT',\\\n",
    "                'int_abs_sigma_perc','vadm_ZAm2','vadm_ZAm2_sigma']]\n",
    "        if not has_vadms and  has_vdms:\n",
    "            int_df.sort_values(by=['site','vdm'],ascending=False,inplace=True)\n",
    "            int_df.drop_duplicates(subset=['int_abs_uT','site'],inplace=True)\n",
    "            int_df['vdm_ZAm2']=1e-21*int_df.vdm.values()\n",
    "            int_df['vdm_sigma_ZAm2']=1e-21*int_df.vdm_sigma.values()\n",
    "\n",
    "            int_df=int_df[['site','int_n_samples','int_abs_uT','int_abs_sigma_uT',\\\n",
    "                'int_abs_sigma_perc','vdm_ZAm2','vdm_ZAm2_sigma']]\n",
    "        if has_vadms and  has_vdms:\n",
    "            int_df.sort_values(by=['site','vadm'],ascending=False,inplace=True)\n",
    "            int_df.drop_duplicates(subset=['int_abs_uT','site'],inplace=True)\n",
    "            int_df['vadm_ZAm2']=1e-21*int_df.vadm.values\n",
    "            int_df['vadm_sigma_ZAm2']=1e-21*int_df.vadm_sigma.values\n",
    "            int_df['vdm_ZAm2']=1e-21*int_df.vdm.values\n",
    "            int_df['vdm_sigma_ZAm2']=1e-21*int_df.vdm_sigma.values\n",
    "            int_df=int_df[['site','int_n_samples','int_abs_uT','int_abs_sigma_uT',\\\n",
    "                'int_abs_sigma_perc','vadm_ZAm2','vadm_sigma_ZAm2','vdm_ZAm2','vdm_sigma_ZAm2']]\n",
    "        int_df.columns=IntCols \n",
    "        int_df.sort_values(by=['Site'],inplace=True,ascending=True)\n",
    "        int_df.fillna(value='',inplace=True)\n",
    "        if latex:\n",
    "            intensities_out = open(int_file, 'w+', errors=\"backslashreplace\")\n",
    "            intensities_out.write('\\documentclass{article}\\n')\n",
    "            intensities_out.write('\\\\usepackage{booktabs}\\n')\n",
    "            intensities_out.write('\\\\usepackage{longtable}\\n')\n",
    "            intensities_out.write('\\\\begin{document}')\n",
    "            intensities_out.write(int_df.to_latex(index=False,longtable=True,multicolumn=False))\n",
    "            intensities_out.write('\\end{document}\\n')\n",
    "            intensities_out.close()\n",
    "        else:\n",
    "            int_df.to_excel(int_file,index=False)\n",
    "    else: \n",
    "        print (\"No intensity data for ouput.\")\n",
    "# site info\n",
    "    nfo_df=sites_df.dropna(subset=['lat','lon']) # delete blank locations\n",
    "    if len(nfo_df)>0:\n",
    "        SiteCols = [\"Site\", \"Location\",\"Lat. (N)\", \"Long. (E)\"]\n",
    "        info_file=pmag.resolve_file_name(info_file,output_dir_path)\n",
    "\n",
    "\n",
    "        test_age=nfo_df.dropna(subset=['age','age_sigma','age_unit'])\n",
    "        if len(test_age)>0:                       \n",
    "            SiteCols.append(\"Age \")\n",
    "            SiteCols.append(\"Age sigma\")\n",
    "            SiteCols.append(\"Units\")\n",
    "            nfo_df=nfo_df[['site','location','lat','lon','age','age_sigma','age_unit']]\n",
    "        else:\n",
    "            nfo_df=nfo_df[['site','location','lat','lon']]\n",
    "        nfo_df.drop_duplicates(inplace=True)\n",
    "        nfo_df.columns=SiteCols\n",
    "        nfo_df.fillna(value='',inplace=True) \n",
    "        if latex:\n",
    "            info_out = open(info_file, 'w+', errors=\"backslashreplace\")\n",
    "            info_out.write('\\documentclass{article}\\n')\n",
    "            info_out.write('\\\\usepackage{booktabs}\\n')\n",
    "            info_out.write('\\\\usepackage{longtable}\\n')\n",
    "            info_out.write('\\\\begin{document}')\n",
    "            info_out.write(nfo_df.to_latex(index=False,longtable=True,multicolumn=False))\n",
    "            info_out.write('\\end{document}\\n')\n",
    "            info_out.close()\n",
    "        else:\n",
    "            nfo_df.to_excel(info_file,index=False)\n",
    "    else: \n",
    "        print (\"No location information  for ouput.\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latex way:\n",
    "sites_extract(directions_file='directions.tex',intensity_file='intensities.tex',\n",
    "              output_dir_path='/users/ltauxe/Desktop',info_file='site_info.tex',\n",
    "              input_dir_path='data_files/3_0/McMurdo',latex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xls way:\n",
    "sites_extract(output_dir_path='/users/ltauxe/Desktop',\n",
    "              input_dir_path='data_files/3_0/McMurdo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criteria_extract(crit_file='criteria.txt',output_file='criteria.xls',\n",
    "                  output_dir_path='./',input_dir_path='./',latex=False):\n",
    "    \"\"\"\n",
    "    Extracts criteria  from a MagIC 3.0 format criteria.txt file.\n",
    "    Default output format is an Excel file. \n",
    "    typeset with latex on your own computer.  \n",
    "    \n",
    "    Parameters\n",
    "    ___________\n",
    "    crit_file : str\n",
    "         input file name\n",
    "    input_dir_path : str\n",
    "          path for intput file if different from output_dir_path (default is same)\n",
    "    latex : boolean\n",
    "           if True, output file should be latex formatted table with a .tex ending\n",
    "           \n",
    "    Return :\n",
    "        [True,False],  data table error type : True if successful\n",
    "        \n",
    "    Effects : \n",
    "        writes cvs or latex formatted tables for use in publications\n",
    "    \"\"\"\n",
    "    if not input_dir_path:\n",
    "        input_dir_path = output_dir_path\n",
    "    try:\n",
    "        fname = pmag.resolve_file_name(crit_file, input_dir_path)\n",
    "    except IOError:\n",
    "        print(\"bad criteria file name\")\n",
    "        return False, \"bad site file name\"\n",
    "    crit_df=pd.read_csv(fname,sep='\\t',header=1)\n",
    "    if len(crit_df)>0:\n",
    "        out_file=pmag.resolve_file_name(output_file,output_dir_path)\n",
    "\n",
    "\n",
    "        s=crit_df['table_column'].str.split(pat='.',expand=True)\n",
    "        crit_df['table']=s[0]\n",
    "        crit_df['column']=s[1]\n",
    "        crit_df=crit_df[['table','column','criterion_value','criterion_operation']]\n",
    "\n",
    "        crit_df.columns=['table','statistic','threshold','operation']\n",
    "\n",
    "        if latex:\n",
    "            crit_df.loc[crit_df['operation'].str.contains('<'),'operation']='maximum'\n",
    "            crit_df.loc[crit_df['operation'].str.contains('>'),'operation']='minimum'\n",
    "            crit_df.loc[crit_df['operation']=='=','operation']='equal to'\n",
    "            info_out = open(out_file, 'w+', errors=\"backslashreplace\")\n",
    "            info_out.write('\\documentclass{article}\\n')\n",
    "            info_out.write('\\\\usepackage{booktabs}\\n')\n",
    "            #info_out.write('\\\\usepackage{longtable}\\n')\n",
    "            info_out.write('\\\\begin{document}')\n",
    "            info_out.write(crit_df.to_latex(index=False,longtable=False,\n",
    "                                            escape=True,multicolumn=False))\n",
    "            info_out.write('\\end{document}\\n')\n",
    "            info_out.close()\n",
    "        else:\n",
    "            crit_df.to_excel(out_file,index=False)\n",
    "\n",
    "    else: \n",
    "        print (\"No criteria   for ouput.\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latex way:\n",
    "criteria_extract(output_dir_path='/users/ltauxe/Desktop',latex=True,output_file='criteria.tex',\n",
    "              input_dir_path='data_files/3_0/Megiddo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel way:\n",
    "criteria_extract(output_dir_path='/users/ltauxe/Desktop',\n",
    "              input_dir_path='data_files/3_0/Megiddo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(map_magic)\n",
    "def specimens_extract(spec_file='specimens.txt',output_file='specimens.xls',landscape=False,\n",
    "                  longtable=False,output_dir_path='./',input_dir_path='./',latex=False):\n",
    "    \"\"\"\n",
    "    Extracts specimen results  from a MagIC 3.0 format specimens.txt file.\n",
    "    Default output format is an Excel file. \n",
    "    typeset with latex on your own computer.  \n",
    "    \n",
    "    Parameters\n",
    "    ___________\n",
    "    spec_file : str\n",
    "         input file name\n",
    "    input_dir_path : str\n",
    "          path for intput file if different from output_dir_path (default is same)\n",
    "    latex : boolean\n",
    "           if True, output file should be latex formatted table with a .tex ending\n",
    "    longtable : boolean\n",
    "           if True output latex longtable\n",
    "    Return :\n",
    "        [True,False],  data table error type : True if successful\n",
    "        \n",
    "    Effects : \n",
    "        writes cvs or latex formatted tables for use in publications\n",
    "    \"\"\"\n",
    "    if not input_dir_path:\n",
    "        input_dir_path = output_dir_path\n",
    "    try:\n",
    "        fname = pmag.resolve_file_name(spec_file, input_dir_path)\n",
    "    except IOError:\n",
    "        print(\"bad specimen file name\")\n",
    "        return False, \"bad specimen file name\"\n",
    "    spec_df=pd.read_csv(fname,sep='\\t',header=1)\n",
    "    spec_df.dropna('columns',how='all',inplace=True)\n",
    "    spec_df.dropna(subset=['int_abs'],inplace=True)\n",
    "    if len(spec_df)>0:\n",
    "        table_df=map_magic.convert_specimen_dm3_table(spec_df)\n",
    "        out_file=pmag.resolve_file_name(output_file,output_dir_path)\n",
    "        if latex:\n",
    "            info_out = open(out_file, 'w+', errors=\"backslashreplace\")\n",
    "            info_out.write('\\documentclass{article}\\n')\n",
    "            info_out.write('\\\\usepackage{booktabs}\\n')\n",
    "            if landscape:info_out.write('\\\\usepackage{lscape}')\n",
    "            if longtable:info_out.write('\\\\usepackage{longtable}\\n')\n",
    "            info_out.write('\\\\begin{document}\\n')\n",
    "            if landscape:info_out.write('\\\\begin{landscape}\\n')\n",
    "            info_out.write(table_df.to_latex(index=False,longtable=longtable,\n",
    "                                            escape=True,multicolumn=False))\n",
    "            if landscape:info_out.write('\\end{landscape}\\n')\n",
    "            info_out.write('\\end{document}\\n')\n",
    "            info_out.close()\n",
    "        else:\n",
    "            table_df.to_excel(out_file,index=False)\n",
    "\n",
    "    else: \n",
    "        print (\"No specimen data   for ouput.\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I- Using online data model\n"
     ]
    }
   ],
   "source": [
    "# latex way: \n",
    "specimens_extract(output_dir_path='/users/ltauxe/Desktop',output_file='specimens.tex',landscape=True,\n",
    "              input_dir_path='data_files/3_0/Megiddo',latex=True,longtable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I- Using online data model\n"
     ]
    }
   ],
   "source": [
    "# excel way:\n",
    "specimens_extract(output_dir_path='/users/ltauxe/Desktop',\n",
    "              input_dir_path='data_files/3_0/Megiddo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locations_extract(loc_file='locations.txt',output_file='locations.xls',\n",
    "                  output_dir_path='./',input_dir_path='./',latex=False):\n",
    "    \"\"\"\n",
    "    Extracts location averages  from a MagIC 3.0 format locations.txt file.\n",
    "    Default output format is an Excel file. \n",
    "    typeset with latex on your own computer.  \n",
    "    \n",
    "    Parameters\n",
    "    ___________\n",
    "    loc_file : str\n",
    "         input file name\n",
    "    input_dir_path : str\n",
    "          path for intput file if different from output_dir_path (default is same)\n",
    "    latex : boolean\n",
    "           if True, output file should be latex formatted table with a .tex ending\n",
    "           \n",
    "    Return :\n",
    "        [True,False],  data table error type : True if successful\n",
    "        \n",
    "    Effects : \n",
    "        writes cvs or latex formatted tables for use in publications\n",
    "    \"\"\"\n",
    "    if not input_dir_path:\n",
    "        input_dir_path = output_dir_path\n",
    "    try:\n",
    "        fname = pmag.resolve_file_name(loc_file, input_dir_path)\n",
    "    except IOError:\n",
    "        print(\"bad location file name\")\n",
    "        return False, \"bad location file name\"\n",
    "    loc_df=pd.read_csv(fname,sep='\\t',header=1)\n",
    "    if len(loc_df)>0:\n",
    "        out_file=pmag.resolve_file_name(output_file,output_dir_path)\n",
    "        poles=loc_df.dropna(subset=['pole_lat','pole_lon'])\n",
    "        print (poles)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  location                                              sites     age  \\\n",
      "1  McMurdo  mc03 : mc04 : mc06 : mc07 : mc08 : mc09 : mc10...  2.5620   \n",
      "2  McMurdo  mc102 : mc103 : mc105 : mc109 : mc110 : mc112 ...  2.5540   \n",
      "3  McMurdo  mc02 : mc03 : mc04 : mc06 : mc07 : mc08 : mc09...  2.5589   \n",
      "\n",
      "   age_sigma age_unit  dir_alpha95  dir_dec  dir_inc  dir_k  dir_n_sites  \\\n",
      "1     2.8348       Ma          3.3     16.3    -80.8   26.0         75.0   \n",
      "2     1.8641       Ma          4.1    186.8     77.7   27.2         46.0   \n",
      "3     2.5017       Ma          2.5     12.1    -79.7   26.4        121.0   \n",
      "\n",
      "      ...      pole_alpha95  pole_antipodal_angle pole_lat pole_lon  \\\n",
      "1     ...               5.5                   NaN     84.6    214.5   \n",
      "2     ...               6.9                   NaN    -79.9      2.7   \n",
      "3     ...               4.3                 173.8     83.1    197.5   \n",
      "\n",
      "   pole_n_sites  pole_reversed_perc   citations   method_codes  \\\n",
      "1          75.0                 0.0  This study         DE-VGP   \n",
      "2          46.0               100.0  This study         DE-VGP   \n",
      "3         121.0                38.0  This study  ST-R-2:DE-VGP   \n",
      "\n",
      "       result_name result_type  \n",
      "1      Normal Pole           a  \n",
      "2     Reverse pole           a  \n",
      "3  Grand Mean pole           a  \n",
      "\n",
      "[3 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "# excel way:\n",
    "locations_extract(output_dir_path='/users/ltauxe/Desktop',\n",
    "              input_dir_path='data_files/3_0/McMurdo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "         if latex:\n",
    "            info_out = open(out_file, 'w+', errors=\"backslashreplace\")\n",
    "            info_out.write('\\documentclass{article}\\n')\n",
    "            info_out.write('\\\\usepackage{booktabs}\\n')\n",
    "            #info_out.write('\\\\usepackage{longtable}\\n')\n",
    "            info_out.write('\\\\begin{document}')\n",
    "            info_out.write(loc_df.to_latex(index=False,longtable=False,\n",
    "                                            escape=True,multicolumn=False))\n",
    "            info_out.write('\\end{document}\\n')\n",
    "            info_out.close()\n",
    "        else:\n",
    "            loc_df.to_excel(out_file,index=False)\n",
    "\n",
    "    else: \n",
    "        print (\"No locations   for ouput.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
