{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was used to develop functionality that is now in pmagpy/data_model3.py.  Examples of how to use the data_model3 module can be found in the \"Importing datamodel module\" section below.  In general, the data model is imported into the GUIs to provide column names, controlled and suggested vocabularies, and validations for column values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import req'd modules\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "import pmagpy.builder2 as builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with json & unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'hello': u'hi', u'so long': u'goodbye'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# json is the same format that the MagIC data model comes in\n",
    "\n",
    "# turn json into Python:\n",
    "json_string = '{\"first_name\": \"Guido\", \"last_name\":\"Rossum\"}'\n",
    "parsed = json.loads(json_string)\n",
    "\n",
    "# turn Python into json\n",
    "d = {'hello': 'hi', 'so long': 'goodbye'}\n",
    "dumped = json.dumps(d)\n",
    "\n",
    "# store json in a file\n",
    "outfile = open('stored.json', 'w')\n",
    "json.dump(dumped, outfile)\n",
    "outfile.close()\n",
    "\n",
    "# read json file into Python\n",
    "jstring = json.load(open('stored.json', 'r'))\n",
    "json.loads(jstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\r\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parsing unicode\n",
    "unicode('\\r\\n\\n\\xc2\\xa0\\xc2\\xa0', errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data model in to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code in this block has been incorporated into data_model3.py\n",
    "\n",
    "def get_data_model():\n",
    "    model_file = os.path.join('..', '..', 'pmagpy', 'data_model', 'data_model.json')\n",
    "    f = open(model_file, 'r')\n",
    "    string = '\\n'.join(f.readlines())\n",
    "    raw = json.loads(unicode(string, errors='ignore'))\n",
    "    full = DataFrame(raw)\n",
    "    return full\n",
    "\n",
    "    \n",
    "try:\n",
    "    full = get_data_model()\n",
    "except IOError:\n",
    "    skip = True\n",
    "    print 'Skip this block'\n",
    "else:\n",
    "    skip = False\n",
    "    \n",
    "if not skip:\n",
    "    DataFrame(full['tables']['locations'])\n",
    "    location = DataFrame(full['tables']['locations']['columns'])\n",
    "    location = location.transpose()\n",
    "    #full['tables']['locations'].pop('columns')\n",
    "    #full['tables']['locations']\n",
    "    # don't really need anything that isn't in ['tables'][table]['columns']\n",
    "    location[:3]\n",
    "\n",
    "    full_df = get_data_model()\n",
    "\n",
    "    data_model = {}\n",
    "    levels = ['specimens', 'samples', 'sites', 'locations', 'criteria']\n",
    "    for level in levels:\n",
    "        df = DataFrame(full_df['tables'][level]['columns'])\n",
    "        data_model[level] = df.transpose()\n",
    "\n",
    "    data_model['sites']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting info from the data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get various different data from the data model\n",
    "\n",
    "if not skip:\n",
    "    # get all headers of a particular group\n",
    "    cond = location['group'] == 'Age'\n",
    "    age_columns = location[cond]\n",
    "    age_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip:\n",
    "    # get a particular column\n",
    "    location.ix['age_high']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip:\n",
    "    # get validations for a particular column\n",
    "    validations = location.ix['age_high']['validations']\n",
    "    validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip:\n",
    "    # get all groups for locations\n",
    "    location['group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip:\n",
    "    # get all rows in a group\n",
    "    group = 'Direction'\n",
    "    location[location['group'] == group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'age', u'age_high', u'age_low', u'age_sigma', u'age_unit', u'analysts', u'citations', u'conglomerate_test', u'contact_test', u'continent_ocean', u'country', u'criteria', u'description', u'dir_alpha95', u'dir_dec', u'dir_inc', u'dir_k', u'dir_k_ratio', u'dir_n_samples', u'dir_n_sites', u'dir_n_specimens', u'dir_polarity', u'dir_r', u'dir_tilt_correction', u'elevation_high', u'elevation_low', u'expedition_description', u'expedition_leg', u'expedition_name', u'expedition_ship', u'expedition_url', u'experiments', u'external_database_ids', u'fold_test', u'fold_test_significance', u'formations', u'geologic_classes', u'geological_province_sections', u'int_abs', u'int_abs_sigma', u'int_abs_sigma_perc', u'int_n_samples', u'int_n_sites', u'int_n_specimens', u'lat_lon_precision', u'lat_n', u'lat_s', u'lithologies', u'location', u'location_alternatives', u'location_type', u'lon_e', u'lon_w', u'members', u'method_codes', u'ocean_sea', u'padm', u'padm_n_sites', u'padm_sigma', u'paleolat', u'paleolat_sigma', u'paleolon', u'paleolon_sigma', u'pdm', u'pdm_n_sites', u'pdm_sigma', u'pis', u'plate_blocks', u'pole_alpha95', u'pole_antipodal_angle', u'pole_bc_q', u'pole_comp_name', u'pole_conf', u'pole_dm', u'pole_dp', u'pole_k', u'pole_lat', u'pole_lon', u'pole_n_sites', u'pole_r', u'pole_reversed_perc', u'pole_vv_q', u'region', u'result_name', u'result_quality', u'result_type', u'reversal_test', u'rock_magnetic_test', u'rotation_sequence', u'samples', u'scientists', u'sites', u'software_packages', u'specimens', u'tectonic_settings', u'terranes', u'village_city']\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "if not skip:\n",
    "    # get all column labels for locations\n",
    "    print list(location.index)\n",
    "    print 'required()' in location.ix['location']['validations']\n",
    "    print 'required()' in location.ix['continent_ocean']['validations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Age' u'Metadata' u'Result' u'Direction' u'Geography' u'Expedition'\n",
      " u'Names' u'Geology' u'Paleointensity' u'Location' u'PADM' u'Paleoposition'\n",
      " u'PDM' u'Pole']\n"
     ]
    }
   ],
   "source": [
    "if not skip:\n",
    "    # get list of unique groups for location\n",
    "    print location['group'].unique()\n",
    "\n",
    "    #sort column names by group\n",
    "    location.sort_values('group').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], ['age_unit', 'geologic_classes', 'lat_n', 'lat_s', 'lithologies', 'location', 'location_type', 'lon_e', 'lon_w'], ['age', 'age_high', 'age_low', 'age_sigma', 'analysts', 'citations', 'conglomerate_test', 'contact_test', 'continent_ocean', 'country', 'criteria', 'description', 'dir_alpha95', 'dir_dec', 'dir_inc', 'dir_k', 'dir_k_ratio', 'dir_n_samples', 'dir_n_sites', 'dir_n_specimens', 'dir_polarity', 'dir_r', 'dir_tilt_correction', 'elevation_high', 'elevation_low', 'expedition_description', 'expedition_leg', 'expedition_name', 'expedition_ship', 'expedition_url', 'experiments', 'external_database_ids', 'fold_test', 'fold_test_significance', 'formations', 'geological_province_sections', 'int_abs', 'int_abs_sigma', 'int_abs_sigma_perc', 'int_n_samples', 'int_n_sites', 'int_n_specimens', 'lat_lon_precision', 'location_alternatives', 'members', 'method_codes', 'ocean_sea', 'padm', 'padm_n_sites', 'padm_sigma', 'paleolat', 'paleolat_sigma', 'paleolon', 'paleolon_sigma', 'pdm', 'pdm_n_sites', 'pdm_sigma', 'pis', 'plate_blocks', 'pole_alpha95', 'pole_antipodal_angle', 'pole_bc_q', 'pole_comp_name', 'pole_conf', 'pole_dm', 'pole_dp', 'pole_k', 'pole_lat', 'pole_lon', 'pole_n_sites', 'pole_r', 'pole_reversed_perc', 'pole_vv_q', 'region', 'result_name', 'result_quality', 'result_type', 'reversal_test', 'rock_magnetic_test', 'rotation_sequence', 'samples', 'scientists', 'sites', 'software_packages', 'specimens', 'tectonic_settings', 'terranes', 'village_city']]\n"
     ]
    }
   ],
   "source": [
    "if not skip:\n",
    "    # get headers the way we do them in the current builder.py\n",
    "    # not sure we will actually want to do it like this as we update magic_gui.py and pmag_gui.py\n",
    "    cond = location['validations'].map(lambda x: 'required()' in str(x))\n",
    "\n",
    "    reqd_loc_headers = [str(i) for i in location[cond].index]\n",
    "    all_loc_headers = [str(i) for i in location['validations'].index if i not in reqd_loc_headers]\n",
    "    headers = [[], reqd_loc_headers, all_loc_headers] # this is basically how self.headers is organizaed now in builder.py\n",
    "\n",
    "    print headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip:\n",
    "    set(headers[1]) - set(headers[2])\n",
    "    set(headers[2]) - set(headers[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing datamodel module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>examples</th>\n",
       "      <th>group</th>\n",
       "      <th>label</th>\n",
       "      <th>notes</th>\n",
       "      <th>position</th>\n",
       "      <th>previous_columns</th>\n",
       "      <th>type</th>\n",
       "      <th>unit</th>\n",
       "      <th>urls</th>\n",
       "      <th>validations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>Location inferred age</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Age</td>\n",
       "      <td>Inferred Age</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>[{u'column': u'average_age', u'table': u'pmag_...</td>\n",
       "      <td>Number</td>\n",
       "      <td>Custom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[requiredUnless(\"age_low\",\"age_high\"), require...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_high</th>\n",
       "      <td>Location inferred age, High range</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Age</td>\n",
       "      <td>Inferred Age High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>[{u'column': u'average_age_high', u'table': u'...</td>\n",
       "      <td>Number</td>\n",
       "      <td>Custom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[min(\"age_low\"), requiredUnless(\"age\")]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_low</th>\n",
       "      <td>Location inferred age, Low range</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Age</td>\n",
       "      <td>Inferred Age Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>[{u'column': u'average_age_low', u'table': u'p...</td>\n",
       "      <td>Number</td>\n",
       "      <td>Custom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[max(\"age_high\"), requiredUnless(\"age\")]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_sigma</th>\n",
       "      <td>Location inferred age, Uncertainty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Age</td>\n",
       "      <td>Inferred Age Sigma</td>\n",
       "      <td>Standard error or standard deviation at one sigma</td>\n",
       "      <td>39</td>\n",
       "      <td>[{u'column': u'average_age_sigma', u'table': u...</td>\n",
       "      <td>Number</td>\n",
       "      <td>Custom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[min(0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_unit</th>\n",
       "      <td>Location inferred age, Unit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Age</td>\n",
       "      <td>Inferred Age Unit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>[{u'column': u'average_age_unit', u'table': u'...</td>\n",
       "      <td>String</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cv(\"age_unit\"), required()]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  description examples group  \\\n",
       "age                     Location inferred age      NaN   Age   \n",
       "age_high    Location inferred age, High range      NaN   Age   \n",
       "age_low      Location inferred age, Low range      NaN   Age   \n",
       "age_sigma  Location inferred age, Uncertainty      NaN   Age   \n",
       "age_unit          Location inferred age, Unit      NaN   Age   \n",
       "\n",
       "                        label  \\\n",
       "age              Inferred Age   \n",
       "age_high    Inferred Age High   \n",
       "age_low      Inferred Age Low   \n",
       "age_sigma  Inferred Age Sigma   \n",
       "age_unit    Inferred Age Unit   \n",
       "\n",
       "                                                       notes position  \\\n",
       "age                                                      NaN       38   \n",
       "age_high                                                 NaN       41   \n",
       "age_low                                                  NaN       40   \n",
       "age_sigma  Standard error or standard deviation at one sigma       39   \n",
       "age_unit                                                 NaN       42   \n",
       "\n",
       "                                            previous_columns    type    unit  \\\n",
       "age        [{u'column': u'average_age', u'table': u'pmag_...  Number  Custom   \n",
       "age_high   [{u'column': u'average_age_high', u'table': u'...  Number  Custom   \n",
       "age_low    [{u'column': u'average_age_low', u'table': u'p...  Number  Custom   \n",
       "age_sigma  [{u'column': u'average_age_sigma', u'table': u...  Number  Custom   \n",
       "age_unit   [{u'column': u'average_age_unit', u'table': u'...  String     NaN   \n",
       "\n",
       "          urls                                        validations  \n",
       "age        NaN  [requiredUnless(\"age_low\",\"age_high\"), require...  \n",
       "age_high   NaN            [min(\"age_low\"), requiredUnless(\"age\")]  \n",
       "age_low    NaN           [max(\"age_high\"), requiredUnless(\"age\")]  \n",
       "age_sigma  NaN                                           [min(0)]  \n",
       "age_unit   NaN                       [cv(\"age_unit\"), required()]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pmagpy.data_model3 as dm\n",
    "reload(dm)\n",
    "\n",
    "data_model = dm.DataModel()\n",
    "data_model.dm['locations'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the data_model module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmagpy.data_model3 as data_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>examples</th>\n",
       "      <th>group</th>\n",
       "      <th>label</th>\n",
       "      <th>notes</th>\n",
       "      <th>position</th>\n",
       "      <th>previous_columns</th>\n",
       "      <th>type</th>\n",
       "      <th>unit</th>\n",
       "      <th>urls</th>\n",
       "      <th>validations</th>\n",
       "      <th>str_validations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age_unit</th>\n",
       "      <td>Location inferred age, Unit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Age</td>\n",
       "      <td>Inferred Age Unit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>[{u'column': u'average_age_unit', u'table': u'...</td>\n",
       "      <td>String</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cv(\"age_unit\"), required()]</td>\n",
       "      <td>cv(\"age_unit\"), required()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geologic_classes</th>\n",
       "      <td>Colon-delimited list of geologic classes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geology</td>\n",
       "      <td>Geologic Classes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>[{u'column': u'location_class', u'table': u'er...</td>\n",
       "      <td>List</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cv(\"class\"), required()]</td>\n",
       "      <td>cv(\"class\"), required()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat_n</th>\n",
       "      <td>Northernmost latitude of the collection of sites</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geography</td>\n",
       "      <td>Northernmost Latitude</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>[{u'column': u'location_begin_lat', u'table': ...</td>\n",
       "      <td>Number</td>\n",
       "      <td>Degrees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[min(-90), max(90), min(\"lat_s\"), required()]</td>\n",
       "      <td>min(-90), max(90), min(\"lat_s\"), required()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat_s</th>\n",
       "      <td>Southernmost latitude of the collection of sites</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geography</td>\n",
       "      <td>Southernmost Latitude</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>[{u'column': u'location_begin_lat', u'table': ...</td>\n",
       "      <td>Number</td>\n",
       "      <td>Degrees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[min(-90), max(90), max(\"lat_n\"), required()]</td>\n",
       "      <td>min(-90), max(90), max(\"lat_n\"), required()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lithologies</th>\n",
       "      <td>Colon-delimited list of lithologies or archeol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geology</td>\n",
       "      <td>Lithologies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>[{u'column': u'location_lithology', u'table': ...</td>\n",
       "      <td>List</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cv(\"lithology\"), required()]</td>\n",
       "      <td>cv(\"lithology\"), required()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>Name for location, dredge or drill site</td>\n",
       "      <td>[San Francisco Volcanic Province, Dredge AMAT0...</td>\n",
       "      <td>Names</td>\n",
       "      <td>Location Name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[{u'column': u'er_location_name', u'table': u'...</td>\n",
       "      <td>String</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[required()]</td>\n",
       "      <td>required()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location_type</th>\n",
       "      <td>Location type</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Location</td>\n",
       "      <td>Location Type</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>[{u'column': u'location_type', u'table': u'er_...</td>\n",
       "      <td>String</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cv(\"location_type\"), required()]</td>\n",
       "      <td>cv(\"location_type\"), required()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lon_e</th>\n",
       "      <td>Easternmost longitude of the collection of sites</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geography</td>\n",
       "      <td>Easternmost Longitude</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>[{u'column': u'location_begin_lon', u'table': ...</td>\n",
       "      <td>Number</td>\n",
       "      <td>Degrees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[min(0), max(360), required()]</td>\n",
       "      <td>min(0), max(360), required()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lon_w</th>\n",
       "      <td>Westernmost longitude of the collection of sites</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geography</td>\n",
       "      <td>Westernmost Longitude</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>[{u'column': u'location_begin_lon', u'table': ...</td>\n",
       "      <td>Number</td>\n",
       "      <td>Degrees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[min(0), max(360), required()]</td>\n",
       "      <td>min(0), max(360), required()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        description  \\\n",
       "age_unit                                Location inferred age, Unit   \n",
       "geologic_classes           Colon-delimited list of geologic classes   \n",
       "lat_n              Northernmost latitude of the collection of sites   \n",
       "lat_s              Southernmost latitude of the collection of sites   \n",
       "lithologies       Colon-delimited list of lithologies or archeol...   \n",
       "location                    Name for location, dredge or drill site   \n",
       "location_type                                         Location type   \n",
       "lon_e              Easternmost longitude of the collection of sites   \n",
       "lon_w              Westernmost longitude of the collection of sites   \n",
       "\n",
       "                                                           examples  \\\n",
       "age_unit                                                        NaN   \n",
       "geologic_classes                                                NaN   \n",
       "lat_n                                                           NaN   \n",
       "lat_s                                                           NaN   \n",
       "lithologies                                                     NaN   \n",
       "location          [San Francisco Volcanic Province, Dredge AMAT0...   \n",
       "location_type                                                   NaN   \n",
       "lon_e                                                           NaN   \n",
       "lon_w                                                           NaN   \n",
       "\n",
       "                      group                  label notes position  \\\n",
       "age_unit                Age      Inferred Age Unit   NaN       42   \n",
       "geologic_classes    Geology       Geologic Classes   NaN       18   \n",
       "lat_n             Geography  Northernmost Latitude   NaN       27   \n",
       "lat_s             Geography  Southernmost Latitude   NaN       26   \n",
       "lithologies         Geology            Lithologies   NaN       19   \n",
       "location              Names          Location Name   NaN        1   \n",
       "location_type      Location          Location Type   NaN        6   \n",
       "lon_e             Geography  Easternmost Longitude   NaN       29   \n",
       "lon_w             Geography  Westernmost Longitude   NaN       28   \n",
       "\n",
       "                                                   previous_columns    type  \\\n",
       "age_unit          [{u'column': u'average_age_unit', u'table': u'...  String   \n",
       "geologic_classes  [{u'column': u'location_class', u'table': u'er...    List   \n",
       "lat_n             [{u'column': u'location_begin_lat', u'table': ...  Number   \n",
       "lat_s             [{u'column': u'location_begin_lat', u'table': ...  Number   \n",
       "lithologies       [{u'column': u'location_lithology', u'table': ...    List   \n",
       "location          [{u'column': u'er_location_name', u'table': u'...  String   \n",
       "location_type     [{u'column': u'location_type', u'table': u'er_...  String   \n",
       "lon_e             [{u'column': u'location_begin_lon', u'table': ...  Number   \n",
       "lon_w             [{u'column': u'location_begin_lon', u'table': ...  Number   \n",
       "\n",
       "                     unit urls                                    validations  \\\n",
       "age_unit              NaN  NaN                   [cv(\"age_unit\"), required()]   \n",
       "geologic_classes      NaN  NaN                      [cv(\"class\"), required()]   \n",
       "lat_n             Degrees  NaN  [min(-90), max(90), min(\"lat_s\"), required()]   \n",
       "lat_s             Degrees  NaN  [min(-90), max(90), max(\"lat_n\"), required()]   \n",
       "lithologies           NaN  NaN                  [cv(\"lithology\"), required()]   \n",
       "location              NaN  NaN                                   [required()]   \n",
       "location_type         NaN  NaN              [cv(\"location_type\"), required()]   \n",
       "lon_e             Degrees  NaN                 [min(0), max(360), required()]   \n",
       "lon_w             Degrees  NaN                 [min(0), max(360), required()]   \n",
       "\n",
       "                                              str_validations  \n",
       "age_unit                           cv(\"age_unit\"), required()  \n",
       "geologic_classes                      cv(\"class\"), required()  \n",
       "lat_n             min(-90), max(90), min(\"lat_s\"), required()  \n",
       "lat_s             min(-90), max(90), max(\"lat_n\"), required()  \n",
       "lithologies                       cv(\"lithology\"), required()  \n",
       "location                                           required()  \n",
       "location_type                 cv(\"location_type\"), required()  \n",
       "lon_e                            min(0), max(360), required()  \n",
       "lon_w                            min(0), max(360), required()  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data_model)\n",
    "reload(data_model)\n",
    "\n",
    "model_container = data_model.DataModel()\n",
    "\n",
    "dm = model_container.dm\n",
    "locs = dm['locations']\n",
    "#dm['locations']['validations'].str.join(\", \")\n",
    "locs['str_validations'] = locs['validations'].str.join(\", \")\n",
    "locs[locs['str_validations'].str.contains(\"required\\(\\)\").fillna(False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Age', u'Metadata', u'Anisotropy', u'Geology', u'Result', u'Geography', u'Direction', u'Names', u'Site', u'Paleointensity', u'Magnetization', u'Paleoposition', u'VADM', u'VDM', u'VGP']\n"
     ]
    }
   ],
   "source": [
    "print model_container.get_groups('sites')\n",
    "#print type(model_container.get_headers('sites', 'Age'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Controlled vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I- Getting method codes from earthref.org\n",
      "-I- Importing controlled vocabularies from https://earthref.org\n",
      "-I- Getting method codes from earthref.org\n",
      "-I- Importing controlled vocabularies from https://earthref.org\n",
      "-I- Importing suggested vocabularies from https://earthref.org\n",
      "[u'cv(\"class\")', u'required()']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age_unit                 [Ga, Ka, Ma, Years AD (+/-), Years BP, Years C...\n",
       "alteration_grade           [Altered, High, Mild, Severe, Trace, Unaltered]\n",
       "alteration_type          [Acid Leaching, Acid Oxidation, Acid Sulphate,...\n",
       "aniso_s_unit             [SI, Am^2, bulk in measurements table, Normali...\n",
       "aniso_type                                         [AMS, AARM, ATRM, AIRM]\n",
       "assemblage               [Aggregate, In Situ, Mineral Separate, Polycry...\n",
       "mineral_assemblage       [Aggregate, In Situ, Mineral Separate, Polycry...\n",
       "int_scat                                  [True, False, true, false, 0, 1]\n",
       "is_reviewed                               [True, False, true, false, 0, 1]\n",
       "is_validated                              [True, False, true, false, 0, 1]\n",
       "geologic_classes         [Archeologic, Extraterrestrial, Extrusive, Ign...\n",
       "conglomerate_test                 [+, -, G+, G-, Go, IG+, IG-, IGo, ND, o]\n",
       "contact_test                      [+, -, C+, C-, Co, IC+, IC-, ICo, ND, o]\n",
       "continent_ocean          [Africa, Antarctica, Artic Ocean, Asia, Atlant...\n",
       "country                  [Afghanistan, Albania, Algeria, American Samoa...\n",
       "criterion_operation      [<, <=, =, >, >=, begins with, ends with, does...\n",
       "int_corr                                                            [c, u]\n",
       "orientation_quality                                                 [b, g]\n",
       "quality                                                             [b, g]\n",
       "result_quality                                                      [b, g]\n",
       "result_type                                                   [a, i, m, s]\n",
       "external_database_ids    [20D, ARCHEO00, ARCHEOINTB, ARCH_AU, ARCH_BU, ...\n",
       "fold_test                [+, -, F+, F-, Fo, ND, RF+, RF-, RFo, SF+, SF-...\n",
       "lithologies              [Acapulcoite Primitive Achondrite, Achondrite,...\n",
       "location_type            [Archeological Site, Core, Drill Site, Laborat...\n",
       "magic_version                                    [2.2, 2.3, 2.4, 2.5, 3.0]\n",
       "standard                                                            [s, u]\n",
       "mineral_class            [Actinolite, Adularia, Aegirine, Albite, Allan...\n",
       "critical_temp_mineral    [Alteration, Antiferromagnetic, Biogenic, Cant...\n",
       "mineral_type             [Alteration, Antiferromagnetic, Biogenic, Cant...\n",
       "dir_nrm_origin                                                      [p, s]\n",
       "ocean_sea                [Adriatic Sea, Aegean Sea, Alboran Sea, Arabia...\n",
       "plate_blocks             [Adriatic Plate, Aegean Sea Plate, African Pla...\n",
       "dir_polarity                                               [e, i, n, r, t]\n",
       "reversal_test                            [+, -, ND, R-, Ra, Rb, Rc, Ro, o]\n",
       "rock_magnetic_test                                                 [M, ND]\n",
       "material_type            [Annealed, Ball Milled, Biogenic, Ceramic, Che...\n",
       "tectonic_settings        [Accreted Terrain, Accretionary Orogen, Accret...\n",
       "critical_temp_type       [Alteration, Blocking, Curie, Ferrimagnetic Py...\n",
       "texture                  [Agmatitic, Amygdaloidal, Angular, Antiperthit...\n",
       "timescale_eon                          [Archean, Phanerozoic, Proterozoic]\n",
       "timescale_epoch          [Cisuralian, Early Cambrian, Early Cretaceous,...\n",
       "timescale_era            [Cenozoic, Eoarchean, Mesoarchean, Mesoprotero...\n",
       "timescale_period         [Calymmian, Cambrian, Carboniferous, Cretaceou...\n",
       "timescale_stage          [Aalenian, Aeronian, Albian, Anisian, Aptian, ...\n",
       "geologic_types           [Baked Clay, Baked Contact, Baked Mud, Baked R...\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure various pieces of the controlled vocabulary stuff works\n",
    "\n",
    "import pmagpy.controlled_vocabularies3 as cv\n",
    "import pmagpy.data_model3 as dm\n",
    "import numpy as np\n",
    "reload(dm)\n",
    "reload(cv)\n",
    "#print dir(cv)\n",
    "\n",
    "\n",
    "#print dir(cv.vocab)\n",
    "vc = cv.Vocabulary()\n",
    "all_codes, code_types = vc.get_meth_codes()\n",
    "vc.get_tiered_meth_category('other', all_codes, code_types)\n",
    "data = vc.get_controlled_vocabularies()\n",
    "\n",
    "vc.get_tiered_meth_category_offline()\n",
    "vc.get_all_vocabulary()\n",
    "\n",
    "\n",
    "\n",
    "def get_cv_from_list(lst):\n",
    "    \"\"\"\n",
    "    If there is a controlled vocabulary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for i in lst:\n",
    "            if \"cv(\" in i:\n",
    "                return i[4:-2]\n",
    "    except TypeError:\n",
    "        return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "data_model = dm.DataModel()\n",
    "dir(data_model)\n",
    "data_model.dm['sites']\n",
    "site_dm = data_model.dm['sites']\n",
    "site_dm['vocab_name'] = site_dm['validations'].apply(get_cv_from_list)\n",
    "site_dm[['vocab_name', 'validations']][site_dm['vocab_name'].notnull()]\n",
    "\n",
    "\n",
    "dir(vc)\n",
    "print site_dm.ix['geologic_classes']['validations']\n",
    "vc.vocabularies['geologic_classes'][:5]\n",
    "vc.vocabularies['age_unit']\n",
    "vc.vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I- Importing controlled vocabularies from https://earthref.org\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age_unit            [Ga, Ka, Ma, Years AD (+/-), Years BP, Years C...\n",
       "alteration_grade      [Altered, High, Mild, Severe, Trace, Unaltered]\n",
       "alteration_type     [Acid Leaching, Acid Oxidation, Acid Sulphate,...\n",
       "aniso_s_unit        [SI, Am^2, bulk in measurements table, Normali...\n",
       "aniso_type                                    [AMS, AARM, ATRM, AIRM]\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pmagpy.controlled_vocabularies3 as cv\n",
    "import pmagpy.data_model3 as dm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "reload(dm)\n",
    "reload(cv)\n",
    "#print dir(cv)\n",
    "\n",
    "\n",
    "#print dir(cv.vocab)\n",
    "vocab = cv.Vocabulary()\n",
    "vocabulary = vocab.get_controlled_vocabularies()\n",
    "vocabulary.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    takes in a dictionary and a mapping which contains new key names,\n",
      "    and returns a new dictionary with the updated key names, i.e.:\n",
      "    dictionary = {'a': 1, 'b': 2, 'c': 3}\n",
      "    mapping = {'a': 'aa', 'c': 'cc'}\n",
      "    mapped_dictionary = mapping(dictionary, mapping)\n",
      "    mapped_dictionary = {'aa': 1, b, 2, 'cc': 3}\n",
      "    \n",
      "{'specimen_theta': 0, 'fail_ptrm_beta_box_scatter': 1, 'specimen_int_dang': 2, 'specimen_dec': 37, 'specimen_mdev': 5, 'specimen_drat': 52, 'lab_dc_field': 55, 'specimen_k_prime_sse': 49, 'specimen_frac': 8, 'measurement_step_max': 10, 'specimen_PCA_sigma_max': 12, 'specimen_PCA_sigma_min': 53, 'specimen_drats': 40, 'specimen_PCA_sigma_int': 39, 'specimen_b_sigma': 4, 'specimen_ptrms_inc': 17, 'specimen_r_sq': 23, 'specimen_mdrat': 58, 'specimen_dac': 19, 'specimen_dck': 20, 'specimen_gamma': 21, 'specimen_scat_bounding_line_high': 11, 'specimen_int_n': 18, 'specimen_z_md': 24, 'specimen_ac_n': 61, 'specimen_scat_bounding_line_low': 25, 'specimen_inc': 9, 'specimen_int_alpha': 41, 'specimen_int_ptrm_tail_n': 29, 'specimen_cdrat': 30, 'specimen_maxdev': 31, 'specimen_int_uT': 26, 'specimen_int_crm': 7, 'specimen_b': 34, 'specimen_cm_y': 35, 'specimen_cm_x': 36, 'specimen_ptrm': 3, 'specimen_int_mad_anc': 38, 'specimen_fvds': 15, 'specimen_md': 22, 'specimen_b_beta': 16, 'specimen_k_sse': 42, 'specimen_ptrms_dec': 43, 'specimen_gmax': 27, 'fail_arai_beta_box_scatter': 46, 'specimen_g': 45, 'fail_tail_beta_box_scatter': 33, 'specimen_int_ptrm_n': 48, 'specimen_int_mad': 32, 'specimen_f': 47, 'specimen_ptrms_mad': 51, 'specimen_ptrms_angle': 6, 'specimen_dpal': 44, 'specimen_q': 14, 'specimen_tail_drat': 54, 'specimen_dt': 28, 'measurement_step_min': 56, 'specimen_PCA_v1': 57, 'specimen_k_prime': 59, 'specimen_scat': 60, 'specimen_z': 13, 'specimen_coeff_det_sq': 62, 'specimen_k': 50, 'specimen_dtr': 63}\n",
      "{'MAD_Anc': 38, 'R_corr2': 62, 'fail_ptrm_beta_box_scatter': 1, 'ptrms_angle_Free': 6, 'scat_bounding_line_low': 25, 'PCA_sigma_int_Free': 39, 'PCA_sigma_max_Free': 12, 'max_ptrm_check': 3, 'pTRM_MAD_Free': 51, 'lab_dc_field': 55, 'specimen_int_crm': 7, 'PCA_sigma_min_Free': 53, 'B_anc': 26, 'alpha': 41, 'delta_pal': 44, 'DRAT_tail': 54, 'specimen_dt': 28, 'Inc_Free': 9, 'R_det2': 23, 'best_fit_vector_Free': 57, 'specimen_fvds': 15, 'delta_AC': 19, 'specimen_g': 45, 'delta_CK': 20, 'specimen_k_prime_SSE': 49, 'y_Arai_mean': 35, 'MD_VDS': 22, 'specimen_int_n': 18, 'theta': 0, 'MAD_Free': 32, 'n_ptrm': 48, 'DRAT': 52, 'FRAC': 8, 'x_Arai_mean': 36, 'CDRAT': 30, 'Z': 13, 'Dec_Free': 37, 'mean_DEV': 5, 'tmin': 56, 'delta_TR': 63, 'SCAT': 60, 'DRATS': 40, 'n_add': 61, 'specimen_k_prime': 59, 'specimen_b_sigma': 4, 'fail_tail_beta_box_scatter': 33, 'max_DEV': 31, 'specimen_b': 34, 'fail_arai_beta_box_scatter': 46, 'mean_DRAT': 58, 'IZZI_MD': 24, 'tmax': 10, 'specimen_f': 47, 'specimen_q': 14, 'specimen_b_beta': 16, 'ptrms_inc_Free': 17, 'n_tail': 29, 'GAP-MAX': 27, 'SSE': 42, 'DANG': 2, 'ptrms_dec_Free': 43, 'specimen_k': 50, 'gamma': 21, 'scat_bounding_line_high': 11}\n"
     ]
    }
   ],
   "source": [
    "from pmagpy.mapping import map_magic\n",
    "reload(map_magic)\n",
    "dir(map_magic)\n",
    "\n",
    "x = map_magic.magic2spd_map.pop('specimen_YT')\n",
    "print map_magic.mapping.__doc__#(map_magic.magic2spd_map\n",
    "d = dict(zip(map_magic.magic2spd_map.keys(), range(len(map_magic.magic2spd_map.keys()))))\n",
    "print d\n",
    "d2 = map_magic.mapping(d, map_magic.magic2spd_map)\n",
    "print d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Ga',\n",
       " u'Ka',\n",
       " u'Ma',\n",
       " u'Years AD (+/-)',\n",
       " u'Years BP',\n",
       " u'Years Cal AD (+/-)',\n",
       " u'Years Cal BP']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print vc.possible_vocabularies\n",
    "vc.vocabularies['age_unit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I- Getting method codes from earthref.org\n",
      "-I- Importing controlled vocabularies from https://earthref.org\n",
      "-I- Importing suggested vocabularies from https://earthref.org\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'int_b_beta': '0.1',\n",
       " 'int_dang': '10.0',\n",
       " 'int_frac': '0.78',\n",
       " 'int_mad': '5.0',\n",
       " 'int_n_ptrm': '2.0',\n",
       " 'int_n_specimens': '3.0',\n",
       " 'int_scat': 'True',\n",
       " 'int_sigma': '6e-06',\n",
       " 'int_sigma_perc': '15.0'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# working on criteria for lisa\n",
    "\n",
    "import os\n",
    "import pmagpy.contribution_builder as cb\n",
    "wdir = os.path.join('..', \"3_0\", \"McMurdo\")\n",
    "contribution = cb.Contribution(wdir, read_tables=['criteria'])\n",
    "crit_container = contribution.tables['criteria']\n",
    "crit_data = crit_container.df\n",
    "crit_data = crit_data[crit_data['criterion'].str.contains('IE-')==True] # fish out all the relavent data\n",
    "crit_dict = dict(crit_data['criterion_value'])\n",
    "{key.split(\".\")[1]: value for key, value in crit_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
