name: Cornell Natural Language Visual Reasoning
tags:
  - visual reasoning
  - visual inference

links:
  website: http://lic.nlp.cornell.edu/nlvr/
  paper: http://alanesuhr.com/suhr2017.pdf
  readme: https://github.com/clic-lab/nlvr/blob/master/README.md

description: |
  Cornell Natural Language Visual Reasoning (NLVR) is a language grounding dataset.
  It contains 92,244 pairs of natural language statements grounded in synthetic images.
  The task is to determine whether a sentence is true or false about an image.
  The data was collected through crowdsourcing, and requires reasoning about sets of objects,
  quantities, comparisons, and spatial relations.

# download: https://github.com/clic-lab/nlvr.git

splits:
  train:
    images: train/images/*.png
    labels: train/train.json
  dev:
    images: dev/images/*.png
    labels: dev/dev.json
  test:
    images: test/images/*.png
    labels: test/test.json
