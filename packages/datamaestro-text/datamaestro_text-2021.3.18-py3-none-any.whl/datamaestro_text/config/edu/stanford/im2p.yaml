# name: IM2P
# website: https://cs.stanford.edu/people/ranjaykrishna/im2p/index.html
# tags:
#   - image
#   - caption
#   - paragraphs

# papers:
#   technical description:
#     url: https://arxiv.org/pdf/1611.06607.pdf
#     bibtex: |
#       @inproceedings{krause2016paragraphs,
#         title={A Hierarchical Approach for Generating Descriptive Image Paragraphs},
#         author={Krause, Jonathan and Johnson, Justin and Krishna, Ranjay and Fei-Fei,
#         Li}, booktitle={Computer Vision and Patterm Recognition (CVPR)}, year={2017}
#       }

# description: |
#    Recent progress on image captioning has made it possible to generate novel
#    sentences describing images in natural language, but compressing an image
#    into a single sentence can describe visual content in only coarse detail.
#    While one new captioning approach, dense captioning, can potentially describe
#    images in finer levels of detail by captioning many regions within an image,
#    it in turn is unable to produce a coherent story for an image. In this paper
#    we overcome these limitations by generating entire paragraphs for describing
#    images, which can tell detailed, unified stories. We develop a model that
#    decomposes both images and paragraphs into their constituent parts, detecting
#    semantic regions in images and using a hierarchical recurrent neural network
#    to reason about language. Linguistic analysis confirms the complexity of the
#    paragraph generation task, and thorough experiments on a new dataset of image
#    and paragraph pairs demonstrate the effectiveness of our approach.

#     With this paper, we are releasing a new dataset to allow researchers to
#     benchmark their progress in generating paragraphs that tell a story about an
#     image. The dataset contains 19,561 images from the Visual Genome dataset.
#     Each image contains one paragraph. The training/val/test sets contains
#     14,575/2487/2489 images. We show in our paper that the paragraphs are more
#     diverse than their corresponding sentences descriptions with more verbs,
#     co-references and adjectives.

#     Since all the images are also part of the Visual Genome dataset, Each image also
#     contains 50 region descriptions (short phrases describing parts of an image), 35
#     objects, 26 attributes and 21 relationships and 17 question-answer pairs.

#     ![https://cs.stanford.edu/people/ranjaykrishna/im2p/examples.png]

# download: !@/multiple:List
#   paragraphs: !@/single:File
#     url: http://visualgenome.org/static/data/dataset/paragraphs_v1.json.zip
#   train: !@/single:File
#     url: https://cs.stanford.edu/people/ranjaykrishna/im2p/train_split.json
#   val: !@/single:File
#     url: https://cs.stanford.edu/people/ranjaykrishna/im2p/val_split.json
#   data: !@/single:File
#     url: https://cs.stanford.edu/people/ranjaykrishna/im2p/test_split.json
