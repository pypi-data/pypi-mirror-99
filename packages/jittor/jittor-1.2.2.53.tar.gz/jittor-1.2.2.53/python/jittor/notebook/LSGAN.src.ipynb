{"cells": [{"source": ["# \u56fe\u50cf\u751f\u6210\u4e4bLSGAN\n", "\n", "\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN, Generative Adversarial Networks \uff09\u662f\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u662f\u8fd1\u5e74\u6765\u590d\u6742\u5206\u5e03\u4e0a\u65e0\u76d1\u7763\u5b66\u4e60\u6700\u5177\u524d\u666f\u7684\u65b9\u6cd5\u4e4b\u4e00\u3002GAN\u6a21\u578b\u7531\u751f\u6210\u5668\uff08Generator\uff09\u548c\u5224\u522b\u5668\uff08Discriminator\uff09\u4e24\u4e2a\u90e8\u5206\u7ec4\u6210\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u751f\u6210\u5668\u7684\u76ee\u6807\u5c31\u662f\u5c3d\u91cf\u751f\u6210\u771f\u5b9e\u7684\u56fe\u7247\u53bb\u6b3a\u9a97\u5224\u522b\u5668\u3002\u800c\u5224\u522b\u5668\u7684\u76ee\u6807\u5c31\u662f\u5c3d\u91cf\u628a\u751f\u6210\u5668\u751f\u6210\u7684\u56fe\u7247\u548c\u771f\u5b9e\u7684\u56fe\u7247\u5206\u522b\u5f00\u6765\u3002\u8fd9\u6837\uff0c\u751f\u6210\u5668\u548c\u5224\u522b\u5668\u6784\u6210\u4e86\u4e00\u4e2a\u52a8\u6001\u7684\u201c\u535a\u5f08\u8fc7\u7a0b\u201d\u3002\u8bb8\u591a\u76f8\u5173\u7684\u7814\u7a76\u5de5\u4f5c\u8868\u660eGAN\u80fd\u591f\u4ea7\u751f\u6548\u679c\u975e\u5e38\u771f\u5b9e\u7684\u751f\u6210\u6548\u679c\u3002\n", "\n", "\u672c\u6559\u7a0b\u4f7f\u7528Jittor\u6846\u67b6\u5b9e\u73b0\u4e86\u4e00\u79cd\u7ecf\u5178GAN\u6a21\u578bLSGAN \u3002LSGAN\u5c06GAN\u7684\u76ee\u6807\u51fd\u6570\u7531\u4ea4\u53c9\u71b5\u635f\u5931\u66ff\u6362\u6210\u6700\u5c0f\u4e8c\u4e58\u635f\u5931\uff0c\u4ee5\u6b64\u62d2\u7edd\u4e86\u6807\u51c6GAN\u751f\u6210\u7684\u56fe\u7247\u8d28\u91cf\u4e0d\u9ad8\u4ee5\u53ca\u8bad\u7ec3\u8fc7\u7a0b\u4e0d\u7a33\u5b9a\u8fd9\u4e24\u4e2a\u7f3a\u9677\u3002\u672c\u6559\u7a0b\u901a\u8fc7LSGAN\u7684\u5b9e\u73b0\u4ecb\u7ecd\u4e86Jittor\u6570\u636e\u52a0\u8f7d\u3001\u6a21\u578b\u5b9a\u4e49\u3001\u6a21\u578b\u8bad\u7ec3\u7684\u4f7f\u7528\u65b9\u6cd5\u3002\n", "\n", "LSGAN\u8bba\u6587\uff1a<https://arxiv.org/abs/1611.04076>\n", "\n", "## 1.\u6570\u636e\u96c6\u51c6\u5907\n", "\n", "\u672c\u6559\u7a0b\u4f7f\u7528\u4e24\u79cd\u6570\u636e\u96c6\u8fdb\u884cLSGAN\u7684\u8bad\u7ec3\uff0c\u5206\u522b\u662fJittor\u81ea\u5e26\u7684\u6570\u636e\u96c6MNIST\uff0c\u548c\u7528\u6237\u6784\u5efa\u7684\u6570\u636e\u96c6CelebA\u3002\n", "\n", "\u5982\u679c\u8981\u4f7f\u7528CelebA\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff0c\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u94fe\u63a5\u4e0b\u8f7dCelebA\u6570\u636e\u96c6\u3002\n", "\n", "- CelebA \u6570\u636e\u96c6\uff1a <http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html>\n", "\n", "\u5c06\u4e0b\u8f7d\u7684\u8bad\u7ec3\u6570\u636e\u548c\u9a8c\u8bc1\u6570\u636e\u5206\u522b\u5b58\u50a8\u5728`./data/celebA_train/imgs/`\u548c`./data/celebA_eval/imgs/`\u4e2d\n", "\n", "\u6700\u7ec8\u6570\u636e\u96c6\u7684\u6587\u4ef6\u7ec4\u7ec7\u5982\u4e0b\u3002\n", "\n", "```\n", "# \u6587\u4ef6\u7ec4\u7ec7\n", "\u6839\u76ee\u5f55\n", "|----data\n", "     |----celebA_train\n", "     |    |----imgs\n", "     |----celebA_eval\n", "     |    |----imgs\n", "```\n", "\n", "## 2.\u6a21\u578b\u5b9a\u4e49\n", "\n", "\u672c\u6559\u7a0b\u4f7f\u7528LSGAN\u8fdb\u884c\u56fe\u50cf\u751f\u6210\uff0c\u5176\u7f51\u7edc\u7ed3\u6784\u7531\u751f\u6210\u5668\u548c\u522b\u5668\u3002\u751f\u6210\u5668\u7f51\u7edc\u8f93\u5165\u4e00\u4e2a`1024`\u7ef4\u7684\u5411\u91cf\uff0c\u751f\u6210\u5206\u8fa8\u7387\u4e3a`112*112`\u7684\u56fe\u50cf\uff1b\u5224\u522b\u5668\u7f51\u7edc\u8f93\u5165`112*112`\u7684\u56fe\u50cf\uff0c\u8f93\u51fa\u4e00\u4e2a\u6570\u5b57\u8868\u793a\u8f93\u5165\u56fe\u50cf\u4e3a\u771f\u5b9e\u56fe\u50cf\u7684\u53ef\u4fe1\u7a0b\u5ea6\u3002\n", "\n", "\u4e0b\u9762\u5206\u522b\u5b9a\u4e49\u751f\u6210\u5668\u548c\u5224\u522b\u5668"], "metadata": {}, "cell_type": "markdown"}, {"source": ["import jittor as jt\n", "from jittor import nn, Module, init\n", "from jittor.dataset.mnist import MNIST\n", "from jittor.dataset.dataset import ImageFolder\n", "import jittor.transform as transform\n", "import os\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "# \u901a\u8fc7use_cuda\u8bbe\u7f6e\u5728GPU\u4e0a\u8fdb\u884c\u8bad\u7ec3\n", "jt.flags.use_cuda = 1\n", "\n", "class generator(Module):\n", "    def __init__(self, dim=3):\n", "        super(generator, self).__init__()\n", "        self.fc = nn.Linear(1024, 7*7*256)\n", "        self.fc_bn = nn.BatchNorm(256)\n", "        self.deconv1 = nn.ConvTranspose(256, 256, 3, 2, 1, 1)\n", "        self.deconv1_bn = nn.BatchNorm(256)\n", "        self.deconv2 = nn.ConvTranspose(256, 256, 3, 1, 1)\n", "        self.deconv2_bn = nn.BatchNorm(256)\n", "        self.deconv3 = nn.ConvTranspose(256, 256, 3, 2, 1, 1)\n", "        self.deconv3_bn = nn.BatchNorm(256)\n", "        self.deconv4 = nn.ConvTranspose(256, 256, 3, 1, 1)\n", "        self.deconv4_bn = nn.BatchNorm(256)\n", "        self.deconv5 = nn.ConvTranspose(256, 128, 3, 2, 1, 1)\n", "        self.deconv5_bn = nn.BatchNorm(128)\n", "        self.deconv6 = nn.ConvTranspose(128, 64, 3, 2, 1, 1)\n", "        self.deconv6_bn = nn.BatchNorm(64)\n", "        self.deconv7 = nn.ConvTranspose(64 , dim, 3, 1, 1)\n", "        self.relu = nn.ReLU()\n", "        self.tanh = nn.Tanh()\n", "\n", "    def execute(self, input):\n", "        x = self.fc(input).reshape((input.shape[0], 256, 7, 7))\n", "        x = self.relu(self.fc_bn(x))\n", "        x = self.relu(self.deconv1_bn(self.deconv1(x)))\n", "        x = self.relu(self.deconv2_bn(self.deconv2(x)))\n", "        x = self.relu(self.deconv3_bn(self.deconv3(x)))\n", "        x = self.relu(self.deconv4_bn(self.deconv4(x)))\n", "        x = self.relu(self.deconv5_bn(self.deconv5(x)))\n", "        x = self.relu(self.deconv6_bn(self.deconv6(x)))\n", "        x = self.tanh(self.deconv7(x))\n", "        return x\n", "\n", "\n", "class discriminator(nn.Module):\n", "    def __init__(self, dim=3):\n", "        super(discriminator, self).__init__()\n", "        self.conv1 = nn.Conv(dim, 64, 5, 2, 2)\n", "        self.conv2 = nn.Conv(64, 128, 5, 2, 2)\n", "        self.conv2_bn = nn.BatchNorm(128)\n", "        self.conv3 = nn.Conv(128, 256, 5, 2, 2)\n", "        self.conv3_bn = nn.BatchNorm(256)\n", "        self.conv4 = nn.Conv(256, 512, 5, 2, 2)\n", "        self.conv4_bn = nn.BatchNorm(512)\n", "        self.fc = nn.Linear(512*7*7, 1)\n", "        self.leaky_relu = nn.Leaky_relu()\n", "\n", "    def execute(self, input):\n", "        x = self.leaky_relu(self.conv1(input), 0.2)\n", "        x = self.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n", "        x = self.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n", "        x = self.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n", "        x = x.reshape((x.shape[0], 512*7*7))\n", "        x = self.fc(x)\n", "        return x"], "metadata": {}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["\u635f\u5931\u51fd\u6570\u91c7\u7528\u6700\u5c0f\u4e8c\u4e58\u635f\u5931\u51fd\u6570\u3002\u5177\u4f53\u5b9e\u73b0\u5982\u4e0b\uff0c`x`\u4e3a\u751f\u6210\u5668\u7684\u8f93\u51fa\u503c\uff0c`b`\u8868\u793a\u8be5\u56fe\u50cf\u662f\u5426\u5e0c\u671b\u88ab\u5224\u522b\u4e3a\u771f\u3002"], "metadata": {}, "cell_type": "markdown"}, {"source": ["def ls_loss(x, b):\n", "    mini_batch = x.shape[0]\n", "    y_real_ = jt.ones((mini_batch,))\n", "    y_fake_ = jt.zeros((mini_batch,))\n", "    if b:\n", "        return (x-y_real_).sqr().mean()\n", "    else:\n", "        return (x-y_fake_).sqr().mean()"], "metadata": {}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["## 3.\u6a21\u578b\u8bad\u7ec3\n", "\n", "\u53c2\u6570\u8bbe\u5b9a\u5982\u4e0b\uff1a"], "metadata": {}, "cell_type": "markdown"}, {"source": ["# \u4f7f\u7528 MNIST \u6216\u8005 CelebA\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\n", "task = \"MNIST\"\n", "# task = \"CelebA\"\n", "# \u6279\u5927\u5c0f\n", "batch_size = 128\n", "# \u5b66\u4e60\u7387\n", "lr = 0.0002\n", "# \u8bad\u7ec3\u8f6e\u6570\n", "train_epoch = 20 if task==\"MNIST\" else 50\n", "# \u8bad\u7ec3\u56fe\u50cf\u6807\u51c6\u5927\u5c0f\n", "img_size = 112\n", "# Adam\u4f18\u5316\u5668\u53c2\u6570\n", "betas = (0.5,0.999)\n", "# \u6570\u636e\u96c6\u56fe\u50cf\u901a\u9053\u6570\uff0cMNIST\u4e3a1\uff0cCelebA\u4e3a3\n", "dim = 1 if task==\"MNIST\" else 3\n", "# \u7ed3\u679c\u56fe\u7247\u5b58\u50a8\u8def\u5f84\n", "save_path = \"./results_img\""], "metadata": {}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["\u5206\u522b\u58f0\u660e\u751f\u6210\u5668\u548c\u5224\u522b\u5668\uff0c\u5e76\u4f7f\u7528Adam\u4f5c\u4e3a\u4f18\u5316\u5668\u3002"], "metadata": {}, "cell_type": "markdown"}, {"source": ["G = generator (dim)\n", "D = discriminator (dim)\n", "G_optim = nn.Adam(G.parameters(), lr, betas=betas)\n", "D_optim = nn.Adam(D.parameters(), lr, betas=betas)"], "metadata": {}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["jittor\u81ea\u5e26\u6709MNIST\u6570\u636e\u96c6\u3002\u4f7f\u7528`jittor.transform`\u53ef\u4ee5\u8fdb\u884c\u6570\u636e\u5f52\u4e00\u5316\u53ca\u6570\u636e\u589e\u5f3a\uff0c\u8fd9\u91cc\u672c\u6559\u7a0b\u901a\u8fc7`transform`\u5c06\u56fe\u7247\u5f52\u4e00\u5316\u5230\u6307\u5b9a\u533a\u95f4\uff0c\u5e76resize\u5230\u6807\u51c6\u5927\u5c0f`112*112`\u3002\u3002\u901a\u8fc7`set_attrs`\u51fd\u6570\u53ef\u4ee5\u4fee\u6539\u6570\u636e\u96c6\u7684\u76f8\u5173\u53c2\u6570\uff0c\u5982`batch_size`\u3001`shuffle`\u53ca`transform`\u7b49\u3002\n", "\n", "\u5982\u679c\u4f7f\u7528\u81ea\u5df1\u6784\u5efaCelebA\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff0c\u53ef\u4ee5\u901a\u8fc7\u901a\u7528\u6570\u636e\u52a0\u8f7d\u5668`jittor.dataset.dataset.ImageFolder`\uff0c\u8f93\u5165\u6570\u636e\u96c6\u8def\u5f84\u5373\u53ef\u6784\u5efa\u7528\u6237\u6570\u636e\u96c6\u3002\n", "\n", "\u6784\u5efa\u6570\u636e\u96c6\u4ee3\u7801\u5982\u4e0b\uff1a"], "metadata": {}, "cell_type": "markdown"}, {"source": ["if task==\"MNIST\":\n", "    transform = transform.Compose([\n", "        transform.Resize(size=img_size),\n", "        transform.Gray(),\n", "        transform.ImageNormalize(mean=[0.5], std=[0.5]),\n", "    ])\n", "    train_loader = MNIST(train=True, transform=transform).set_attrs(batch_size=batch_size, shuffle=True)\n", "    eval_loader = MNIST(train=False, transform = transform).set_attrs(batch_size=batch_size, shuffle=True)\n", "elif task==\"CelebA\":\n", "    transform = transform.Compose([\n", "        transform.Resize(size=img_size),\n", "        transform.ImageNormalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n", "    ])\n", "    train_dir = './data/celebA_train'\n", "    train_loader = ImageFolder(train_dir).set_attrs(transform=transform, batch_size=batch_size, shuffle=True)\n", "    eval_dir = './data/celebA_eval'\n", "    eval_loader = ImageFolder(eval_dir).set_attrs(transform=transform, batch_size=batch_size, shuffle=True)"], "metadata": {}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["\u8bad\u7ec3\u548c\u9a8c\u8bc1\u4ee3\u7801\u5982\u4e0b\uff1a"], "metadata": {}, "cell_type": "markdown"}, {"source": ["def train(epoch):\n", "    for batch_idx, (x_, target) in enumerate(train_loader):\n", "        mini_batch = x_.shape[0]\n", "        # train discriminator\n", "        D_result = D(x_)\n", "        D_real_loss = ls_loss(D_result, True)\n", "        z_ = jt.init.gauss((mini_batch, 1024), 'float')\n", "        G_result = G(z_)\n", "        D_result_ = D(G_result)\n", "        D_fake_loss = ls_loss(D_result_, False)\n", "        D_train_loss = D_real_loss + D_fake_loss\n", "        D_train_loss.sync()\n", "        D_optim.step(D_train_loss)\n", "\n", "        # train generator\n", "        z_ = jt.init.gauss((mini_batch, 1024), 'float')\n", "        G_result = G(z_)\n", "        D_result = D(G_result)\n", "        G_train_loss = ls_loss(D_result, True)\n", "        G_train_loss.sync()\n", "        G_optim.step(G_train_loss)\n", "        if (batch_idx%100==0):\n", "            print(\"train: batch_idx\",batch_idx,\"epoch\",epoch)\n", "            print('  D training loss =', D_train_loss.data.mean())\n", "            print('  G training loss =', G_train_loss.data.mean())\n", "\n", "def validate(epoch):\n", "    D_losses = []\n", "    G_losses = []\n", "    G.eval()\n", "    D.eval()\n", "    for batch_idx, (x_, target) in enumerate(eval_loader):\n", "        mini_batch = x_.shape[0]\n", "        \n", "        # calculation discriminator loss\n", "        D_result = D(x_)\n", "        D_real_loss = ls_loss(D_result, True)\n", "        z_ = jt.init.gauss((mini_batch, 1024), 'float')\n", "        G_result = G(z_)\n", "        D_result_ = D(G_result)\n", "        D_fake_loss = ls_loss(D_result_, False)\n", "        D_train_loss = D_real_loss + D_fake_loss\n", "        D_losses.append(D_train_loss.data.mean())\n", "\n", "        # calculation generator loss\n", "        z_ = jt.init.gauss((mini_batch, 1024), 'float')\n", "        G_result = G(z_)\n", "        D_result = D(G_result)\n", "        G_train_loss = ls_loss(D_result, True)\n", "        G_losses.append(G_train_loss.data.mean())\n", "    G.train()\n", "    D.train()\n", "    print(\"validate: epoch\",epoch)\n", "    print('  D validate loss =', np.array(D_losses).mean())\n", "    print('  G validate loss =', np.array(G_losses).mean())"], "metadata": {}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["\u4f7f\u7528\u6bcf\u4e2aepoch\u7684\u751f\u6210\u5668\u901a\u8fc7\u56fa\u5b9a\u5411\u91cf\u751f\u6210\u56fe\u7247\uff0c\u5c06\u56fe\u7247\u663e\u793a\u5e76\u5b58\u50a8\u5728`./results_img/`\u4e2d"], "metadata": {}, "cell_type": "markdown"}, {"source": ["if not os.path.exists(save_path):\n", "    os.mkdir(save_path)\n", "fixed_z_ = jt.init.gauss((5 * 5, 1024), 'float')\n", "def save_result(num_epoch, G , path = 'result.png'):\n", "    \"\"\"Use the current generator to generate 5*5 pictures and store them.\n", "\n", "    Args:\n", "        num_epoch(int): current epoch\n", "        G(generator): current generator\n", "        path(string): storage path of result image\n", "    \"\"\"\n", "\n", "    z_ = fixed_z_\n", "    G.eval()\n", "    test_images = G(z_)\n", "    G.train()\n", "    size_figure_grid = 5\n", "    fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(5, 5))\n", "    for i in range(size_figure_grid):\n", "        for j in range(size_figure_grid):\n", "            ax[i, j].get_xaxis().set_visible(False)\n", "            ax[i, j].get_yaxis().set_visible(False)\n", "\n", "    for k in range(5*5):\n", "        i = k // 5\n", "        j = k % 5\n", "        ax[i, j].cla()\n", "        if task==\"MNIST\":\n", "            ax[i, j].imshow((test_images[k, 0].data+1)/2, cmap='gray')\n", "        else:\n", "            ax[i, j].imshow((test_images[k].data.transpose(1, 2, 0)+1)/2)\n", "\n", "    label = 'Epoch {0}'.format(num_epoch)\n", "    fig.text(0.5, 0.04, label, ha='center')\n", "    plt.savefig(path)\n", "    plt.show()"], "metadata": {}, "cell_type": "code", "outputs": [], "execution_count": null}, {"source": ["\u73b0\u5728\uff0c\u8ba9\u6211\u4eec\u8bad\u7ec3\u4e00\u756a\u8bd5\u8bd5\uff01"], "metadata": {}, "cell_type": "markdown"}, {"source": ["for epoch in range(train_epoch):\n", "    print ('number of epochs', epoch)\n", "    train(epoch)\n", "    validate(epoch)\n", "    result_img_path = './results_img/' + task + str(epoch) + '.png'\n", "    save_result(epoch, G, path=result_img_path)"], "metadata": {}, "cell_type": "code", "outputs": [], "execution_count": null}], "nbformat": 4, "nbformat_minor": 2, "metadata": {}}