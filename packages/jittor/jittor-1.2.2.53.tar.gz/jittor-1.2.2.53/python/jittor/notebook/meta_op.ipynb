{"cells": [{"source": ["# Meta-operator: Implement your own convolution with Meta-operator\n", "\n", "\n", "Meta-operator is a key concept of jittor, The hierarchical architecture of meta-operators is shown below.\n", "\n", "The meta-operators are consist of reindex, reindex-reduce and element-wise operators. Reindex and reindex-reduce operators are both unary operators. The reindex operator is a one-to-many mapping between its input and output. And the reindex-reduce operator is a many-to-one mapping. Broadcast, pad and slice operators are common reindex operators. And reduce, product and sum are common reindex-reduce operators. Element-wise operator is the third component of meta-operators. Compared to the first two, element-wise operators may contain multiple inputs. But all the input and output shapes of element-wise operators must be the same. And they are one-to-one mapped. For example, the addition of two variables is a binary element-wise operator.\n", "\n", "\n", "\n", "> ![](./figs/mop.svg)\n", "> The hierarchical architecture of meta-operators. The meta-operators are consist of reindex, reindex-reduce and element-wise operators. Reindex and reindex-reduce are each other's backward operators. The backward operators of element-wise operators are itself. Those meta-operators are fused into common DL operations, and these DL operators further constitute the model.\n", ">\n", "\n", "In the previous [example](example.ipynb), we have demonstrated how to implement matrix multiplication via three meta-operators:\n", "\n", "```\n", "def matmul(a, b):\n", "    (n, m), k = a.shape, b.shape[-1]\n", "    a = a.broadcast([n,m,k], dims=[2])\n", "    b = b.broadcast([n,m,k], dims=[0])\n", "    return (a*b).sum(dim=1)\n", "```\n", "\n", "In this tutorial, we will show how to implement your own convolution with meta-operator.\n", "\n", "First, let's implement a naive Python convolution:\n", "\n", "```\n", "import numpy as np\n", "import os\n", "def conv_naive(x, w):\n", "    N,H,W,C = x.shape\n", "\n", "    Kh, Kw, _C, Kc = w.shape\n", "    assert C==_C, (x.shape, w.shape)\n", "    y = np.zeros([N,H-Kh+1,W-Kw+1,Kc])\n", "    for i0 in range(N):\n", "        for i1 in range(H-Kh+1): # dimension error\n", "            for i2 in range(W-Kw+1):\n", "                for i3 in range(Kh):\n", "                    for i4 in range(Kw):\n", "                        for i5 in range(C):\n", "                            for i6 in range(Kc):\n", "                                if i1-i3<0 or i2-i4<0 or i1-i3>=H or i2-i4>=W: continue\n", "                                y[i0, i1, i2, i6] += x[i0, i1 + i3, i2 + i4, i5] * w[i3,i4,i5,i6]\n", "    return y\n", "```\n", "\n", "Then, let's download a cat image, and run `conv_naive` with a simple horizontal filte.\n", "\n", "```\n", "# %matplotlib inline\n", "import pylab as pl\n", "img_path=\"/tmp/cat.jpg\"\n", "if not os.path.isfile(img_path):\n", "    !wget -O - 'https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Felis_silvestris_catus_lying_on_rice_straw.jpg/220px-Felis_silvestris_catus_lying_on_rice_straw.jpg' > $img_path\n", "img = pl.imread(img_path)\n", "pl.subplot(121)\n", "pl.imshow(img)\n", "kernel = np.array([\n", "    [-1, -1, -1],\n", "    [0, 0, 0],\n", "    [1, 1, 1],\n", "])\n", "pl.subplot(122)\n", "x = img[np.newaxis,:,:,:1].astype(\"float32\")\n", "w = kernel[:,:,np.newaxis,np.newaxis].astype(\"float32\")\n", "y = conv_naive(x, w)\n", "print (x.shape, y.shape) # shape exists confusion\n", "pl.imshow(y[0,:,:,0])\n", "```\n", "\n", "It looks good, our `naive_conv` works well. Let's replace our naive implementation with jittor.\n", "\n", "```\n", "import jittor as jt\n", "\n", "def conv(x, w):\n", "    N,H,W,C = x.shape\n", "    Kh, Kw, _C, Kc = w.shape\n", "    assert C==_C\n", "    xx = x.reindex([N,H-Kh+1,W-Kw+1,Kh,Kw,C,Kc], [\n", "        'i0', # Nid\n", "        'i1+i3', # Hid+Khid\n", "        'i2+i4', # Wid+KWid\n", "        'i5', # Cid|\n", "    ])\n", "    ww = w.broadcast_var(xx)\n", "    yy = xx*ww\n", "    y = yy.sum([3,4,5]) # Kh, Kw, c\n", "    return y\n", "\n", "# Let's disable tuner. This will cause jittor not to use mkl for convolution\n", "jt.flags.enable_tuner = 0\n", "\n", "jx = jt.array(x)\n", "jw = jt.array(w)\n", "jy = conv(jx, jw).fetch_sync()\n", "print (jx.shape, jy.shape)\n", "pl.imshow(jy[0,:,:,0])\n", "```\n", "\n", "They looks the same. How about the performance?\n", "\n", "```\n", "%time y = conv_naive(x, w)\n", "%time jy = conv(jx, jw).fetch_sync()\n", "```\n", "\n", "The jittor implementation is much faster. So why this two implementation are equivalent in math, and why jittor's implementation is faster? We will explain step by step:\n", "\n", "First, let's take a look at the help document of `jt.reindex`.\n", "\n", "```\n", "help(jt.reindex)\n", "```\n", "\n", "Following the document, we can expand the reindex operation for better understanding:\n", "\n", "```\n", "py\n", "xx = x.reindex([N,H-Kh+1,W-Kw+1,Kh,Kw,C,Kc], [\n", "    'i0', # Nid\n", "    'i1+i3', # Hid+Khid\n", "    'i2+i4', # Wid+KWid\n", "    'i5', # Cid\n", "])\n", "ww = w.broadcast_var(xx)\n", "yy = xx*ww\n", "y = yy.sum([3,4,5]) # Kh, Kw, C\n", "```\n", "\n", "**After expansion:**\n", "\n", "```\n", "py\n", "shape = [N,H-Kh+1,W-Kw+1,Kh,Kw,C,Kc]\n", "# expansion of x.reindex\n", "xx = np.zeros(shape, x.dtype)\n", "for i0 in range(shape[0]):\n", "    for i1 in range(shape[1]):\n", "        for i2 in range(shape[2]):\n", "            for i3 in range(shape[3]):\n", "                for i4 in range(shape[4]):\n", "                    for i5 in range(shape[5]):\n", "                        for i6 in range(shape[6]):\n", "                            if is_overflow(i0,i1,i2,i3,i4,i5,i6):\n", "                                xx[i0,i1,...,in] = 0\n", "                            else:\n", "                                xx[i0,i1,i2,i3,i4,i5,i6] = x[i0,i1+i3,i2+i4,i5]\n", "\n", "# expansion of w.broadcast_var(xx)\n", "ww = np.zeros(shape, x.dtype)\n", "for i0 in range(shape[0]):\n", "    for i1 in range(shape[1]):\n", "        for i2 in range(shape[2]):\n", "            for i3 in range(shape[3]):\n", "                for i4 in range(shape[4]):\n", "                    for i5 in range(shape[5]):\n", "                        for i6 in range(shape[6]):\n", "                            ww[i0,i1,i2,i3,i4,i5,i6] = w[i3,i4,i5,i6]\n", "# expansion of xx*ww\n", "yy = np.zeros(shape, x.dtype)\n", "for i0 in range(shape[0]):\n", "    for i1 in range(shape[1]):\n", "        for i2 in range(shape[2]):\n", "            for i3 in range(shape[3]):\n", "                for i4 in range(shape[4]):\n", "                    for i5 in range(shape[5]):\n", "                        for i6 in range(shape[6]):\n", "                            yy[i0,i1,i2,i3,i4,i5,i6] = xx[i0,i1,i2,i3,i4,i5,i6] * ww[i0,i1,i2,i3,i4,i5,i6]\n", "# expansion of yy.sum([3,4,5])\n", "shape2 = [N,H-Kh+1,W-Kw+1,Kc]\n", "y = np.zeros(shape2, x.dtype)\n", "for i0 in range(shape[0]):\n", "    for i1 in range(shape[1]):\n", "        for i2 in range(shape[2]):\n", "            for i3 in range(shape[3]):\n", "                for i4 in range(shape[4]):\n", "                    for i5 in range(shape[5]):\n", "                        for i6 in range(shape[6]):\n", "                            y[i0,i1,i2,i6] += yy[i0,i1,i2,i3,i4,i5,i6]\n", "```\n", "\n", "**After loop fusion:**\n", "\n", "```\n", "py\n", "shape2 = [N,H-Kh+1,W-Kw+1,Kc]\n", "y = np.zeros(shape2, x.dtype)\n", "for i0 in range(shape[0]):\n", "    for i1 in range(shape[1]):\n", "        for i2 in range(shape[2]):\n", "            for i3 in range(shape[3]):\n", "                for i4 in range(shape[4]):\n", "                    for i5 in range(shape[5]):\n", "                        for i6 in range(shape[6]):\n", "                            if not is_overflow(i0,i1,i2,i3,i4,i5,i6):\n", "                                y[i0,i1,i2,i6] += x[i0,i1+i3,i2+i4,i5] * w[i3,i4,i5,i6]\n", "```\n", "\n", "This is the trick of meta-operator, It can fused multiple operator into a complicated operation, including many variation of convolution (e.g. group conv, seperate conv,...).\n", "\n", "jittor will try to optimize the fused operator as fast as possible. Let's try some optimizations(compile the shapes as constants into the kernel), and show the underlying c++ kernel.\n", "\n", "```\n", "jt.flags.compile_options={\"compile_shapes\":1}\n", "with jt.profile_scope() as report:\n", "    jy = conv(jx, jw).fetch_sync()\n", "jt.flags.compile_options={}\n", "\n", "print(f\"Time: {float(report[1][4])/1e6}ms\")\n", "\n", "with open(report[1][1], 'r') as f:\n", "    print(f.read())\n", "```\n", "\n", "Even faster than the previous implementation! From the output we can look at the function definition of func0. This is the main code of our convolution kernel, which is generated Just-in-time. Because the compiler knows the shapes of the kernel and more optimizations are used. \n", "\n", "\n", "\n", "In this tutorial, Jittor simply demonstrated the use of meta-operators, which is not a performance test. If you need a performance test, `jt.flags.enable_tuner = 1` will try to use the dedicated hardware library."], "metadata": {}, "cell_type": "markdown"}], "nbformat": 4, "nbformat_minor": 2, "metadata": {}}