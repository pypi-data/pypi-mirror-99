# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: tfx_bsl/public/proto/model_spec.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor.FileDescriptor(
  name='tfx_bsl/public/proto/model_spec.proto',
  package='tfx_bsl.model_spec',
  syntax='proto3',
  serialized_options=None,
  serialized_pb=_b('\n%tfx_bsl/public/proto/model_spec.proto\x12\x12tfx_bsl.model_spec\"\xbb\x01\n\x11InferenceSpecType\x12>\n\x10saved_model_spec\x18\x01 \x01(\x0b\x32\".tfx_bsl.model_spec.SavedModelSpecH\x00\x12^\n!ai_platform_prediction_model_spec\x18\x02 \x01(\x0b\x32\x31.tfx_bsl.model_spec.AIPlatformPredictionModelSpecH\x00\x42\x06\n\x04type\"I\n\x0eSavedModelSpec\x12\x12\n\nmodel_path\x18\x01 \x01(\t\x12\x16\n\x0esignature_name\x18\x02 \x03(\t\x12\x0b\n\x03tag\x18\x03 \x03(\t\"\x93\x01\n\x1d\x41IPlatformPredictionModelSpec\x12\x12\n\nproject_id\x18\x01 \x01(\t\x12\x12\n\nmodel_name\x18\x02 \x01(\t\x12\x14\n\x0cversion_name\x18\x03 \x01(\t\x12\"\n\x18use_serialization_config\x18\x04 \x01(\x08H\x00\x42\x10\n\x0e\x65xample_configb\x06proto3')
)




_INFERENCESPECTYPE = _descriptor.Descriptor(
  name='InferenceSpecType',
  full_name='tfx_bsl.model_spec.InferenceSpecType',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='saved_model_spec', full_name='tfx_bsl.model_spec.InferenceSpecType.saved_model_spec', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='ai_platform_prediction_model_spec', full_name='tfx_bsl.model_spec.InferenceSpecType.ai_platform_prediction_model_spec', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='type', full_name='tfx_bsl.model_spec.InferenceSpecType.type',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=62,
  serialized_end=249,
)


_SAVEDMODELSPEC = _descriptor.Descriptor(
  name='SavedModelSpec',
  full_name='tfx_bsl.model_spec.SavedModelSpec',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='model_path', full_name='tfx_bsl.model_spec.SavedModelSpec.model_path', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='signature_name', full_name='tfx_bsl.model_spec.SavedModelSpec.signature_name', index=1,
      number=2, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='tag', full_name='tfx_bsl.model_spec.SavedModelSpec.tag', index=2,
      number=3, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=251,
  serialized_end=324,
)


_AIPLATFORMPREDICTIONMODELSPEC = _descriptor.Descriptor(
  name='AIPlatformPredictionModelSpec',
  full_name='tfx_bsl.model_spec.AIPlatformPredictionModelSpec',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='project_id', full_name='tfx_bsl.model_spec.AIPlatformPredictionModelSpec.project_id', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='model_name', full_name='tfx_bsl.model_spec.AIPlatformPredictionModelSpec.model_name', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='version_name', full_name='tfx_bsl.model_spec.AIPlatformPredictionModelSpec.version_name', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='use_serialization_config', full_name='tfx_bsl.model_spec.AIPlatformPredictionModelSpec.use_serialization_config', index=3,
      number=4, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='example_config', full_name='tfx_bsl.model_spec.AIPlatformPredictionModelSpec.example_config',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=327,
  serialized_end=474,
)

_INFERENCESPECTYPE.fields_by_name['saved_model_spec'].message_type = _SAVEDMODELSPEC
_INFERENCESPECTYPE.fields_by_name['ai_platform_prediction_model_spec'].message_type = _AIPLATFORMPREDICTIONMODELSPEC
_INFERENCESPECTYPE.oneofs_by_name['type'].fields.append(
  _INFERENCESPECTYPE.fields_by_name['saved_model_spec'])
_INFERENCESPECTYPE.fields_by_name['saved_model_spec'].containing_oneof = _INFERENCESPECTYPE.oneofs_by_name['type']
_INFERENCESPECTYPE.oneofs_by_name['type'].fields.append(
  _INFERENCESPECTYPE.fields_by_name['ai_platform_prediction_model_spec'])
_INFERENCESPECTYPE.fields_by_name['ai_platform_prediction_model_spec'].containing_oneof = _INFERENCESPECTYPE.oneofs_by_name['type']
_AIPLATFORMPREDICTIONMODELSPEC.oneofs_by_name['example_config'].fields.append(
  _AIPLATFORMPREDICTIONMODELSPEC.fields_by_name['use_serialization_config'])
_AIPLATFORMPREDICTIONMODELSPEC.fields_by_name['use_serialization_config'].containing_oneof = _AIPLATFORMPREDICTIONMODELSPEC.oneofs_by_name['example_config']
DESCRIPTOR.message_types_by_name['InferenceSpecType'] = _INFERENCESPECTYPE
DESCRIPTOR.message_types_by_name['SavedModelSpec'] = _SAVEDMODELSPEC
DESCRIPTOR.message_types_by_name['AIPlatformPredictionModelSpec'] = _AIPLATFORMPREDICTIONMODELSPEC
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

InferenceSpecType = _reflection.GeneratedProtocolMessageType('InferenceSpecType', (_message.Message,), {
  'DESCRIPTOR' : _INFERENCESPECTYPE,
  '__module__' : 'tfx_bsl.public.proto.model_spec_pb2'
  # @@protoc_insertion_point(class_scope:tfx_bsl.model_spec.InferenceSpecType)
  })
_sym_db.RegisterMessage(InferenceSpecType)

SavedModelSpec = _reflection.GeneratedProtocolMessageType('SavedModelSpec', (_message.Message,), {
  'DESCRIPTOR' : _SAVEDMODELSPEC,
  '__module__' : 'tfx_bsl.public.proto.model_spec_pb2'
  # @@protoc_insertion_point(class_scope:tfx_bsl.model_spec.SavedModelSpec)
  })
_sym_db.RegisterMessage(SavedModelSpec)

AIPlatformPredictionModelSpec = _reflection.GeneratedProtocolMessageType('AIPlatformPredictionModelSpec', (_message.Message,), {
  'DESCRIPTOR' : _AIPLATFORMPREDICTIONMODELSPEC,
  '__module__' : 'tfx_bsl.public.proto.model_spec_pb2'
  # @@protoc_insertion_point(class_scope:tfx_bsl.model_spec.AIPlatformPredictionModelSpec)
  })
_sym_db.RegisterMessage(AIPlatformPredictionModelSpec)


# @@protoc_insertion_point(module_scope)
