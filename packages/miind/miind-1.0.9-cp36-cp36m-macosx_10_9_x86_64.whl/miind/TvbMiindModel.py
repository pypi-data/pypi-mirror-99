# -*- coding: utf-8 -*-
#
#
#  TheVirtualBrain-Scientific Package. This package holds all simulators, and
# analysers necessary to run brain-simulations. You can use it stand alone or
# in conjunction with TheVirtualBrain-Framework Package. See content of the
# documentation-folder for more details. See also http://www.thevirtualbrain.org
#
# (c) 2012-2017, Baycrest Centre for Geriatric Care ("Baycrest") and others
#
# This program is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software Foundation,
# either version 3 of the License, or (at your option) any later version.
# This program is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
# PARTICULAR PURPOSE.  See the GNU General Public License for more details.
# You should have received a copy of the GNU General Public License along with this
# program.  If not, see <http://www.gnu.org/licenses/>.
#
#
#   CITATION:
# When using The Virtual Brain for scientific publications, please cite it as follows:
#
#   Paula Sanz Leon, Stuart A. Knock, M. Marmaduke Woodman, Lia Domide,
#   Jochen Mersmann, Anthony R. McIntosh, Viktor Jirsa (2013)
#       The Virtual Brain: a simulator of primate brain network dynamics.
#   Frontiers in Neuroinformatics (7:10. doi: 10.3389/fninf.2013.00010)

"""
MIIND Adapter class to allow MIIND models to be generically imported and run in TVB.

"""

import numpy
from tvb.simulator.models.base import Model
from tvb.simulator.common import get_logger
from tvb.basic.neotraits.api import NArray, Final, List, Range
import uuid

from miind.miind_api import MiindSimulation

class Miind(Model):
    r"""
    MIIND (Multiple Instantiations of Interacting Neural Dynamics) [MDK_2013] is
    a software package which simulates interacting populations of neurons using
    population density techniques [OM_2000]. It has been implemented here to leverage
    the TVB's connectivity and coupling functionality while performing the actual
    region (node) simulation in MIIND.

    **Technical Notes**:

    The Miind class constructor takes a filename which should point to a shared library
    file generated by MIIND which both defines and performs the simulation for each region.
    When using MIIND in TVB, a user can instantiate this Miind class to be used as the model
    in the simulation then "plug and play" different shared library files from MIIND.

    Shared library files can be generated by MIIND to support MPI. While tvb-library
    source files do not require an MPI implementation, the script to run the TVB
    simulation should call MPI_Init to ensure compatability.

    The Miind model class requires that MIIND has been installed on the system.
    Installation instructions are available at
    http://miind.sourceforge.net/

    **References**:

    .. [MDK_2013] de Kamps, M., 2013. A generic approach to solving jump diffusion
    equations with applications to neural populations. arXiv preprint arXiv:1309.1654.

    .. [OM_2000] Omurtag, A., Knight, B.W. and Sirovich, L., 2000. On the simulation
    of large populations of neurons. Journal of computational neuroscience, 8(1), pp.51-63.

    """

    _ui_name = "MIIND"
    ui_configurable_parameters = []

    # Used for phase-plane axis ranges and to bound random initial() conditions.
    state_variable_range = Final(
        label="State Variable ranges [lo, hi]",
        default={"S": numpy.array([0.0, 1.0])},
        doc="""Population firing rate""")

    variables_of_interest = List(
        of=str,
        label="Variables watched by Monitors",
        choices=("S"),
        default=("S",),
        doc="""default state variables to be monitored""")

    state_variables = ('S')
    _nvar = 1
    cvar = numpy.array([0], dtype=numpy.int32)

    gid = Final( label="gid", default=uuid.uuid1(), doc="""This is a hack""")
    log = get_logger(__name__)

    def __init__(self, sim_file, num_nodes, duplicate_connections=False):
        # In TVB, connection weights can cause input activities to MIIND
        # to go negative (inhibition). MIIND expects to always recieve positive
        # activities with the post synaptic efficacy either excitatory or inhibitory
        # As a work around, we can set duplicate_connections to True
        # All TVB connections will be duplicated with the expectation that 
        # every IncomingConnection in the MIIND simulation is duplicated in the XML:
        # one with a positive efficacy, one with a matching negative efficacy.
        #
        # eg. if in dfun, parameter x multiplied by the coupling yields
        # c_ = [0.24, -3.2, 1.324, -0.52]
        # with duplicate_connections == True
        # cd_ = [0.24, 0.0, 0.0, 3.2, 1.324, 0.0, 0.0, 0.52] will be passed to MIIND
        #
        # See the miind_tvb example.
        self.duplicate_connections = duplicate_connections
        
        sim = MiindSimulation(sim_file)
        
        if sim.requires_cuda:
            print("Group algorithm detected. Importing Cuda MIIND (miindsimv).")
            import miind.miindsimv as miind_sim
        else:
            import miind.miindsim as miind_sim
        self.miind = miind_sim
        # dynamically import the MIIND shared library
        self.number_of_nodes = num_nodes
        self.miind.init(self.number_of_nodes, sim_file)
        self.simulation_length = self.miind.getSimulationLength()
        self.miind_time_step = self.miind.getTimeStep()

    def configure(self):
        """  """
        super(Miind, self).configure()
        self.update_derived_parameters() 
        self.miind.startSimulation()


    def dfun(self, x, c, local_coupling=0.0):

        S = x[0, :]

        # long-range coupling
        c_0 = c[0, :]

        # short-range (local) coupling
        lc_0 = local_coupling * S

        # Would be nice to pass this function as a parameter to make this
        # class more generic
        coupling_S = c_0 + lc_0

        c_ = coupling_S[:,0]
        # In TVB, the coupling can make the incoming activity go negative.
        # MIIND does not allow negative activities (only negative efficacies)
        # To work with TVB, all MIIND simulations must provide a positive and
        # negative efficacy incoming connection.
        # Here we duplicate and negate each incoming activity
        if self.duplicate_connections:
            cn_ = [i*val if i*val > 0 else 0.0 for val in c_.tolist() for i in (1, -1)]
        else:
            cn_ = c_.tolist()
        
        x_ = numpy.array(self.miind.evolveSingleStep(cn_))

        return numpy.reshape(x_, x.shape)