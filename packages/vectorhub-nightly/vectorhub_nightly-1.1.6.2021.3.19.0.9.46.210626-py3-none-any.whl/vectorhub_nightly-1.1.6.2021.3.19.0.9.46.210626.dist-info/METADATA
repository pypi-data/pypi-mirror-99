Metadata-Version: 2.1
Name: vectorhub-nightly
Version: 1.1.6.2021.3.19.0.9.46.210626
Summary: One liner to encode data into vectors with state-of-the-art models using tensorflow, pytorch and other open source libraries. Word2Vec, Image2Vec, BERT, etc
Home-page: https://github.com/vector-ai/vectorhub
Author: OnSearch Pty Ltd
Author-email: dev@vctr.ai
License: Apache
Keywords: vector,embeddings,machinelearning,ai,artificialintelligence,nlp,tensorflow,pytorch,nearestneighbors,search,analytics,clustering,dimensionalityreduction
Platform: UNKNOWN
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: Intended Audience :: Information Technology
Classifier: Intended Audience :: Financial and Insurance Industry
Classifier: Intended Audience :: Healthcare Industry
Classifier: Intended Audience :: Manufacturing
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.4
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: Implementation :: PyPy
Classifier: Topic :: Database
Classifier: Topic :: Multimedia :: Sound/Audio :: Conversion
Classifier: Topic :: Multimedia :: Video :: Conversion
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Image Recognition
Classifier: Topic :: Scientific/Engineering :: Information Analysis
Classifier: Topic :: Scientific/Engineering :: Visualization
Classifier: Topic :: Software Development :: Libraries :: Application Frameworks
Requires-Python: >=3
Description-Content-Type: text/markdown
Requires-Dist: numpy
Requires-Dist: PyYAML
Requires-Dist: vectorai
Requires-Dist: requests
Provides-Extra: pillow
Requires-Dist: Pillow ; extra == 'pillow'
Provides-Extra: pyyaml
Requires-Dist: PyYAML ; extra == 'pyyaml'
Provides-Extra: all
Requires-Dist: fairseq ; extra == 'all'
Requires-Dist: numpy ; extra == 'all'
Requires-Dist: sentence-transformers ; extra == 'all'
Requires-Dist: opencv-python ; extra == 'all'
Requires-Dist: soundfile ; extra == 'all'
Requires-Dist: vectorai ; extra == 'all'
Requires-Dist: pytest ; extra == 'all'
Requires-Dist: PyYAML ; extra == 'all'
Requires-Dist: tensorflow-hub ; extra == 'all'
Requires-Dist: tf-models-official ; extra == 'all'
Requires-Dist: torch (>=1.6.0) ; extra == 'all'
Requires-Dist: transformers ; extra == 'all'
Requires-Dist: requests ; extra == 'all'
Requires-Dist: fastai (==2.1.8) ; extra == 'all'
Requires-Dist: Pillow ; extra == 'all'
Requires-Dist: tensorflow-text ; extra == 'all'
Requires-Dist: appdirs ; extra == 'all'
Requires-Dist: moviepy ; extra == 'all'
Requires-Dist: clip-by-openai ; extra == 'all'
Requires-Dist: librosa ; extra == 'all'
Requires-Dist: scikit-image ; extra == 'all'
Requires-Dist: sphinx-rtd-theme (>=0.5.0) ; extra == 'all'
Requires-Dist: imageio ; extra == 'all'
Requires-Dist: mtcnn ; extra == 'all'
Requires-Dist: tensorflow ; extra == 'all'
Requires-Dist: bert-for-tf2 ; extra == 'all'
Provides-Extra: appdirs
Requires-Dist: appdirs ; extra == 'appdirs'
Provides-Extra: audio-encoder
Requires-Dist: librosa ; extra == 'audio-encoder'
Provides-Extra: bert-for-tf2
Requires-Dist: bert-for-tf2 ; extra == 'bert-for-tf2'
Provides-Extra: clip
Requires-Dist: imageio ; extra == 'clip'
Requires-Dist: clip-by-openai ; extra == 'clip'
Requires-Dist: scikit-image ; extra == 'clip'
Requires-Dist: Pillow ; extra == 'clip'
Provides-Extra: clip-by-openai
Requires-Dist: clip-by-openai ; extra == 'clip-by-openai'
Provides-Extra: core
Requires-Dist: numpy ; extra == 'core'
Requires-Dist: PyYAML ; extra == 'core'
Requires-Dist: vectorai ; extra == 'core'
Requires-Dist: requests ; extra == 'core'
Provides-Extra: encoders-audio-pytorch
Requires-Dist: fairseq ; extra == 'encoders-audio-pytorch'
Requires-Dist: torch (>=1.6.0) ; extra == 'encoders-audio-pytorch'
Provides-Extra: encoders-audio-tfhub
Requires-Dist: librosa ; extra == 'encoders-audio-tfhub'
Requires-Dist: tensorflow-hub ; extra == 'encoders-audio-tfhub'
Requires-Dist: tensorflow ; extra == 'encoders-audio-tfhub'
Requires-Dist: soundfile ; extra == 'encoders-audio-tfhub'
Provides-Extra: encoders-code-transformers
Requires-Dist: transformers ; extra == 'encoders-code-transformers'
Requires-Dist: torch (>=1.6.0) ; extra == 'encoders-code-transformers'
Provides-Extra: encoders-image
Requires-Dist: imageio ; extra == 'encoders-image'
Requires-Dist: scikit-image ; extra == 'encoders-image'
Provides-Extra: encoders-image-fastai
Requires-Dist: fastai (==2.1.8) ; extra == 'encoders-image-fastai'
Requires-Dist: torch (>=1.6.0) ; extra == 'encoders-image-fastai'
Provides-Extra: encoders-image-tf-face-detection
Requires-Dist: mtcnn ; extra == 'encoders-image-tf-face-detection'
Requires-Dist: tensorflow ; extra == 'encoders-image-tf-face-detection'
Requires-Dist: appdirs ; extra == 'encoders-image-tf-face-detection'
Requires-Dist: opencv-python ; extra == 'encoders-image-tf-face-detection'
Requires-Dist: Pillow ; extra == 'encoders-image-tf-face-detection'
Provides-Extra: encoders-image-tfhub
Requires-Dist: imageio ; extra == 'encoders-image-tfhub'
Requires-Dist: tensorflow-hub ; extra == 'encoders-image-tfhub'
Requires-Dist: tensorflow ; extra == 'encoders-image-tfhub'
Requires-Dist: scikit-image ; extra == 'encoders-image-tfhub'
Provides-Extra: encoders-text-sentence-transformers
Requires-Dist: sentence-transformers ; extra == 'encoders-text-sentence-transformers'
Requires-Dist: torch (>=1.6.0) ; extra == 'encoders-text-sentence-transformers'
Provides-Extra: encoders-text-tf-transformers
Requires-Dist: transformers ; extra == 'encoders-text-tf-transformers'
Requires-Dist: tensorflow ; extra == 'encoders-text-tf-transformers'
Provides-Extra: encoders-text-tfhub
Requires-Dist: tensorflow ; extra == 'encoders-text-tfhub'
Requires-Dist: tensorflow-text ; extra == 'encoders-text-tfhub'
Requires-Dist: tf-models-official ; extra == 'encoders-text-tfhub'
Requires-Dist: tensorflow-hub ; extra == 'encoders-text-tfhub'
Requires-Dist: bert-for-tf2 ; extra == 'encoders-text-tfhub'
Provides-Extra: encoders-text-tfhub-windows
Requires-Dist: tensorflow-hub ; extra == 'encoders-text-tfhub-windows'
Requires-Dist: tensorflow ; extra == 'encoders-text-tfhub-windows'
Requires-Dist: bert-for-tf2 ; extra == 'encoders-text-tfhub-windows'
Requires-Dist: tf-models-official ; extra == 'encoders-text-tfhub-windows'
Provides-Extra: encoders-text-torch-transformers
Requires-Dist: transformers ; extra == 'encoders-text-torch-transformers'
Requires-Dist: torch (>=1.6.0) ; extra == 'encoders-text-torch-transformers'
Provides-Extra: encoders-video
Requires-Dist: opencv-python ; extra == 'encoders-video'
Requires-Dist: moviepy ; extra == 'encoders-video'
Provides-Extra: fairseq
Requires-Dist: fairseq ; extra == 'fairseq'
Provides-Extra: fastai_2.1.8
Requires-Dist: fastai (==2.1.8) ; extra == 'fastai_2.1.8'
Provides-Extra: imageio
Requires-Dist: imageio ; extra == 'imageio'
Provides-Extra: librosa
Requires-Dist: librosa ; extra == 'librosa'
Provides-Extra: moviepy
Requires-Dist: moviepy ; extra == 'moviepy'
Provides-Extra: mtcnn
Requires-Dist: mtcnn ; extra == 'mtcnn'
Provides-Extra: numpy
Requires-Dist: numpy ; extra == 'numpy'
Provides-Extra: opencv-python
Requires-Dist: opencv-python ; extra == 'opencv-python'
Provides-Extra: perf
Provides-Extra: pytest
Requires-Dist: pytest ; extra == 'pytest'
Provides-Extra: requests
Requires-Dist: requests ; extra == 'requests'
Provides-Extra: scikit-image
Requires-Dist: scikit-image ; extra == 'scikit-image'
Provides-Extra: sentence-transformers
Requires-Dist: sentence-transformers ; extra == 'sentence-transformers'
Provides-Extra: soundfile
Requires-Dist: soundfile ; extra == 'soundfile'
Provides-Extra: sphinx-rtd-theme_0.5.0
Requires-Dist: sphinx-rtd-theme (>=0.5.0) ; extra == 'sphinx-rtd-theme_0.5.0'
Provides-Extra: tensorflow
Requires-Dist: tensorflow ; extra == 'tensorflow'
Provides-Extra: tensorflow_hub
Requires-Dist: tensorflow-hub ; extra == 'tensorflow_hub'
Provides-Extra: tensorflow_text
Requires-Dist: tensorflow-text ; extra == 'tensorflow_text'
Provides-Extra: test
Requires-Dist: sphinx-rtd-theme (>=0.5.0) ; extra == 'test'
Requires-Dist: pytest ; extra == 'test'
Provides-Extra: tf-models-official
Requires-Dist: tf-models-official ; extra == 'tf-models-official'
Provides-Extra: torch_1.6.0
Requires-Dist: torch (>=1.6.0) ; extra == 'torch_1.6.0'
Provides-Extra: transformers
Requires-Dist: transformers ; extra == 'transformers'
Provides-Extra: vectorai
Requires-Dist: vectorai ; extra == 'vectorai'

<p align="center">
    <a href="https://hub.getvectorai.com">
        <img align="center" src="https://getvectorai.com/assets/hub-logo-with-text.png" width="400"/>
    </a>
    <br>
<p>
<br>
<p align="center">
    <a href="https://github.com/vector-ai/vectorhub">
        <img alt="Release" src="https://img.shields.io/github/v/tag/vector-ai/vectorhub?label=release">
    </a>
    <a href="https://getvectorai.com">
        <img alt="Website" src="https://img.shields.io/website?up_message=online&label=website&url=https%3A%2F%2Fgetvectorai.com">
    </a>
    <a href="https://vector-ai.github.io/vectorhub">
        <img alt="Documentation" src="https://img.shields.io/website?up_message=online&label=documentation&url=https%3A%2F%2Fvector-ai.github.io%2Fvectorhub">
    </a>
    <a href="https://hub.getvectorai.com">
        <img alt="Hub" src="https://img.shields.io/website?up_message=online&label=hub&url=https%3A%2F%2Fhub.getvectorai.com">
    </a>
    <a href="https://join.slack.com/t/vector-ai-workspace/shared_invite/zt-itto14oy-0KerBV7onSuYRP_kmXE9yA">
        <img alt="Slack" src="https://img.shields.io/badge/slack-join-blue.svg">
    </a>
</p>

<h3 align="center">
Vector Hub is a library for publication, discovery, and consumption of State-of-the-art models to turn data into vectors. (Text2Vec, Image2Vec, Video2Vec, Face2Vec, Bert2Vec, Inception2Vec, Code2Vec, LegalBert2Vec, etc)
</h3>


---
<p align="center">
    <a href="https://hub.getvectorai.com">
        <img align="center" src="https://getvectorai.com/assets/vectorhub-goal.png" width="800"/>
    </a>
</p>
<br>


There are many ways to extract vectors from data. This library aims to bring in all the state of the art models in a simple manner to vectorise your data easily.

Vector Hub provides:
- A low barrier of entry for practitioners (using common methods)
- Vectorise rich and complex data types like: text, image, audio, etc in 3 lines of code
- Retrieve and find information about a model
- An easy way to handle dependencies easily for different models
- Universal format of installation and encoding (using a simple `encode` method).

In order to provide an easy way for practitioners to quickly experiment, research and build new models and feature vectors, we provide a streamlined way to obtain vectors through our `encode` method.
There are thousands of _____2Vec models across different use cases/domains. Vectorhub allows people to aggregate their work and share it with the community. 

Think transformers for NLP, Sci-kit Learn for data scientists.

---

## Quickstart:

[Intro to Vectors](https://github.com/vector-ai/vectorhub#what-are-vectors) | [Model Hub](https://hub.getvectorai.com/) | [Google Colab Quickstart](https://go.vctr.ai/vectorhub-colab) | [Python Documentation](https://go.vctr.ai/vectorhub-docs)

---

## Installation:
To get started quickly install vectorhub:

```
pip install vectorhub
```

Alternatively if you require more up-to-date models/features and are okay if it is not fully stable, you can install the nightly version of VectorHub using:
```
pip install vectorhub-nightly
```

After this, our built-in dependency manager will tell you what to install when you instantiate
a model. The main types of installation options can be found here: https://hub.getvectorai.com/

To install different types of models:
```
# To install transformer requirements
pip install vectorhub[text-encoder-transformers]
```

To install all models at once (note: this can take a while! We recommend searching for an interesting model on the website such as USE2Vec or BitMedium2Vec and following the installation line or see examples below.)
```
pip install vectorhub[all]
```

We recommend activating a new virtual environment and then installing using the following: 

```
python3 -m pip install virtualenv 
python3 -m virtualenv env 
source env/bin/activate
python3 -m pip install --upgrade pip 
python3 -m pip install vectorhub[all]
```

### Leverage [Tensorflow Hub's](https://tfhub.dev) powerful models to create vectors
Vectorise your image in 3 lines of code using [Google's Big Image Transfer model](https://blog.tensorflow.org/2020/05/bigtransfer-bit-state-of-art-transfer-learning-computer-vision.html):

```
from vectorhub.encoders.image.tfhub import BitSmall2Vec
image_encoder = BitSmall2Vec()
image_encoder.encode('https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_92x30dp.png')
[0.47, 0.83, 0.148, ...]
```
Vectorise your text in 3 lines of code using [Google's BERT model](https://blog.google/products/search/search-language-understanding-bert/):
```
from vectorhub.encoders.text.tfhub import Bert2Vec
text_encoder = Bert2Vec()
text_encoder.encode('This is sparta!')
[0.47, 0.83, 0.148, ...]
```

Vectorise your question and answer in 3 lines of code using [Google's USE QA model](https://tfhub.dev/google/universal-sentence-encoder-qa/3):
```
from vectorhub.bi_encoders.text.tfhub import UseQA2Vec
text_encoder = UseQA2Vec()
text_encoder.encode_question('Who is sparta!')
[0.47, 0.83, 0.148, ...]
text_encoder.encode_answer('Sparta!')
[0.47, 0.83, 0.148, ...]
```

### Leverage [HuggingFace Transformer's Albert](https://github.com/huggingface/transformers)

```
from vectorhub.encoders.text import Transformer2Vec
text_encoder = Transformer2Vec('albert-base-v2')
text_encoder.encode('This is sparta!')
[0.47, 0.83, 0.148, ...]
```
### Leverage [Facebook Dense Passage Retrieval](https://github.com/facebookresearch/DPR)
```
from vectorhub.bi_encoders.qa.torch_transformers import DPR2Vec
text_encoder = DPR2Vec()
text_encoder.encode_question('Who is sparta!')
[0.47, 0.83, 0.148, ...]
text_encoder.encode_answer('Sparta!')
[0.47, 0.83, 0.148, ...]
```

---

### Index and search your vectors easily on the cloud using 1 line of code! 

```
#pip install vectorhub[encoders-text-tfhub]
from vectorhub.encoders.text.tfhub import USE2VEc
encoder = USE2Vec()

# You can request an api_key simply by using your username and email.
username = '<your username>'
email = '<your email>'
api_key = encoder.request_api_key(username, email)

# Index in 1 line of code
items = ['dogs', 'toilet', 'paper', 'enjoy walking']
encoder.add_documents(user, api_key, items)

# Search in 1 line of code and get the most similar results.
encoder.search('basin')
```

Add metadata to your search (information about your vectors)

```
# Add the number of letters of each word
metadata = [7, 6, 5, 12]
encoder.add_documents(user, api_key, items=items, metadata=metadata)
```

#### Using a document-orientated-approach instead:

```
from vectorhub.encoders.text import Transformer2Vec
encoder = Transformer2Vec('bert-base-uncased')

from vectorai import ViClient
vi_client = ViClient(username, api_key)
docs = vi_client.create_sample_documents(10)
vi_client.insert_documents('collection_name_here', docs, models={'color': encoder.encode})

# Now we can search through our collection 
vi_client.search('collection_name_here', field='color_vector_', vector=encoder.encode('purple'))
```

---

### Easily access information with your model!

```
# If you want to additional information about the model, you can access the information below:
text_encoder.definition.repo
text_encoder.definition.description
# If you want all the information in a dictionary, you can call:
text_encoder.definition.create_dict() # returns a dictionary with model id, description, paper, etc.
```

---

### Turn Off Error-Catching

By default, if encoding errors, it returns a vector filled with 1e-7 so that if you are encoding and then inserting then it errors out.
However, if you want to turn off automatic error-catching in VectorHub, simply run: 

```
import vectorhub
vectorhub.options.set_option('catch_vector_errors', False)
```

If you want to turn it back on again, run: 
```
vectorhub.options.set_option('catch_vector_errors', True)
```

---

### Instantiate our auto_encoder class as such and use any of the models! 

```
from vectorhub.auto_encoder import AutoEncoder
encoder = AutoEncoder.from_model('text/bert')
encoder.encode("Hello vectorhub!")
[0.47, 0.83, 0.148, ...]
```

You can choose from our list of models: 
```
['text/albert', 'text/bert', 'text/labse', 'text/use', 'text/use-multi', 'text/use-lite', 'text/legal-bert', 'audio/fairseq', 'audio/speech-embedding', 'audio/trill', 'audio/trill-distilled', 'audio/vggish', 'audio/yamnet', 'audio/wav2vec', 'image/bit', 'image/bit-medium', 'image/inception', 'image/inception-v2', 'image/inception-v3', 'image/inception-resnet', 'image/mobilenet', 'image/mobilenet-v2', 'image/resnet', 'image/resnet-v2', 'qa/use-multi-qa', 'qa/use-qa', 'qa/dpr', 'qa/lareqa-qa']
```
## What are Vectors?
Common Terminologys when operating with Vectors:
- Vectors (aka. Embeddings, Encodings, Neural Representation) ~ It is a list of numbers to represent a piece of data. 
    E.g. the vector for the word "king" using a Word2Vec model is [0.47, 0.83, 0.148, ...]
- ____2Vec (aka. Models, Encoders, Embedders) ~ Turns data into vectors e.g. Word2Vec turns words into vector

<p align="center">
    <img align="center" src="https://jalammar.github.io/images/word2vec/word2vec.png" width="600"/>
    <br>
<p>


### How can I use vectors?

Vectors have a broad range of applications. The most common use case is to perform semantic vector search and analysing the topics/clusters using vector analytics. 

If you are interested in these applications, take a look at [Vector AI](https://github.com/vector-ai/vectorai).

### How can I obtain vectors?
- Taking the outputs of layers from deep learning models
- Data cleaning, such as one hot encoding labels
- Converting graph representations to vectors

### How To Upload Your 2Vec Model

[Read here if you would like to contribute your model!](https://vector-ai.github.io/vectorhub/how_to_add_a_model.html)

## Philosophy

The goal of VectorHub is to provide a flexible yet comprehensive framework that allows people to easily be able to turn their data into vectors in whatever form the data can be in. While our focus is largely on simplicity, customisation should always be an option and the level of abstraction is always up model-uploader as long as the reason is justified. For example - with text, we chose to keep the encoding at the text level as opposed to the token level because selection of text should not be applied at the token level so practitioners are aware of what texts go into the actual vectors (i.e. instead of ignoring a '[next][SEP][wo][##rd]', we are choosing to ignore 'next word' explicitly. We think this will allow practitioners to focus better on what should matter when it comes to encoding. 

Similarly, when we are turning data into vectors, we convert to native Python objects. The decision for this is to attempt to remove as many dependencies as possible once the vectors are created - specifically those of deep learning frameworks such as Tensorflow/PyTorch. This is to allow other frameworks to be built on top of it.

## Team

This library is maintained by the Vector AI - your go-to solution for Production-Ready AI development. If you are interested in using our API for vector search, visit https://vctr.ai or if you are interested in using Vector AI API, check out https://api.vctr.ai or our Github package https://gh.vctr.ai

### Credit:

This library wouldn't exist if it weren't for the following libraries and the incredible machine learning community that releases their state-of-the-art models:

1. https://github.com/huggingface/transformers
2. https://github.com/tensorflow/hub
3. https://github.com/pytorch/pytorch
4. Word2Vec image - Alammar, Jay (2018). The Illustrated Transformer [Blog post]. Retrieved from https://jalammar.github.io/illustrated-transformer/
5. https://github.com/UKPLab/sentence-transformers


