# coding=utf-8
# --------------------------------------------------------------------------
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is
# regenerated.
# --------------------------------------------------------------------------

from msrest.serialization import Model


class RunConfiguration(Model):
    """RunConfiguration.

    :param script:
    :type script: str
    :param command:
    :type command: str
    :param use_absolute_path:
    :type use_absolute_path: bool
    :param arguments:
    :type arguments: list[str]
    :param framework: Possible values include: 'Python', 'PySpark', 'Cntk',
     'TensorFlow', 'PyTorch', 'PySparkInteractive', 'R'
    :type framework: str or ~designer.models.Framework
    :param communicator: Possible values include: 'None', 'ParameterServer',
     'Gloo', 'Mpi', 'Nccl', 'ParallelTask'
    :type communicator: str or ~designer.models.Communicator
    :param target:
    :type target: str
    :param data_references:
    :type data_references: dict[str,
     ~designer.models.DataReferenceConfiguration]
    :param data:
    :type data: dict[str, ~designer.models.Data]
    :param output_data:
    :type output_data: dict[str, ~designer.models.OutputData]
    :param job_name:
    :type job_name: str
    :param max_run_duration_seconds:
    :type max_run_duration_seconds: long
    :param node_count:
    :type node_count: int
    :param priority:
    :type priority: int
    :param credential_passthrough:
    :type credential_passthrough: bool
    :param identity:
    :type identity: ~designer.models.IdentityConfiguration
    :param environment:
    :type environment: ~designer.models.EnvironmentDefinition
    :param history:
    :type history: ~designer.models.HistoryConfiguration
    :param spark:
    :type spark: ~designer.models.SparkConfiguration
    :param parallel_task:
    :type parallel_task: ~designer.models.ParallelTaskConfiguration
    :param ai_super_computer:
    :type ai_super_computer: ~designer.models.AISuperComputerConfiguration
    :param tensorflow:
    :type tensorflow: ~designer.models.TensorflowConfiguration
    :param mpi:
    :type mpi: ~designer.models.MpiConfiguration
    :param py_torch:
    :type py_torch: ~designer.models.PyTorchConfiguration
    :param hdi:
    :type hdi: ~designer.models.HdiConfiguration
    :param docker:
    :type docker: ~designer.models.DockerConfiguration
    :param command_return_code_config:
    :type command_return_code_config: ~designer.models.CommandReturnCodeConfig
    :param environment_variables:
    :type environment_variables: dict[str, str]
    """

    _attribute_map = {
        'script': {'key': 'script', 'type': 'str'},
        'command': {'key': 'command', 'type': 'str'},
        'use_absolute_path': {'key': 'useAbsolutePath', 'type': 'bool'},
        'arguments': {'key': 'arguments', 'type': '[str]'},
        'framework': {'key': 'framework', 'type': 'str'},
        'communicator': {'key': 'communicator', 'type': 'str'},
        'target': {'key': 'target', 'type': 'str'},
        'data_references': {'key': 'dataReferences', 'type': '{DataReferenceConfiguration}'},
        'data': {'key': 'data', 'type': '{Data}'},
        'output_data': {'key': 'outputData', 'type': '{OutputData}'},
        'job_name': {'key': 'jobName', 'type': 'str'},
        'max_run_duration_seconds': {'key': 'maxRunDurationSeconds', 'type': 'long'},
        'node_count': {'key': 'nodeCount', 'type': 'int'},
        'priority': {'key': 'priority', 'type': 'int'},
        'credential_passthrough': {'key': 'credentialPassthrough', 'type': 'bool'},
        'identity': {'key': 'identity', 'type': 'IdentityConfiguration'},
        'environment': {'key': 'environment', 'type': 'EnvironmentDefinition'},
        'history': {'key': 'history', 'type': 'HistoryConfiguration'},
        'spark': {'key': 'spark', 'type': 'SparkConfiguration'},
        'parallel_task': {'key': 'parallelTask', 'type': 'ParallelTaskConfiguration'},
        'ai_super_computer': {'key': 'aiSuperComputer', 'type': 'AISuperComputerConfiguration'},
        'tensorflow': {'key': 'tensorflow', 'type': 'TensorflowConfiguration'},
        'mpi': {'key': 'mpi', 'type': 'MpiConfiguration'},
        'py_torch': {'key': 'pyTorch', 'type': 'PyTorchConfiguration'},
        'hdi': {'key': 'hdi', 'type': 'HdiConfiguration'},
        'docker': {'key': 'docker', 'type': 'DockerConfiguration'},
        'command_return_code_config': {'key': 'commandReturnCodeConfig', 'type': 'CommandReturnCodeConfig'},
        'environment_variables': {'key': 'environmentVariables', 'type': '{str}'},
    }

    def __init__(self, **kwargs):
        super(RunConfiguration, self).__init__(**kwargs)
        self.script = kwargs.get('script', None)
        self.command = kwargs.get('command', None)
        self.use_absolute_path = kwargs.get('use_absolute_path', None)
        self.arguments = kwargs.get('arguments', None)
        self.framework = kwargs.get('framework', None)
        self.communicator = kwargs.get('communicator', None)
        self.target = kwargs.get('target', None)
        self.data_references = kwargs.get('data_references', None)
        self.data = kwargs.get('data', None)
        self.output_data = kwargs.get('output_data', None)
        self.job_name = kwargs.get('job_name', None)
        self.max_run_duration_seconds = kwargs.get('max_run_duration_seconds', None)
        self.node_count = kwargs.get('node_count', None)
        self.priority = kwargs.get('priority', None)
        self.credential_passthrough = kwargs.get('credential_passthrough', None)
        self.identity = kwargs.get('identity', None)
        self.environment = kwargs.get('environment', None)
        self.history = kwargs.get('history', None)
        self.spark = kwargs.get('spark', None)
        self.parallel_task = kwargs.get('parallel_task', None)
        self.ai_super_computer = kwargs.get('ai_super_computer', None)
        self.tensorflow = kwargs.get('tensorflow', None)
        self.mpi = kwargs.get('mpi', None)
        self.py_torch = kwargs.get('py_torch', None)
        self.hdi = kwargs.get('hdi', None)
        self.docker = kwargs.get('docker', None)
        self.command_return_code_config = kwargs.get('command_return_code_config', None)
        self.environment_variables = kwargs.get('environment_variables', None)
