{% macro loss_quadratic(declared_name) %}
    {{declared_name}} = tf.keras.losses.MeanSquaredError()
{% endmacro %}


{% macro loss_crossentropy(declared_name) %}
    {{declared_name}} = tf.keras.losses.CategoricalCrossentropy()
{% endmacro %}


{% macro loss_weighted_crossentropy(declared_name, class_weights) %}
    def {{declared_name}}(y_true, y_pred):
        n_classes = y_pred.get_shape().as_list()[-1]
        flat_pred = tf.reshape(y_pred, [-1, n_classes])
        flat_labels = tf.reshape(y_true, [-1, n_classes])
        loss_tensor =  tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, {{class_weights}}))        
        return loss_tensor
{% endmacro %}


{% macro loss_dice(declared_name) %}
    def {{declared_name}}(y_true, y_pred):
        eps = 1e-5
        intersection = tf.reduce_sum(tf.multiply(y_pred, y_true))
        union = tf.reduce_sum(tf.multiply(y_pred, y_pred)) + tf.reduce_sum(tf.multiply(y_true, y_true))
        dice_coef = (2 * intersection + eps)/(union + eps)
        loss_tensor = tf.clip_by_value(1 - dice_coef, eps, 1.0-eps)
        return loss_tensor
{% endmacro %}
