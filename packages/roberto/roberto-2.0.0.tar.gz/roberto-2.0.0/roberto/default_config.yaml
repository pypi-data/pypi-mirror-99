project:
  name: null
  # One can specify project-level extra requirements, but this normally not
  # needed. Roberto will try to derive all requirements automatically from
  # the default configuration and the conda recipes present in the project.
  # Requirements are always specified as a 2-tuple with a conda package name
  # and a pip package name. When a package does not exist, use null instead
  # of the name
  requirements: []
  packages: [
  # Repeat as many as you like. The order determines the order in which they
  # are linted, tested, built, etc.
  # - conda_name: 'name of the conda package' # deprecated, use dist_name
  #   dist_name: 'name_for_distribution_packages' # can include python-
  #   tools: [] # list, any of the tools defined below
  #   name: '' # python or cpp name, defaults to project.name
  #   path: # root of the package relative to the project root defaults to '.'
  ]

# Either use "pip" or "conda" (with pip as fallback) as package manager.
package_manager: pip
testenv:
  # The following setting controls what kind of virtual environment should be
  # used. This can be "venv", "conda" or "none". When set to "none", it is
  # assumed that some environment is externally created and activated before
  # calling Roberto. (The latter may be useful for CI in the cloud.)
  use: venv
  # The following are filled-in automatically and can be useful in the
  # tools defined below:
  base_path: null  # Root directory where all environments are stored.
  name: null  # Name of the testing environment.
  path: null  # Directory containing the testing environment.
# When the absolute is set to true, feature branches are treated as if they are
# the master branch. This only affects linters that can ignore issues outside
# the feature branch.
absolute: false


# Custom configuration below this line should be rarely needed.


# Used for downloading miniconda and optionally macosx sdk:
download_dir: '${HOME}/Downloads/'
# Set to true for deployment of architecture-independent files:
deploy_noarch: false
# Set to true for deployment of architecture-dependent files:
deploy_binary: false
# Set to true for uploading coverage:
upload_coverage: false

run:
  echo: true

git:
  # Name of the branch being merged into, may be same as git.branch, if not a PR.
  merge_branch: master
  # The following are set automatically...
  branch: null  # name of the current branch
  describe: null  # output of git describe --tags
  tag: null  # the most recent tag
  tag_version: null  # version name derived from git describe, i.e. major.minor.patch{.post}
  tag_soversion: null  # the so-version, i.e. major.minor
  tag_version_major: null
  tag_version_minor: null
  tag_version_patch: null
  tag_version_suffix: null
  tag_stable: false  # is the current build a stable or main release?
  tag_test: false  # is the current build a test or beta release?
  tag_dev: false  # is the current build a development or alpha release?
  tag_release: false  # is the current build a release

# Some special settings for a special OS:
macosx:
  install_sdk: false
  release: '10.9'
  sdk_release: 'https://github.com/phracker/MacOSX-SDKs/releases/download/10.13'
  # The following will be derived from the above settings.
  sdk_root: null

# Conda-specific settings:
conda:
  linux_url: 'https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh'
  osx_url: 'https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh'
  base_path: '${HOME}/miniconda3'
  # The pinning config must be a string of words separated by whitespace,
  # alternating package and version number. These packages will be pinned at
  # the given version in conda. Don't use wildcards.
  pinning: 'python 3.7'
  channels: [conda-forge]  # you practically always need to include conda-forge.


# Venv-specific settings
venv:
  # New virtual environments will be created in:
  base_path: '${HOME}/.local/venvs'
  # Python binary to use when creating new venv:
  python_bin: python


tools:
  # Writer a version.py file.
  write-py-version:
    cls: WriteVersion
    template: |
      """Autogenerated version information file.

      Manual changes to this file will be overwritten.

      The output of git describe was: ``{config.git.describe}``

      The derived version is: ``{config.git.tag_version}``
      """
      __version__ = '{config.git.tag_version}'
      DEV_CLASSIFIER = '{config.git.dev_classifier}'
    destination: '{package.name}/_version.py'

  # Write a CMakeListsVersion.txt.in file
  write-cmake-version:
    cls: WriteVersion
    template: |
      # This file is automatically generated. Manual changes will be overwritten.
      set(GIT_DESCRIBE "{config.git.describe}")
      set(GIT_TAG_VERSION "{config.git.tag_version}")
      set(GIT_TAG_SOVERSION "{config.git.tag_soversion}")
      set(GIT_TAG_VERSION_MAJOR "{config.git.tag_version_major}")
      set(GIT_TAG_VERSION_MINOR "{config.git.tag_version_minor}")
      set(GIT_TAG_VERSION_PATCH "{config.git.tag_version_patch}")
    destination: 'CMakeListsVersion.txt.in'

  # Run the static linters with for cardboardlint as configured in in ~/.cardboardlint.yaml
  # (Static liners do not require compilation or interpretaton of code.)
  # See https://github.com/theochem/cardboardlint/
  # Some requirements have no pip packages. You may install these manually,
  # e.g. using your OS package manager.
  cardboardlint-static:
    cls: LintStatic
    requirements:
      - [theochem::cardboardlint, cardboardlint]
      - [pycodestyle, pycodestyle]
      - [pydocstyle, pydocstyle]
      - [cppcheck, null]
      - [cpplint, cpplint]
      - [yamllint, yamllint]
      - [flake8, flake8]
      - [doxygen, null]
      - [autopep8, autopep8]
      - [black, black]
      - [yapf, yapf]
      - [restructuredtext_lint, restructuredtext_lint]
      # Following is needed for rst-lint.
      # See https://github.com/twolfson/restructuredtext-lint/issues/41
      - [pygments, pygments]
    commands_master:
      - cardboardlinter -f static -n auto
    commands_feature:
      - 'cardboardlinter -r {config.git.merge_branch} -f static -n auto'

  # Perform an in-place build of a Python package. This may even be useful for
  # pure python packages, to generate a suitable activate script.
  build-py-inplace:
    cls: BuildInPlace
    check_vars:
      - CXXFLAGS
      - CFLAGS
      - LDFLAGS
      - PYTHONPATH
      - RPATH
    commands:
      # Note that distutils is not very clever with an empty -R argument.
      # This would simply result in a disfunctional compiler argument,
      # which we have to avoid. Hence, some ugly bash is needed.
      # In case of OSX, i.e. when SDKROOT is specified, we need to set CFLAGS
      # and CXXFLAGS explicitly because distutils does not pick this up for us.
      - if [[ -n "${{CONDA_BUILD_SYSROOT}}" ]]; then
          export CXXFLAGS="${{CXXFLAGS}} -isysroot ${{CONDA_BUILD_SYSROOT}}";
          export CFLAGS="${{CFLAGS}} -isysroot ${{CONDA_BUILD_SYSROOT}}";
        fi;
        python setup.py build_ext -i --define CYTHON_TRACE_NOGIL
        $([[ -n "${{RPATH}}" ]] && echo -R "${{RPATH}}")
    extra_vars:
      PYTHONPATH: '{package.abspath}'

  # Perform an in-place build of a CMake package.
  build-cmake-inplace:
    cls: BuildInPlace
    requirements:
      - [cmake, null]
      - [make, null]
    check_vars:
      - CXXFLAGS
      - CFLAGS
      - LDFLAGS
    commands:
      # On OSX, CMake will pick up SDKROOT automatically. See CMake docs
      # https://cmake.org/cmake/help/latest/variable/CMAKE_OSX_SYSROOT.html
      - mkdir -p build
      - cd build; cmake .. -DCMAKE_BUILD_TYPE=debug
      - cd build; make VERBOSE=1 -j
    extra_vars:
      # Different compilers have incompatible arguments to set the RPATH
      # for the linker, so we cannot use LDFLAGS for this, alas.
      RPATH: '{package.abspath}/build/{package.name}'
      CXXFLAGS: >-
        -I{package.abspath}
      CFLAGS: >-
        -I{package.abspath}
      LDFLAGS: >-
        -L{package.abspath}/build/{package.name}

  # Run unit tests on an in-place build with pytest.
  pytest:
    cls: TestInPlace
    requirements:
      - [pytest, pytest]
      - [pytest-cov, pytest-cov]
      - [pytest-xdist, pytest-xdist]
      - [pytest-regressions, pytest-regressions]
    commands:
      - pytest {package.name} -v --cov={package.name}
          --cov-report xml:coverage_pytest.xml
          --cov-report term-missing
          --cov-branch --color=yes
          -n auto

  # Run unit tests on an in-place build with `make test`.
  maketest:
    cls: TestInPlace
    requirements:
      - [gcovr, null]
      - [make, null]
    commands:
      # Remove old coverage results, if any.
      - cd build; find . | grep '\\.gcda$' | xargs rm -vf
      # Run the tests.
      - cd build; make test
      # Run gcov manually, only on Linux for now.
      - if [[ "$OSTYPE" == "linux-gnu"* ]]; then
          cd build; find . -type f -name '*.gcno' -exec ${{HOST}}-gcov -pbc {{}} +;
        fi
      # Remove coverage files related to libraries in the conda env.
      - cd build; rm -vf *'#envs#{config.testenv.name}#'*.gcov
      # gcovr searches for all *.gcov files and produces a nice text report on
      # stdout.
      - gcovr -gk

  # Upload coverage result to codecov
  upload-codecov:
    cls: UploadCoverage
    requirements:
      - [codecov, codecov]
    commands:
      # We have already executed gcov previously, so no need to run it again.
      - codecov -X gcov

  # Run the dynamic linters with for cardboardlint as configured in in ~/.cardboardlint.yaml
  # (Dynamic liners may require compilation or interpretaton of code.)
  # See https://github.com/theochem/cardboardlint/
  cardboardlint-dynamic:
    cls: LintDynamic
    requirements:
      - [theochem::cardboardlint, cardboardlint]
      - [pylint, pylint]
    commands_master:
      - cardboardlinter -f dynamic -n auto
    commands_feature:
      - 'cardboardlinter -r {config.git.merge_branch} -f dynamic -n auto'

  # Build the sphinx documentation
  build-sphinx-doc:
    cls: BuildDocs
    requirements:
      - [sphinx >=1.8, sphinx>=1.8]
      - [sphinx_rtd_theme, sphinx_rtd_theme]
      - [sphinx-autodoc-typehints, sphinx-autodoc-typehints]
      - [sphinxcontrib-apidoc, sphinxcontrib-apidoc]
    commands:
      - cd doc; make html

  # Upload (force-push) the sphinx documentation to gh-pages on github.com
  upload-docs-gh:
    cls: UploadDocsGit
    docroot: '{package.path}/doc/_build/html'
    docbranch: gh-pages
    docremote: origin
    deploy_labels:
      - main
      - test

  # Build a python sdist
  build-py-source:
    cls: BuildPackage
    commands:
      - python setup.py sdist

  # Build a source distribution with cmake
  build-cmake-source:
    cls: BuildPackage
    requirements:
      - [cmake, null]
      - [make, null]
    commands:
      - mkdir -p dist
      - cd dist; cmake .. -DCMAKE_BUILD_TYPE=release
      - cd dist; make sdist

  # Build a conda package
  build-conda:
    cls: BuildPackage
    supported_envs: [conda]
    requirements:
      - [conda-build, null]
      - [conda-verify, null]
    commands:
      # CONDA_BLD_PATH must be set because otherwise local dependencies
      # cannot be found when working in any other environment than base.
      # See https://github.com/conda/conda-build/issues/2592
      # Some SDK kung-fu is needed to make everything reproducible on OSX. The
      # lines below are very sensitive to subtle changes, so don't touch
      # without proper testing on both Linux and OSX.
      - if [[ -n "${{SDKROOT}}" ]]; then
          printf "CONDA_BUILD_SYSROOT:\n  - ${{SDKROOT}}\n"
          > {config.testenv.path}/conda_build_config.yaml;
          cd {config.testenv.path};
        fi;
        CONDA_BLD_PATH={config.conda.build_path}
        PROJECT_VERSION={config.git.tag_version}
        conda build {package.abspath}/tools/conda.recipe --override-channel
          --skip-existing --no-anaconda-upload --variants {config.conda.variants}

  # Upload python source packages to pypi
  deploy-pypi:
    cls: Deploy
    requirements:
      - [twine, twine]
    deploy_vars:
      - TWINE_USERNAME
      - TWINE_PASSWORD
    include_sha256: false
    noarch_asset_patterns:
      - '{package.path}/dist/{package.dist_name}-{config.git.tag_version}.*'
    binary_asset_patterns: []
    deploy_labels:
      - main
      - test
      - dev
    commands:
      - twine upload --non-interactive {assets}

  # Upload any source packages to github.com
  deploy-github:
    cls: Deploy
    requirements:
      - [gh, null]
    deploy_vars:
      - GITHUB_TOKEN
    include_sha256: true
    noarch_asset_patterns:
      - '{package.path}/*dist*/{package.dist_name}-{config.git.tag_version}.*'
    binary_asset_patterns: []
    deploy_labels:
      - main
      - test
      - dev
    commands:
      - gh auth login -w; true
      - if [[ "{config.git.deploy_label}" == "main" ]]; then
            gh release create
            {config.git.tag_version}
            {assets}
            -t "Automatic release of version {config.git.tag_version}";
        else
            gh release create -p
            {config.git.tag_version}
            {assets}
            -t "Automatic release of version {config.git.tag_version}";
        fi

  # Upload conda packages to anaconda.org
  deploy-conda:
    cls: Deploy
    supported_envs: [conda]
    requirements:
      - [anaconda-client, null]
    deploy_vars:
      - ANACONDA_API_TOKEN
    include_sha256: false
    noarch_asset_patterns:
      - '{config.conda.build_path}/noarch/{package.dist_name}-{config.git.tag_version}-*.*'
    binary_asset_patterns:
      - '{config.conda.build_path}/linux-64/{package.dist_name}-{config.git.tag_version}-*.*'
      - '{config.conda.build_path}/osx-64/{package.dist_name}-{config.git.tag_version}-*.*'
    deploy_labels:
      - main
      - test
      - dev
    commands:
      - 'anaconda -v upload --force -l {config.git.deploy_label} {assets}'
